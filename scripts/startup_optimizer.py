#!/usr/bin/env python3
"""
Phase 4: å®¹å™¨å•Ÿå‹•æ€§èƒ½å„ªåŒ–å™¨
ç¢ºä¿æ•´å€‹ç³»çµ±å¿«é€Ÿå•Ÿå‹•ï¼Œé è¨ˆç®—æ•¸æ“šå³æ™‚å¯ç”¨
"""

import os
import time
import json
import logging
import asyncio
from pathlib import Path
from typing import Dict, List, Optional
import sys

# æ·»åŠ è·¯å¾‘
sys.path.append("/app/src")
sys.path.append("/app")

# é…ç½®æ—¥èªŒ
logging.basicConfig(
    level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)


class StartupOptimizer:
    """å®¹å™¨å•Ÿå‹•æ€§èƒ½å„ªåŒ–å™¨"""

    def __init__(self):
        self.startup_start_time = time.time()
        self.startup_file = "/tmp/netstack_startup_time"
        self.data_paths = {
            "enhanced_data": "/app/data",
            "tle_data": "/app/tle_data",
            "data": "/app/data",  # ä¿®æ­£è·¯å¾‘ï¼šå¾ test_output æ”¹ç‚º data
        }
        self.required_files = [
            "enhanced_satellite_data.json",
            "enhanced_data_summary.json",
            "enhanced_build_config.json",
        ]

    def record_startup_time(self):
        """è¨˜éŒ„å•Ÿå‹•æ™‚é–“"""
        try:
            with open(self.startup_file, "w") as f:
                f.write(str(self.startup_start_time))
            logger.info(f"âœ… å•Ÿå‹•æ™‚é–“å·²è¨˜éŒ„: {self.startup_start_time}")
        except Exception as e:
            logger.error(f"âŒ è¨˜éŒ„å•Ÿå‹•æ™‚é–“å¤±æ•—: {e}")

    def check_data_availability(self) -> Dict[str, bool]:
        """æª¢æŸ¥æ•¸æ“šå¯ç”¨æ€§"""
        logger.info("ğŸ” æª¢æŸ¥é è¨ˆç®—æ•¸æ“šå¯ç”¨æ€§")

        availability = {}

        for data_type, data_path in self.data_paths.items():
            path = Path(data_path)
            availability[data_type] = {
                "path_exists": path.exists(),
                "is_directory": path.is_dir() if path.exists() else False,
                "file_count": (
                    len(list(path.glob("*"))) if path.exists() and path.is_dir() else 0
                ),
            }

            if availability[data_type]["path_exists"]:
                logger.info(
                    f"âœ… {data_type}: {data_path} å­˜åœ¨ ({availability[data_type]['file_count']} å€‹æª”æ¡ˆ)"
                )
            else:
                logger.warning(f"âš ï¸ {data_type}: {data_path} ä¸å­˜åœ¨")

        return availability

    def preload_critical_data(self) -> Dict[str, any]:
        """é è¼‰å…¥é—œéµæ•¸æ“š"""
        logger.info("ğŸ“Š é è¼‰å…¥é—œéµæ•¸æ“š")

        preloaded_data = {}

        # æª¢æŸ¥ data ç›®éŒ„ä¸­çš„ Phase 0 æ•¸æ“š
        data_path = Path(self.data_paths["data"])

        for required_file in self.required_files:
            file_path = data_path / required_file

            if file_path.exists():
                try:
                    start_time = time.time()

                    if required_file.endswith(".json"):
                        with open(file_path, "r", encoding="utf-8") as f:
                            data = json.load(f)

                        # åªè¼‰å…¥å…ƒæ•¸æ“šï¼Œä¸è¼‰å…¥å¤§å‹æ•¸æ“š
                        if required_file == "enhanced_satellite_data.json":
                            # åªè¼‰å…¥æ‘˜è¦ä¿¡æ¯ï¼Œä¸è¼‰å…¥å®Œæ•´è»Œé“æ•¸æ“š
                            summary_data = {
                                "metadata": data.get("metadata", {}),
                                "observer_location": data.get("observer_location", {}),
                                "generation_info": data.get("generation_info", {}),
                                "constellations_summary": {},
                            }

                            # ç‚ºæ¯å€‹æ˜Ÿåº§åªè¼‰å…¥çµ±è¨ˆä¿¡æ¯
                            constellations = data.get("constellations", {})
                            for (
                                constellation,
                                constellation_data,
                            ) in constellations.items():
                                summary_data["constellations_summary"][
                                    constellation
                                ] = {
                                    "satellite_count": len(
                                        constellation_data.get("orbit_data", {})
                                    ),
                                    "statistics": constellation_data.get(
                                        "statistics", {}
                                    ),
                                }

                            preloaded_data[required_file] = summary_data
                        else:
                            preloaded_data[required_file] = data

                    load_time = time.time() - start_time
                    file_size = file_path.stat().st_size

                    logger.info(
                        f"âœ… {required_file}: è¼‰å…¥æˆåŠŸ ({file_size:,} bytes, {load_time:.3f}s)"
                    )

                except Exception as e:
                    logger.error(f"âŒ {required_file}: è¼‰å…¥å¤±æ•— - {e}")
                    preloaded_data[required_file] = None
            else:
                logger.warning(f"âš ï¸ {required_file}: æª”æ¡ˆä¸å­˜åœ¨")
                preloaded_data[required_file] = None

        return preloaded_data

    def optimize_memory_usage(self):
        """å„ªåŒ–è¨˜æ†¶é«”ä½¿ç”¨"""
        logger.info("ğŸ§  å„ªåŒ–è¨˜æ†¶é«”ä½¿ç”¨")

        try:
            import gc

            # å¼·åˆ¶åƒåœ¾å›æ”¶
            collected = gc.collect()
            logger.info(f"âœ… åƒåœ¾å›æ”¶å®Œæˆï¼Œé‡‹æ”¾ {collected} å€‹å°è±¡")

            # è¨­ç½®åƒåœ¾å›æ”¶é–¾å€¼
            gc.set_threshold(700, 10, 10)
            logger.info("âœ… åƒåœ¾å›æ”¶é–¾å€¼å·²å„ªåŒ–")

        except Exception as e:
            logger.error(f"âŒ è¨˜æ†¶é«”å„ªåŒ–å¤±æ•—: {e}")

    def setup_environment_variables(self):
        """è¨­ç½®ç’°å¢ƒè®Šé‡"""
        logger.info("ğŸ”§ è¨­ç½®ç’°å¢ƒè®Šé‡")

        env_vars = {
            "PYTHONUNBUFFERED": "1",
            "PYTHONDONTWRITEBYTECODE": "1",
            "PYTHONHASHSEED": "0",
            "PRECOMPUTED_DATA_ENABLED": "true",
            "ORBIT_CACHE_PRELOAD": "true",
        }

        for key, value in env_vars.items():
            if key not in os.environ:
                os.environ[key] = value
                logger.info(f"âœ… è¨­ç½®ç’°å¢ƒè®Šé‡: {key}={value}")

    def validate_startup_requirements(self) -> bool:
        """é©—è­‰å•Ÿå‹•éœ€æ±‚"""
        logger.info("âœ… é©—è­‰å•Ÿå‹•éœ€æ±‚")

        requirements = {
            "python_version": sys.version_info >= (3, 8),
            "data_availability": False,
            "memory_sufficient": True,
            "disk_space_sufficient": True,
        }

        # æª¢æŸ¥æ•¸æ“šå¯ç”¨æ€§
        availability = self.check_data_availability()
        requirements["data_availability"] = any(
            info["path_exists"] for info in availability.values()
        )

        # æª¢æŸ¥è¨˜æ†¶é«”
        try:
            import psutil

            memory = psutil.virtual_memory()
            requirements["memory_sufficient"] = (
                memory.available > 512 * 1024 * 1024
            )  # 512MB
            logger.info(f"å¯ç”¨è¨˜æ†¶é«”: {memory.available / 1024 / 1024:.1f} MB")
        except ImportError:
            logger.warning("ç„¡æ³•æª¢æŸ¥è¨˜æ†¶é«”ä½¿ç”¨é‡ (psutil æœªå®‰è£)")

        # æª¢æŸ¥ç£ç¢Ÿç©ºé–“
        try:
            import shutil

            disk_usage = shutil.disk_usage("/")
            free_space_gb = disk_usage.free / (1024**3)
            requirements["disk_space_sufficient"] = free_space_gb > 1.0  # 1GB
            logger.info(f"å¯ç”¨ç£ç¢Ÿç©ºé–“: {free_space_gb:.1f} GB")
        except:
            logger.warning("ç„¡æ³•æª¢æŸ¥ç£ç¢Ÿç©ºé–“")

        # è¼¸å‡ºé©—è­‰çµæœ
        all_passed = all(requirements.values())

        for requirement, passed in requirements.items():
            status = "âœ…" if passed else "âŒ"
            logger.info(f"{status} {requirement}: {'é€šé' if passed else 'å¤±æ•—'}")

        return all_passed

    def create_readiness_probe(self):
        """å‰µå»ºå°±ç·’æ¢é‡"""
        logger.info("ğŸ¥ å‰µå»ºå°±ç·’æ¢é‡")

        readiness_file = "/tmp/netstack_ready"

        try:
            with open(readiness_file, "w") as f:
                f.write(
                    json.dumps(
                        {
                            "ready": True,
                            "timestamp": time.time(),
                            "startup_duration": time.time() - self.startup_start_time,
                        }
                    )
                )

            logger.info(f"âœ… å°±ç·’æ¢é‡å·²å‰µå»º: {readiness_file}")

        except Exception as e:
            logger.error(f"âŒ å‰µå»ºå°±ç·’æ¢é‡å¤±æ•—: {e}")

    def generate_startup_report(self, preloaded_data: Dict) -> Dict:
        """ç”Ÿæˆå•Ÿå‹•å ±å‘Š"""
        startup_duration = time.time() - self.startup_start_time

        report = {
            "startup_info": {
                "start_time": self.startup_start_time,
                "duration_seconds": round(startup_duration, 3),
                "status": "completed",
            },
            "data_status": {
                "preloaded_files": len(
                    [f for f in preloaded_data.values() if f is not None]
                ),
                "total_files": len(self.required_files),
                "success_rate": len(
                    [f for f in preloaded_data.values() if f is not None]
                )
                / len(self.required_files),
            },
            "performance_metrics": {
                "startup_target_seconds": 30,
                "actual_startup_seconds": startup_duration,
                "target_achieved": startup_duration < 30,
                "performance_score": min(100, (30 / max(startup_duration, 1)) * 100),
            },
            "system_info": {
                "python_version": f"{sys.version_info.major}.{sys.version_info.minor}.{sys.version_info.micro}",
                "platform": sys.platform,
                "pid": os.getpid(),
            },
        }

        return report

    async def optimize_startup(self) -> Dict:
        """åŸ·è¡Œå®Œæ•´çš„å•Ÿå‹•å„ªåŒ–æµç¨‹"""
        logger.info("ğŸš€ é–‹å§‹å®¹å™¨å•Ÿå‹•å„ªåŒ–")

        # è¨˜éŒ„å•Ÿå‹•æ™‚é–“
        self.record_startup_time()

        # è¨­ç½®ç’°å¢ƒè®Šé‡
        self.setup_environment_variables()

        # é©—è­‰å•Ÿå‹•éœ€æ±‚
        requirements_ok = self.validate_startup_requirements()
        if not requirements_ok:
            logger.warning("âš ï¸ éƒ¨åˆ†å•Ÿå‹•éœ€æ±‚æœªæ»¿è¶³ï¼Œä½†ç¹¼çºŒå•Ÿå‹•")

        # é è¼‰å…¥é—œéµæ•¸æ“š
        preloaded_data = self.preload_critical_data()

        # å„ªåŒ–è¨˜æ†¶é«”ä½¿ç”¨
        self.optimize_memory_usage()

        # å‰µå»ºå°±ç·’æ¢é‡
        self.create_readiness_probe()

        # ç”Ÿæˆå•Ÿå‹•å ±å‘Š
        report = self.generate_startup_report(preloaded_data)

        # ä¿å­˜å•Ÿå‹•å ±å‘Š
        report_file = "/tmp/netstack_startup_report.json"
        try:
            with open(report_file, "w") as f:
                json.dump(report, f, indent=2)
            logger.info(f"ğŸ“Š å•Ÿå‹•å ±å‘Šå·²ä¿å­˜: {report_file}")
        except Exception as e:
            logger.error(f"âŒ ä¿å­˜å•Ÿå‹•å ±å‘Šå¤±æ•—: {e}")

        # è¼¸å‡ºæœ€çµ‚çµæœ
        duration = report["startup_info"]["duration_seconds"]
        target_achieved = report["performance_metrics"]["target_achieved"]

        if target_achieved:
            logger.info(f"ğŸ‰ å•Ÿå‹•å„ªåŒ–å®Œæˆï¼è€—æ™‚ {duration:.3f}s (ç›®æ¨™: <30s) âœ…")
        else:
            logger.warning(
                f"âš ï¸ å•Ÿå‹•å„ªåŒ–å®Œæˆï¼Œä½†è¶…éç›®æ¨™æ™‚é–“ã€‚è€—æ™‚ {duration:.3f}s (ç›®æ¨™: <30s)"
            )

        return report


async def main():
    """ä¸»å‡½æ•¸"""
    optimizer = StartupOptimizer()
    report = await optimizer.optimize_startup()

    # è¼¸å‡ºé—œéµæŒ‡æ¨™
    print(f"\nğŸ“Š å•Ÿå‹•æ€§èƒ½æ‘˜è¦:")
    print(f"å•Ÿå‹•æ™‚é–“: {report['startup_info']['duration_seconds']:.3f}s")
    print(
        f"ç›®æ¨™é”æˆ: {'æ˜¯' if report['performance_metrics']['target_achieved'] else 'å¦'}"
    )
    print(f"æ•¸æ“šè¼‰å…¥æˆåŠŸç‡: {report['data_status']['success_rate']:.1%}")
    print(f"æ€§èƒ½è©•åˆ†: {report['performance_metrics']['performance_score']:.1f}/100")


if __name__ == "__main__":
    asyncio.run(main())
