# TLE æ¸¬è©¦æ•¸æ“šåŠ è¼‰å™¨
# æä¾›çœŸå¯¦TLEæ•¸æ“šç”¨æ–¼æ¸¬è©¦ï¼Œç¢ºä¿å­¸è¡“ç´šæ•¸æ“šæ¨™æº–

import os
from pathlib import Path
from datetime import datetime, timezone, timedelta
from typing import List, Dict, Optional, Tuple
import json

class TLETestDataLoader:
    """TLEæ¸¬è©¦æ•¸æ“šåŠ è¼‰å™¨ - ç¢ºä¿ä½¿ç”¨çœŸå¯¦æ•¸æ“š"""
    
    def __init__(self):
        self.base_dir = Path(__file__).parent.parent.parent
        self.starlink_tle_dir = self.base_dir / "data" / "tle_data" / "starlink" / "tle"
        self.oneweb_tle_dir = self.base_dir / "data" / "tle_data" / "oneweb" / "tle"
        
    def get_real_starlink_tle(self, date: str = "20250908", satellite_count: int = 10) -> List[Dict]:
        """
        ç²å–çœŸå¯¦çš„Starlink TLEæ•¸æ“š
        
        Args:
            date: TLEæ•¸æ“šæ—¥æœŸ (YYYYMMDD)
            satellite_count: è¿”å›çš„è¡›æ˜Ÿæ•¸é‡ (é»˜èª10é¡†ç”¨æ–¼æ¸¬è©¦)
            
        Returns:
            List[Dict]: TLEæ•¸æ“šå­—å…¸åˆ—è¡¨
        """
        tle_file = self.starlink_tle_dir / f"starlink_{date}.tle"
        
        if not tle_file.exists():
            raise FileNotFoundError(f"TLEæ–‡ä»¶ä¸å­˜åœ¨: {tle_file}")
            
        tle_data = []
        with open(tle_file, 'r') as f:
            lines = f.readlines()
            
        # è§£æTLEæ•¸æ“š (æ¯3è¡Œç‚ºä¸€çµ„)
        for i in range(0, min(len(lines), satellite_count * 3), 3):
            if i + 2 < len(lines):
                tle_entry = self._parse_tle_lines(
                    lines[i].strip(),     # è¡›æ˜Ÿåç¨±
                    lines[i+1].strip(),   # Line 1
                    lines[i+2].strip()    # Line 2
                )
                if tle_entry:
                    tle_data.append(tle_entry)
                    
        return tle_data[:satellite_count]
    
    def get_real_oneweb_tle(self, date: str = "20250908", satellite_count: int = 5) -> List[Dict]:
        """
        ç²å–çœŸå¯¦çš„OneWeb TLEæ•¸æ“š
        
        Args:
            date: TLEæ•¸æ“šæ—¥æœŸ (YYYYMMDD)
            satellite_count: è¿”å›çš„è¡›æ˜Ÿæ•¸é‡ (é»˜èª5é¡†ç”¨æ–¼æ¸¬è©¦)
            
        Returns:
            List[Dict]: TLEæ•¸æ“šå­—å…¸åˆ—è¡¨
        """
        tle_file = self.oneweb_tle_dir / f"oneweb_{date}.tle"
        
        if not tle_file.exists():
            raise FileNotFoundError(f"TLEæ–‡ä»¶ä¸å­˜åœ¨: {tle_file}")
            
        tle_data = []
        with open(tle_file, 'r') as f:
            lines = f.readlines()
            
        # è§£æTLEæ•¸æ“š
        for i in range(0, min(len(lines), satellite_count * 3), 3):
            if i + 2 < len(lines):
                tle_entry = self._parse_tle_lines(
                    lines[i].strip(),
                    lines[i+1].strip(),
                    lines[i+2].strip()
                )
                if tle_entry:
                    tle_data.append(tle_entry)
                    
        return tle_data[:satellite_count]
    
    def get_mixed_constellation_tle(self, starlink_count: int = 8, oneweb_count: int = 2) -> List[Dict]:
        """
        ç²å–æ··åˆæ˜Ÿåº§çš„TLEæ•¸æ“š (Starlink + OneWeb)
        
        Args:
            starlink_count: Starlinkè¡›æ˜Ÿæ•¸é‡
            oneweb_count: OneWebè¡›æ˜Ÿæ•¸é‡
            
        Returns:
            List[Dict]: æ··åˆTLEæ•¸æ“šåˆ—è¡¨
        """
        starlink_data = self.get_real_starlink_tle(satellite_count=starlink_count)
        oneweb_data = self.get_real_oneweb_tle(satellite_count=oneweb_count)
        
        # æ¨™è¨˜æ˜Ÿåº§é¡å‹
        for tle in starlink_data:
            tle['constellation'] = 'STARLINK'
            
        for tle in oneweb_data:
            tle['constellation'] = 'ONEWEB'
            
        return starlink_data + oneweb_data
    
    def _parse_tle_lines(self, line0: str, line1: str, line2: str) -> Optional[Dict]:
        """
        è§£æTLEä¸‰è¡Œæ•¸æ“š
        
        Args:
            line0: è¡›æ˜Ÿåç¨±è¡Œ
            line1: TLEç¬¬ä¸€è¡Œ  
            line2: TLEç¬¬äºŒè¡Œ
            
        Returns:
            Dict: è§£æå¾Œçš„TLEæ•¸æ“š
        """
        try:
            # é©—è­‰TLEæ ¼å¼
            if not line1.startswith('1 ') or not line2.startswith('2 '):
                return None
                
            # è§£æåŸºæœ¬ä¿¡æ¯
            satellite_number = int(line1[2:7])
            classification = line1[7]
            international_designator = line1[9:17].strip()
            
            # è§£æepochæ™‚é–“
            epoch_year = int(line1[18:20])
            if epoch_year < 50:
                epoch_year += 2000
            else:
                epoch_year += 1900
            epoch_day = float(line1[20:32])
            
            # è¨ˆç®—epochæ™‚é–“æˆ³
            epoch_date = datetime(epoch_year, 1, 1, tzinfo=timezone.utc) + \
                        timedelta(days=epoch_day - 1)
            
            # è§£æè»Œé“åƒæ•¸
            inclination = float(line2[8:16])
            raan = float(line2[17:25])  # å‡äº¤é»èµ¤ç¶“
            eccentricity = float('0.' + line2[26:33])
            arg_perigee = float(line2[34:42])  # è¿‘åœ°é»è§’è·
            mean_anomaly = float(line2[43:51])  # å¹³å‡è¿‘é»è§’  
            mean_motion = float(line2[52:63])  # å¹³å‡é‹å‹•
            revolution_number = int(line2[63:68])
            
            return {
                # ğŸš¨ é—œéµï¼šæ·»åŠ Stage 1è™•ç†å™¨æœŸæœ›çš„æ‰€æœ‰å­—æ®µ
                'name': line0,  # è¡›æ˜Ÿåç¨±
                'satellite_name': line0,
                'line0': line0,
                'line1': line1,
                'line2': line2,
                'tle_line1': line1,
                'tle_line2': line2,
                'satellite_number': satellite_number,
                'norad_id': str(satellite_number),  # NORAD ID
                'classification': classification,
                'international_designator': international_designator,
                'epoch_year': epoch_year,
                'epoch_day': epoch_day,
                'epoch_datetime': epoch_date,
                'inclination': inclination,
                'raan': raan,
                'eccentricity': eccentricity,
                'arg_perigee': arg_perigee,
                'mean_anomaly': mean_anomaly,
                'mean_motion': mean_motion,
                'revolution_number': revolution_number,
                'data_source': f'Real TLE data from {line0}',
                'is_real_data': True  # ğŸš¨ é‡è¦ï¼šæ¨™è¨˜ç‚ºçœŸå¯¦æ•¸æ“š
            }
            
        except Exception as e:
            print(f"TLEè§£æéŒ¯èª¤: {e}")
            return None
    
    def get_tle_epoch_time(self, tle_data: Dict) -> datetime:
        """
        ç²å–TLEæ•¸æ“šçš„epochæ™‚é–“ - é€™æ˜¯SGP4è¨ˆç®—çš„æ­£ç¢ºæ™‚é–“åŸºæº–
        
        Args:
            tle_data: TLEæ•¸æ“šå­—å…¸
            
        Returns:
            datetime: TLE epochæ™‚é–“ (UTC)
        """
        return tle_data['epoch_datetime']
    
    def validate_real_data(self, tle_data: List[Dict]) -> bool:
        """
        é©—è­‰TLEæ•¸æ“šç¢ºå¯¦æ˜¯çœŸå¯¦æ•¸æ“šï¼Œä¸æ˜¯æ¨¡æ“¬æ•¸æ“š
        
        Args:
            tle_data: TLEæ•¸æ“šåˆ—è¡¨
            
        Returns:
            bool: æ˜¯å¦ç‚ºçœŸå¯¦æ•¸æ“š
        """
        for tle in tle_data:
            # æª¢æŸ¥æ˜¯å¦æ¨™è¨˜ç‚ºçœŸå¯¦æ•¸æ“š
            if not tle.get('is_real_data', False):
                return False
                
            # æª¢æŸ¥æ•¸æ“šä¾†æºä¸åŒ…å«ç¦ç”¨é—œéµå­—
            data_source = tle.get('data_source', '').lower()
            forbidden_patterns = ['mock', 'fake', 'random', 'simulated', 'test']
            
            for pattern in forbidden_patterns:
                if pattern in data_source:
                    return False
                    
        return True
    
    def create_test_dataset(self, output_file: str = None) -> Dict:
        """
        å‰µå»ºæ¨™æº–æ¸¬è©¦æ•¸æ“šé›†ï¼Œä¿å­˜ç‚ºJSONæ–‡ä»¶
        
        Args:
            output_file: è¼¸å‡ºæ–‡ä»¶è·¯å¾„ (å¯é¸)
            
        Returns:
            Dict: æ¸¬è©¦æ•¸æ“šé›†
        """
        dataset = {
            'created_at': datetime.now(timezone.utc).isoformat(),
            'data_date': '2025-09-08',
            'description': 'çœŸå¯¦TLEæ•¸æ“šæ¸¬è©¦é›† - å­¸è¡“ç´šæ¨™æº–',
            'starlink_satellites': self.get_real_starlink_tle(satellite_count=10),
            'oneweb_satellites': self.get_real_oneweb_tle(satellite_count=5),
            'mixed_constellation': self.get_mixed_constellation_tle(8, 2),
            'validation': {
                'is_real_data': True,
                'data_source_verified': True,
                'academic_compliance': True
            }
        }
        
        if output_file:
            output_path = Path(output_file)
            output_path.parent.mkdir(parents=True, exist_ok=True)
            
            with open(output_path, 'w', encoding='utf-8') as f:
                json.dump(dataset, f, indent=2, default=str, ensure_ascii=False)
                
        return dataset

# ä¾¿åˆ©å‡½æ•¸
def load_test_tle_data(constellation: str = "mixed", count: int = 10) -> List[Dict]:
    """
    ä¾¿åˆ©å‡½æ•¸ï¼šå¿«é€Ÿè¼‰å…¥æ¸¬è©¦TLEæ•¸æ“š
    
    Args:
        constellation: æ˜Ÿåº§é¡å‹ ('starlink', 'oneweb', 'mixed')
        count: è¡›æ˜Ÿæ•¸é‡
        
    Returns:
        List[Dict]: TLEæ•¸æ“šåˆ—è¡¨
    """
    loader = TLETestDataLoader()
    
    if constellation.lower() == 'starlink':
        return loader.get_real_starlink_tle(satellite_count=count)
    elif constellation.lower() == 'oneweb':
        return loader.get_real_oneweb_tle(satellite_count=count)
    elif constellation.lower() == 'mixed':
        starlink_count = max(1, count * 4 // 5)  # 80% Starlink
        oneweb_count = count - starlink_count     # 20% OneWeb
        return loader.get_mixed_constellation_tle(starlink_count, oneweb_count)
    else:
        raise ValueError(f"ä¸æ”¯æŒçš„æ˜Ÿåº§é¡å‹: {constellation}")

def get_tle_epoch_time(tle_data: Dict) -> datetime:
    """
    ç²å–TLE epochæ™‚é–“ - SGP4è¨ˆç®—çš„æ­£ç¢ºæ™‚é–“åŸºæº–
    
    ğŸš¨ é‡è¦ï¼šçµ•å°ä¸èƒ½ä½¿ç”¨ datetime.now() é€²è¡Œè»Œé“è¨ˆç®—ï¼
    å¿…é ˆä½¿ç”¨TLEæ•¸æ“šçš„epochæ™‚é–“ä½œç‚ºè¨ˆç®—åŸºæº–ã€‚
    """
    return tle_data['epoch_datetime']