"""
Stage 1 Processor - è»Œé“è¨ˆç®—è™•ç†å™¨ (é‡æ§‹ç‰ˆ)

é€™æ˜¯é‡æ§‹å¾Œçš„Stage 1è™•ç†å™¨ï¼Œç¹¼æ‰¿è‡ªBaseStageProcessorï¼Œ
æä¾›æ¨¡çµ„åŒ–ã€å¯é™¤éŒ¯çš„è»Œé“è¨ˆç®—åŠŸèƒ½ã€‚

ä¸»è¦æ”¹é€²ï¼š
1. æ¨¡çµ„åŒ–è¨­è¨ˆ - æ‹†åˆ†ç‚ºå¤šå€‹å°ˆè²¬çµ„ä»¶
2. çµ±ä¸€æ¥å£ - ç¬¦åˆBaseStageProcessorè¦ç¯„
3. å¯é™¤éŒ¯æ€§ - æ”¯æ´å–®éšæ®µåŸ·è¡Œå’Œæ•¸æ“šæ³¨å…¥
4. å­¸è¡“æ¨™æº– - ä¿æŒGrade Aç´šåˆ¥çš„è¨ˆç®—ç²¾åº¦

ğŸ”§ Phase 1Aé‡æ§‹ (v7.0):
5. è·è²¬é‚Šç•Œæ¸…æ™° - ç§»é™¤è§€æ¸¬è€…è¨ˆç®—åŠŸèƒ½ (ç§»è‡³Stage 2)
6. è»Œé“ç›¸ä½åˆ†æ - æ•´åˆTemporalSpatialAnalysisEngineçš„18å€‹ç›¸ä½åˆ†ææ–¹æ³•
7. ç´”ECIè¼¸å‡º - åš´æ ¼éµå¾ªStage 1è·è²¬ç¯„åœ

é‡æ§‹ç›®æ¨™ï¼š
- åš´æ ¼éµå¾ªSTAGE_RESPONSIBILITIES.mdå®šç¾©çš„è·è²¬é‚Šç•Œ
- åªè² è²¬TLEè¼‰å…¥å’ŒSGP4è»Œé“è¨ˆç®—ï¼Œè¼¸å‡ºç´”ECIåº§æ¨™
- ç§»é™¤è¶Šç•ŒåŠŸèƒ½ï¼šè§€æ¸¬è€…è¨ˆç®— â†’ Stage 2
"""

import json
import logging
import math
import gzip
from typing import Dict, Any, Optional, List
from pathlib import Path
from datetime import datetime, timezone

# å°å…¥åŸºç¤è™•ç†å™¨
import sys
sys.path.insert(0, str(Path(__file__).parent.parent.parent))
from shared.base_processor import BaseStageProcessor

# å°å…¥Stage 1å°ˆç”¨çµ„ä»¶
from .tle_data_loader import TLEDataLoader
# ğŸ”„ v2.0: è»Œé“è¨ˆç®—å™¨å·²ç§»è‡³ Stage 2
# from .orbital_calculator import OrbitalCalculator  # å·²æ£„ç”¨
from .orbital_validation_engine import OrbitalValidationEngine

logger = logging.getLogger(__name__)

import time

class Stage1TLEProcessor(BaseStageProcessor):
    """
    ğŸ”„ Stage 1: TLEæ•¸æ“šè¼‰å…¥å±¤è™•ç†å™¨ (v2.0 é‡æ§‹ç‰ˆ)
    
    ğŸ“‹ è·è²¬ç¯„åœ (ç¬¦åˆæ–‡æª”v2.0è¦ç¯„):
    1. âœ… TLEæ•¸æ“šè¼‰å…¥å’Œè§£æ
    2. âœ… æ•¸æ“šæ ¼å¼é©—è­‰å’Œå®Œæ•´æ€§æª¢æŸ¥  
    3. âœ… æ™‚é–“åŸºæº–æ¨™æº–åŒ–
    4. âœ… ç‚ºStage 2æä¾›æ¸…æ½”çš„æ•¸æ“šè¼¸å‡º
    
    âŒ ä¸å†åŒ…å«:
    - è»Œé“è¨ˆç®— (ç§»è‡³Stage 2)
    - SGP4ä½ç½®è¨ˆç®— (ç§»è‡³Stage 2)
    - å¯è¦‹æ€§åˆ†æ (ç§»è‡³Stage 2)
    """

    def __init__(self, config: Optional[Dict[str, Any]] = None):
        super().__init__(stage_number=1, stage_name="tle_data_loading", config=config or {})

        # ğŸ”§ v2.0 é…ç½®åƒæ•¸
        self.sample_mode = self.config.get('sample_mode', False)
        self.sample_size = self.config.get('sample_size', 100)
        self.validate_tle_epoch = self.config.get('validate_tle_epoch', True)

        # ğŸ—ï¸ v2.0 æ¨¡çµ„åŒ–çµ„ä»¶ (ç¬¦åˆæ–‡æª”è¨­è¨ˆ)
        try:
            from .tle_data_loader import TLEDataLoader
            from .data_validator import DataValidator
            from .time_reference_manager import TimeReferenceManager
            
            self.tle_loader = TLEDataLoader()
            self.data_validator = DataValidator(self.config)  
            self.time_reference_manager = TimeReferenceManager(self.config)
            
        except ImportError as e:
            self.logger.error(f"âŒ v2.0çµ„ä»¶è¼‰å…¥å¤±æ•—: {e}")
            # å‰µå»ºåŸºæœ¬å¯¦ä¾‹é¿å…éŒ¯èª¤
            self.tle_loader = None
            self.data_validator = None
            self.time_reference_manager = None

        # ğŸ”„ v2.0 é©—è­‰å¼•æ“
        try:
            from shared.validation_framework.validation_engine import ValidationEngine
            self.validation_engine = ValidationEngine('stage1_data_loading')
        except ImportError:
            self.validation_engine = None

        # ğŸ“Š è™•ç†çµ±è¨ˆ
        self.processing_stats = {
            'total_files_scanned': 0,
            'total_satellites_loaded': 0,
            'validation_failures': 0,
            'time_reference_issues': 0,
            'data_quality_score': 0.0
        }

        self.logger.info("ğŸ”„ Stage 1 TLEæ•¸æ“šè¼‰å…¥è™•ç†å™¨å·²åˆå§‹åŒ– (v2.0æ¶æ§‹)")

    def scan_tle_data(self) -> List[str]:
        """æƒæTLEæ•¸æ“šæ–‡ä»¶"""
        if not self.tle_loader:
            self.logger.error("âŒ TLEè¼‰å…¥å™¨æœªåˆå§‹åŒ–")
            return []
            
        try:
            tle_files = self.tle_loader.scan_tle_data()
            self.processing_stats['total_files_scanned'] = len(tle_files)
            return tle_files
        except Exception as e:
            self.logger.error(f"âŒ TLEæ•¸æ“šæƒæå¤±æ•—: {e}")
            return []

    def load_raw_satellite_data(self, tle_files: List[str]) -> List[Dict[str, Any]]:
        """è¼‰å…¥åŸå§‹è¡›æ˜Ÿæ•¸æ“š"""
        if not self.tle_loader:
            self.logger.error("âŒ TLEè¼‰å…¥å™¨æœªåˆå§‹åŒ–")
            return []
            
        try:
            satellite_data = self.tle_loader.load_satellite_data(tle_files)
            
            # ğŸ¯ æ¨£æœ¬æ¨¡å¼è™•ç†
            if self.sample_mode and len(satellite_data) > self.sample_size:
                self.logger.info(f"ğŸ¯ æ¨£æœ¬æ¨¡å¼: å¾{len(satellite_data)}é¡†è¡›æ˜Ÿä¸­é¸å–{self.sample_size}é¡†")
                satellite_data = satellite_data[:self.sample_size]
            
            self.processing_stats['total_satellites_loaded'] = len(satellite_data)
            return satellite_data
            
        except Exception as e:
            self.logger.error(f"âŒ è¡›æ˜Ÿæ•¸æ“šè¼‰å…¥å¤±æ•—: {e}")
            return []

    def process_tle_data_loading(self) -> Dict[str, Any]:
        """
        ğŸ”„ v2.0ä¸»è¦è™•ç†æ–¹æ³•ï¼šç´”æ•¸æ“šè¼‰å…¥æµç¨‹
        
        Returns:
            åŒ…å«è¼‰å…¥å’Œé©—è­‰çš„TLEæ•¸æ“šçš„å­—å…¸
        """
        start_time = datetime.now(timezone.utc)
        self.logger.info("ğŸš€ é–‹å§‹Stage 1 TLEæ•¸æ“šè¼‰å…¥è™•ç†...")

        try:
            # 1ï¸âƒ£ æƒæTLEæ–‡ä»¶
            tle_files = self.scan_tle_data()
            if not tle_files:
                raise ValueError("æœªæ‰¾åˆ°TLEæ•¸æ“šæ–‡ä»¶")

            # 2ï¸âƒ£ è¼‰å…¥åŸå§‹æ•¸æ“š  
            raw_data = self.load_raw_satellite_data(tle_files)
            if not raw_data:
                raise ValueError("TLEæ•¸æ“šè¼‰å…¥å¤±æ•—")

            # 3ï¸âƒ£ æ•¸æ“šé©—è­‰
            if self.data_validator:
                validation_result = self.data_validator.validate_tle_dataset(raw_data)
                if not validation_result.get('is_valid', False):
                    self.processing_stats['validation_failures'] = len(validation_result.get('errors', []))
                    self.logger.warning(f"âš ï¸ æ•¸æ“šé©—è­‰ç™¼ç¾ {self.processing_stats['validation_failures']} å€‹å•é¡Œ")

            # 4ï¸âƒ£ æ™‚é–“åŸºæº–æ¨™æº–åŒ–
            if self.time_reference_manager:
                time_reference_result = self.time_reference_manager.establish_time_reference(raw_data)
                standardized_data = time_reference_result.get('standardized_data', raw_data)
                
                if not time_reference_result.get('time_reference_established', False):
                    self.processing_stats['time_reference_issues'] = len(raw_data)
                    self.logger.warning("âš ï¸ æ™‚é–“åŸºæº–å»ºç«‹éƒ¨åˆ†å¤±æ•—")
            else:
                standardized_data = raw_data

            # 5ï¸âƒ£ æ•¸æ“šå“è³ªè©•ä¼°
            self.processing_stats['data_quality_score'] = self._assess_data_quality(standardized_data)

            # ğŸ“Š è™•ç†çµæœæ§‹å»º
            processing_duration = datetime.now(timezone.utc) - start_time
            
            result = {
                'stage': 'tle_data_loading',
                'stage_name': 'TLEæ•¸æ“šè¼‰å…¥å±¤',
                'satellites': standardized_data,
                'metadata': {
                    'total_satellites': len(standardized_data),
                    'processing_start_time': start_time.isoformat(),
                    'processing_end_time': datetime.now(timezone.utc).isoformat(),
                    'processing_duration_seconds': processing_duration.total_seconds(),
                    'files_processed': len(tle_files),
                    'data_quality_score': self.processing_stats['data_quality_score'],
                    'constellations': self._analyze_constellations(standardized_data),
                    
                    # ğŸ¯ v2.0 æ™‚é–“åŸºæº–è¼¸å‡º (ç¬¦åˆæ–‡æª”è¦æ±‚)
                    'calculation_base_time': self._extract_calculation_base_time(standardized_data),
                    'tle_epoch_time': self._extract_tle_epoch_time(standardized_data),
                    'time_base_source': 'tle_epoch_derived',
                    'tle_epoch_compliance': True,
                    'stage1_time_inheritance': {
                        'exported_time_base': self._extract_calculation_base_time(standardized_data),
                        'inheritance_ready': True,
                        'calculation_reference': 'tle_epoch_based'
                    }
                },
                'processing_stats': self.processing_stats
            }

            self.logger.info(f"âœ… Stage 1 TLEæ•¸æ“šè¼‰å…¥å®Œæˆ: {len(standardized_data)}é¡†è¡›æ˜Ÿ")
            return result

        except Exception as e:
            self.logger.error(f"âŒ Stage 1 TLEæ•¸æ“šè¼‰å…¥å¤±æ•—: {e}")
            return {
                'stage': 'tle_data_loading',
                'satellites': [],
                'error': str(e),
                'processing_stats': self.processing_stats,
                'metadata': {
                    'processing_start_time': start_time.isoformat(),
                    'processing_end_time': datetime.now(timezone.utc).isoformat(),
                    'status': 'ERROR'
                }
            }

    def _assess_data_quality(self, data: List[Dict]) -> float:
        """è©•ä¼°æ•¸æ“šå“è³ªåˆ†æ•¸ (0-100)"""
        if not data:
            return 0.0
            
        quality_factors = []
        
        # TLEæ ¼å¼å®Œæ•´æ€§
        format_score = sum(1 for d in data if all(k in d for k in ['satellite_id', 'line1', 'line2', 'name'])) / len(data)
        quality_factors.append(format_score)
        
        # æ™‚é–“åŸºæº–ä¸€è‡´æ€§
        time_score = sum(1 for d in data if 'epoch_datetime' in d) / len(data)
        quality_factors.append(time_score)
        
        # æ•¸æ“šå¤šæ¨£æ€§ (æ˜Ÿåº§è¦†è“‹)
        constellations = set(d.get('constellation', 'unknown').lower() for d in data)
        diversity_score = min(len(constellations) / 2.0, 1.0)  # æœŸæœ›è‡³å°‘2å€‹æ˜Ÿåº§
        quality_factors.append(diversity_score)
        
        return sum(quality_factors) / len(quality_factors) * 100

    def _analyze_constellations(self, data: List[Dict]) -> Dict[str, Dict]:
        """åˆ†ææ˜Ÿåº§åˆ†å¸ƒ"""
        constellations = {}
        
        for satellite in data:
            constellation = satellite.get('constellation', 'unknown').lower()
            if constellation not in constellations:
                constellations[constellation] = {
                    'satellite_count': 0,
                    'sample_satellites': []
                }
            
            constellations[constellation]['satellite_count'] += 1
            if len(constellations[constellation]['sample_satellites']) < 3:
                constellations[constellation]['sample_satellites'].append({
                    'satellite_id': satellite.get('satellite_id'),
                    'name': satellite.get('name', 'Unknown')
                })
        
        return constellations

    def _extract_calculation_base_time(self, data: List[Dict]) -> str:
        """æå–è¨ˆç®—åŸºæº–æ™‚é–“ (TLE epochæ™‚é–“)"""
        if not data:
            return datetime.now(timezone.utc).isoformat()
            
        # ä½¿ç”¨æœ€æ–°çš„TLE epochæ™‚é–“ä½œç‚ºè¨ˆç®—åŸºæº–
        epoch_times = []
        for satellite in data:
            epoch_time = satellite.get('epoch_datetime')
            if epoch_time:
                try:
                    if isinstance(epoch_time, str):
                        parsed_time = datetime.fromisoformat(epoch_time.replace('Z', '+00:00'))
                    else:
                        parsed_time = epoch_time
                    epoch_times.append(parsed_time)
                except:
                    continue
        
        if epoch_times:
            # ä½¿ç”¨æœ€æ–°çš„epochæ™‚é–“
            latest_epoch = max(epoch_times)
            return latest_epoch.isoformat()
        else:
            return datetime.now(timezone.utc).isoformat()

    def _extract_tle_epoch_time(self, data: List[Dict]) -> str:
        """æå–TLE epochæ™‚é–“"""
        return self._extract_calculation_base_time(data)  # åœ¨v2.0æ¶æ§‹ä¸­å…©è€…ç›¸åŒ

    def validate_input(self, input_data: Any) -> Dict[str, Any]:
        """é©—è­‰è¼¸å…¥æ•¸æ“š (v2.0ç‰ˆæœ¬ - æ•¸æ“šè¼‰å…¥å°ˆç”¨)"""
        validation_result = {
            'is_valid': True,
            'errors': [],
            'warnings': []
        }

        # åŸºæœ¬æ ¼å¼æª¢æŸ¥
        if input_data is not None:
            if not isinstance(input_data, dict):
                validation_result['errors'].append("è¼¸å…¥æ•¸æ“šå¿…é ˆæ˜¯å­—å…¸æ ¼å¼æˆ–None")
                validation_result['is_valid'] = False

        return validation_result

    def process(self, input_data: Any = None) -> Dict[str, Any]:
        """
        ğŸ”„ v2.0çµ±ä¸€è™•ç†ä»‹é¢
        
        Args:
            input_data: è¼¸å…¥æ•¸æ“š (å¯é¸ï¼Œå°‡è‡ªå‹•è¼‰å…¥TLEæ–‡ä»¶)
            
        Returns:
            è™•ç†çµæœå­—å…¸
        """
        # è¼¸å…¥é©—è­‰
        validation = self.validate_input(input_data)
        if not validation['is_valid']:
            return {
                'stage': 'tle_data_loading',
                'error': '; '.join(validation['errors']),
                'satellites': [],
                'processing_stats': self.processing_stats
            }

        # åŸ·è¡Œæ•¸æ“šè¼‰å…¥æµç¨‹
        return self.process_tle_data_loading()

    def validate_output(self, output_data: Dict[str, Any]) -> Dict[str, Any]:
        """é©—è­‰è¼¸å‡ºæ•¸æ“š (v2.0ç‰ˆæœ¬ - æ•¸æ“šè¼‰å…¥å°ˆç”¨)"""
        validation_result = {
            'is_valid': True,
            'errors': [],
            'warnings': []
        }

        # æª¢æŸ¥å¿…è¦å­—æ®µ
        required_fields = ['stage', 'satellites', 'metadata']
        for field in required_fields:
            if field not in output_data:
                validation_result['errors'].append(f"ç¼ºå°‘å¿…è¦å­—æ®µ: {field}")

        # æª¢æŸ¥éšæ®µæ¨™è­˜
        if output_data.get('stage') != 'tle_data_loading':
            validation_result['errors'].append("éšæ®µæ¨™è­˜éŒ¯èª¤ï¼Œæ‡‰ç‚º 'tle_data_loading'")

        # æª¢æŸ¥è¡›æ˜Ÿæ•¸æ“š
        satellites = output_data.get('satellites', [])
        if not isinstance(satellites, list):
            validation_result['errors'].append("è¡›æ˜Ÿæ•¸æ“šå¿…é ˆæ˜¯åˆ—è¡¨æ ¼å¼")
        elif len(satellites) == 0:
            validation_result['warnings'].append("è¡›æ˜Ÿæ•¸æ“šç‚ºç©º")

        # v2.0 æ™‚é–“åŸºæº–æª¢æŸ¥
        metadata = output_data.get('metadata', {})
        if 'calculation_base_time' not in metadata:
            validation_result['errors'].append("ç¼ºå°‘calculation_base_time")
        if metadata.get('time_base_source') != 'tle_epoch_derived':
            validation_result['warnings'].append("æ™‚é–“åŸºæº–ä¾†æºä¸æ˜¯tle_epoch_derived")

        validation_result['is_valid'] = len(validation_result['errors']) == 0
        return validation_result

    def extract_key_metrics(self, results: Dict[str, Any] = None) -> Dict[str, Any]:
        """æå–é—œéµæŒ‡æ¨™"""
        return {
            'stage': 'tle_data_loading',
            'satellites_loaded': self.processing_stats['total_satellites_loaded'],
            'files_scanned': self.processing_stats['total_files_scanned'],
            'validation_failures': self.processing_stats['validation_failures'],
            'time_reference_issues': self.processing_stats['time_reference_issues'],
            'data_quality_score': self.processing_stats['data_quality_score'],
            'success_rate': (
                (self.processing_stats['total_satellites_loaded'] - self.processing_stats['validation_failures'])
                / max(1, self.processing_stats['total_satellites_loaded'])
            ) * 100 if self.processing_stats['total_satellites_loaded'] > 0 else 0
        }

    def run_validation_checks(self, data: Any) -> Dict[str, Any]:
        """
        ğŸ”„ v2.0é©—è­‰æª¢æŸ¥ (å°ˆç‚ºæ•¸æ“šè¼‰å…¥è¨­è¨ˆ)
        """
        try:
            if isinstance(data, dict) and 'satellites' in data:
                satellite_data = data['satellites']
            elif isinstance(data, list):
                satellite_data = data
            else:
                return {
                    'validation_status': 'failed',
                    'overall_status': 'FAIL',
                    'stage_compliance': False,
                    'academic_standards': False,
                    'error_message': 'è¼¸å…¥æ•¸æ“šæ ¼å¼éŒ¯èª¤',
                    'timestamp': datetime.now(timezone.utc).isoformat()
                }

            # ğŸ” æ•¸æ“šè¼‰å…¥å°ˆç”¨é©—è­‰é …ç›®
            validation_checks = {
                'tle_format_validation': self._check_tle_format(satellite_data),
                'data_completeness_check': self._check_data_completeness(satellite_data),
                'time_reference_check': self._check_time_reference(satellite_data),
                'constellation_coverage_check': self._check_constellation_coverage(satellite_data)
            }

            # è¨ˆç®—ç¸½é«”ç‹€æ…‹
            passed_checks = sum(1 for check in validation_checks.values() if check)
            total_checks = len(validation_checks)
            overall_status = 'PASS' if passed_checks >= total_checks * 0.8 else 'FAIL'  # 80%é€šéç‡

            return {
                'validation_status': 'passed' if overall_status == 'PASS' else 'failed',
                'overall_status': overall_status,
                'checks_performed': list(validation_checks.keys()),
                'stage_compliance': overall_status == 'PASS',
                'academic_standards': passed_checks >= total_checks * 0.9,  # 90%ç‚ºå­¸è¡“æ¨™æº–
                'detailed_results': validation_checks,
                'checks_passed': passed_checks,
                'total_checks': total_checks,
                'timestamp': datetime.now(timezone.utc).isoformat()
            }

        except Exception as e:
            self.logger.error(f"âŒ é©—è­‰æª¢æŸ¥å¤±æ•—: {e}")
            return {
                'validation_status': 'error',
                'overall_status': 'ERROR',
                'stage_compliance': False,
                'academic_standards': False,
                'error_message': str(e),
                'timestamp': datetime.now(timezone.utc).isoformat()
            }

    def _check_tle_format(self, satellite_data: List[Dict]) -> bool:
        """æª¢æŸ¥TLEæ ¼å¼å®Œæ•´æ€§"""
        if not satellite_data:
            return False
            
        required_fields = ['satellite_id', 'line1', 'line2', 'name']
        valid_count = 0
        
        for satellite in satellite_data:
            if all(field in satellite and satellite[field] for field in required_fields):
                line1, line2 = satellite['line1'], satellite['line2']
                if len(line1) == 69 and len(line2) == 69 and line1[0] == '1' and line2[0] == '2':
                    valid_count += 1
        
        return valid_count >= len(satellite_data) * 0.95  # 95%æ ¼å¼æ­£ç¢ºç‡

    def _check_data_completeness(self, satellite_data: List[Dict]) -> bool:
        """æª¢æŸ¥æ•¸æ“šå®Œæ•´æ€§"""
        if not satellite_data:
            return False
            
        # æª¢æŸ¥æœ€å°æ•¸æ“šé‡ (è‡³å°‘100é¡†è¡›æ˜Ÿ)
        if len(satellite_data) < 100:
            return False
            
        # æª¢æŸ¥æ•¸æ“šå­—æ®µå®Œæ•´æ€§
        complete_records = sum(1 for s in satellite_data 
                             if all(k in s for k in ['satellite_id', 'name', 'line1', 'line2']))
        
        return complete_records >= len(satellite_data) * 0.98  # 98%å®Œæ•´ç‡

    def _check_time_reference(self, satellite_data: List[Dict]) -> bool:
        """æª¢æŸ¥æ™‚é–“åŸºæº–å»ºç«‹"""
        if not satellite_data:
            return False
            
        time_valid_count = sum(1 for s in satellite_data if 'epoch_datetime' in s)
        return time_valid_count >= len(satellite_data) * 0.90  # 90%æ™‚é–“è§£ææˆåŠŸç‡

    def _check_constellation_coverage(self, satellite_data: List[Dict]) -> bool:
        """æª¢æŸ¥æ˜Ÿåº§è¦†è“‹åº¦"""
        if not satellite_data:
            return False
            
        constellations = set()
        for satellite in satellite_data:
            name = satellite.get('name', '').lower()
            if 'starlink' in name:
                constellations.add('starlink')
            elif 'oneweb' in name:
                constellations.add('oneweb')
                
        return len(constellations) >= 2  # è‡³å°‘åŒ…å«å…©å€‹ä¸»è¦æ˜Ÿåº§

    def save_results(self, results: Dict[str, Any]) -> str:
        """
        ğŸ”„ v2.0ä¿å­˜çµæœ (ç¬¦åˆæ–‡æª”å‘½åè¦ç¯„)
        
        æ–‡æª”è¦æ±‚: /app/data/tle_orbital_calculation_output.json
        """
        try:
            # ğŸ“ ä½¿ç”¨æ–‡æª”è¦ç¯„çš„è¼¸å‡ºè·¯å¾‘å’Œå‘½å
            output_filename = "tle_orbital_calculation_output.json"
            output_path = self.output_dir / output_filename

            # ç¢ºä¿è¼¸å‡ºç›®éŒ„å­˜åœ¨
            self.output_dir.mkdir(parents=True, exist_ok=True)

            # ä¿å­˜çµæœ
            import json
            with open(output_path, 'w', encoding='utf-8') as f:
                json.dump(results, f, indent=2, ensure_ascii=False, default=str)

            self.logger.info(f"âœ… Stage 1 çµæœå·²ä¿å­˜è‡³: {output_path}")
            return str(output_path)

        except Exception as e:
            self.logger.error(f"âŒ ä¿å­˜çµæœå¤±æ•—: {e}")
            raise RuntimeError(f"Stage 1 çµæœä¿å­˜å¤±æ•—: {e}")

    def execute(self, input_data: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
        """
        ğŸ”„ v2.0åŸ·è¡Œä»‹é¢ (èˆ‡å…­éšæ®µç³»çµ±å…¼å®¹)
        
        Args:
            input_data: å¯é¸çš„è¼¸å…¥æ•¸æ“š
            
        Returns:
            è™•ç†çµæœå­—å…¸
        """
        try:
            # åŸ·è¡Œæ•¸æ“šè¼‰å…¥è™•ç†
            results = self.process(input_data)
            
            # ä¿å­˜çµæœ (å¦‚æœé…ç½®å…è¨±)
            if self.config.get('save_output', True):
                self.save_results(results)
            
            # ç”Ÿæˆé©—è­‰å¿«ç…§
            if self.config.get('generate_validation_snapshot', True):
                self.save_validation_snapshot(results)
            
            return results
            
        except Exception as e:
            self.logger.error(f"âŒ Stage 1 åŸ·è¡Œå¤±æ•—: {e}")
            return {
                'stage': 'tle_data_loading',
                'error': str(e),
                'satellites': [],
                'processing_stats': self.processing_stats,
                'metadata': {
                    'status': 'ERROR',
                    'error_message': str(e),
                    'timestamp': datetime.now(timezone.utc).isoformat()
                }
            }

    def save_validation_snapshot(self, results: Dict[str, Any]) -> None:
        """ä¿å­˜é©—è­‰å¿«ç…§ (ç¬¦åˆæ–‡æª”è¦ç¯„)"""
        try:
            # ğŸ“ é©—è­‰å¿«ç…§ç›®éŒ„
            validation_dir = self.output_dir / "validation_snapshots"
            validation_dir.mkdir(parents=True, exist_ok=True)
            
            snapshot_path = validation_dir / "stage1_validation.json"
            
            # æ§‹å»ºé©—è­‰å¿«ç…§
            snapshot = {
                'stage': 1,
                'stage_name': 'tle_data_loading',
                'timestamp': datetime.now(timezone.utc).isoformat(),
                'summary': {
                    'total_satellites': len(results.get('satellites', [])),
                    'processing_success': 'error' not in results,
                    'data_quality_score': results.get('processing_stats', {}).get('data_quality_score', 0),
                },
                'validation_results': self.run_validation_checks(results),
                'key_metrics': self.extract_key_metrics(results),
                'metadata': results.get('metadata', {})
            }
            
            import json
            with open(snapshot_path, 'w', encoding='utf-8') as f:
                json.dump(snapshot, f, indent=2, ensure_ascii=False, default=str)
            
            self.logger.info(f"âœ… é©—è­‰å¿«ç…§å·²ä¿å­˜: {snapshot_path}")
            
        except Exception as e:
            self.logger.error(f"âŒ ä¿å­˜é©—è­‰å¿«ç…§å¤±æ•—: {e}")
