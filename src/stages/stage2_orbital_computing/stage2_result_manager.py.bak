#!/usr/bin/env python3
"""
Stage 2: çµæœç®¡ç†æ¨¡çµ„ (é‡æ§‹ç‰ˆæœ¬ - ä½¿ç”¨ BaseResultManager)

æ•´åˆåŸæœ‰çš„ Stage2ResultManager åŠŸèƒ½ï¼Œä½¿ç”¨ Template Method Pattern æ¶ˆé™¤ä»£ç¢¼é‡è¤‡ã€‚

æ”¯æ´æ ¼å¼ï¼š
- JSONï¼šå‘å¾Œå…¼å®¹ï¼Œæ˜“è®€æ€§é«˜
- HDF5ï¼šé«˜æ•ˆå£“ç¸®ï¼Œå­¸è¡“æ¨™æº–æ ¼å¼

Author: ORBIT Engine Team
Created: 2025-10-12 (Phase 3 Refactoring)
"""

import logging
import json
import os
import glob
import numpy as np
from datetime import datetime, timezone, timedelta
from typing import Dict, List, Any, Optional

# Phase 3 Refactoring: Import base class
from shared.base_result_manager import BaseResultManager

try:
    import h5py
    HDF5_AVAILABLE = True
except ImportError:
    HDF5_AVAILABLE = False
    logging.warning("âš ï¸ h5py æœªå®‰è£ï¼ŒHDF5 æ ¼å¼ä¸å¯ç”¨")


class Stage2ResultManager(BaseResultManager):
    """
    Stage 2 çµæœç®¡ç†å™¨ (é‡æ§‹ç‰ˆ)

    æ•´åˆåŠŸèƒ½:
    - âœ… çµæœæ§‹å»º (åŸ build_final_result())
    - âœ… JSON æ ¼å¼ä¿å­˜ (åŸºé¡æä¾›)
    - âœ… HDF5 æ ¼å¼ä¿å­˜ (Stage 2 å°ˆç”¨æ“´å±•)
    - âœ… é›™æ ¼å¼ä¿å­˜ (JSON + HDF5)
    - âœ… Stage 1 è¼¸å‡ºè¼‰å…¥ (Stage 2 å°ˆç”¨)
    - âœ… Metadata åˆä½µ (ä½¿ç”¨åŸºé¡å·¥å…·)

    é‡æ§‹äº®é»:
    - æ¶ˆé™¤ç›®éŒ„å‰µå»ºã€JSONä¿å­˜ã€æ™‚é–“æˆ³ç”Ÿæˆé‡è¤‡ä»£ç¢¼
    - ä½¿ç”¨åŸºé¡ metadata åˆä½µå·¥å…·
    - ä¿ç•™ HDF5 å°ˆç”¨é‚è¼¯ä½œç‚ºæ“´å±•
    - 100% å‘å¾Œå…¼å®¹
    """

    def __init__(self, logger_instance: Optional[logging.Logger] = None):
        """
        åˆå§‹åŒ– Stage 2 çµæœç®¡ç†å™¨

        Args:
            logger_instance: æ—¥èªŒè¨˜éŒ„å™¨
        """
        super().__init__(logger_instance=logger_instance)

    # ==================== Abstract Methods Implementation ====================

    def get_stage_number(self) -> int:
        """è¿”å›éšæ®µç·¨è™Ÿ"""
        return 2

    def get_stage_identifier(self) -> str:
        """è¿”å›éšæ®µè­˜åˆ¥å­—ä¸²"""
        return 'stage2_orbital_computing'

    def build_stage_results(self, **kwargs) -> Dict[str, Any]:
        """
        æ§‹å»º Stage 2 çµæœçµæ§‹ (é‡æ§‹è‡ª build_final_result())

        Args:
            **kwargs: å¿…éœ€åƒæ•¸
                - orbital_results: è»Œé“è¨ˆç®—çµæœ
                - start_time: è™•ç†é–‹å§‹æ™‚é–“
                - processing_time: è™•ç†è€—æ™‚
                - input_data: è¼¸å…¥æ•¸æ“š
                - processing_stats: è™•ç†çµ±è¨ˆ
                - coordinate_system: åº§æ¨™ç³»çµ±
                - propagation_method: å‚³æ’­æ–¹æ³•
                - time_interval_seconds: æ™‚é–“é–“éš”
                - dynamic_calculation: æ˜¯å¦å‹•æ…‹è¨ˆç®—
                - coverage_cycles: è¦†è“‹é€±æœŸ

        Returns:
            Stage 2 å®Œæ•´è¼¸å‡ºæ•¸æ“šçµæ§‹
        """
        # æå–åƒæ•¸
        orbital_results = kwargs.get('orbital_results', {})
        start_time = kwargs.get('start_time')
        processing_time = kwargs.get('processing_time')
        input_data = kwargs.get('input_data', {})
        processing_stats = kwargs.get('processing_stats', {})
        coordinate_system = kwargs.get('coordinate_system', 'TEME')
        propagation_method = kwargs.get('propagation_method', 'SGP4')
        time_interval_seconds = kwargs.get('time_interval_seconds', 60.0)
        dynamic_calculation = kwargs.get('dynamic_calculation', True)
        coverage_cycles = kwargs.get('coverage_cycles', 1.0)

        # æŒ‰æ˜Ÿåº§åˆ†çµ„çµ±è¨ˆ
        constellation_stats = {}
        satellites_by_constellation = {}

        for satellite_id, result in orbital_results.items():
            constellation = result.constellation
            if constellation not in constellation_stats:
                constellation_stats[constellation] = 0
                satellites_by_constellation[constellation] = {}

            constellation_stats[constellation] += 1
            # è½‰æ›ç‚ºè¦æ ¼æ ¼å¼
            orbital_states = []
            for pos in result.teme_positions:
                orbital_state = {
                    'timestamp': pos.timestamp,
                    'position_teme': [pos.x, pos.y, pos.z],  # TEME åº§æ¨™ (km)
                    'velocity_teme': [pos.vx, pos.vy, pos.vz],  # TEME é€Ÿåº¦ (km/s)
                    'satellite_id': satellite_id,
                    # âœ… Grade A æ¨™æº–: ç§»é™¤ä¼°è¨ˆèª¤å·®å€¼
                    # SGP4 èª¤å·®æ‡‰å¾ç®—æ³•å¯¦éš›è¨ˆç®—ç²å–ï¼Œä¸ä½¿ç”¨ç¡¬ç·¨ç¢¼ä¼°ç®—å€¼
                    # åƒè€ƒ: Vallado 2013, Table 3.2 - SGP4 ç²¾åº¦ç¯„åœ 0.5-5 km (è¦– TLE æ–°èˆŠè€Œå®š)
                }
                orbital_states.append(orbital_state)

            satellites_by_constellation[constellation][satellite_id] = {
                'satellite_id': satellite_id,
                'constellation': constellation,
                'epoch_datetime': result.epoch_datetime,
                'orbital_states': orbital_states,
                'propagation_successful': result.propagation_successful,
                'algorithm_used': result.algorithm_used,
                'coordinate_system': result.coordinate_system,
                'total_positions': len(result.teme_positions)
            }

        # è¨˜éŒ„çµ±è¨ˆä¿¡æ¯
        self.logger.info(f"ğŸ“Š æœ€çµ‚çµæœçµ±è¨ˆ:")
        for constellation, count in constellation_stats.items():
            self.logger.info(f"   {constellation}: {count} é¡†è¡›æ˜Ÿ")

        # âœ… ä½¿ç”¨åŸºé¡å·¥å…·åˆä½µ metadata
        upstream_metadata = input_data.get('metadata', {})
        stage2_metadata = {
            # Stage 2 ç‰¹å®šä¿¡æ¯
            'processing_start_time': start_time.isoformat() if start_time else '',
            'processing_end_time': datetime.now(timezone.utc).isoformat(),
            'processing_duration_seconds': processing_time.total_seconds() if processing_time else 0,
            'total_satellites_processed': processing_stats.get('total_satellites_processed', 0),
            'successful_propagations': processing_stats.get('successful_propagations', 0),
            'failed_propagations': processing_stats.get('failed_propagations', 0),
            'total_teme_positions': processing_stats.get('total_teme_positions', 0),
            'constellation_distribution': constellation_stats,
            'coordinate_system': coordinate_system,
            'propagation_method': propagation_method,
            'time_interval_seconds': time_interval_seconds,
            'dynamic_calculation_enabled': dynamic_calculation,
            'coverage_cycles': coverage_cycles,
            'architecture_version': 'v3.0',
            'processing_grade': 'A',
            'stage_concept': 'orbital_state_propagation',
            'tle_reparse_prohibited': True,
            'epoch_datetime_source': 'stage1_provided'
        }

        # ä½¿ç”¨åŸºé¡çš„ metadata åˆä½µæ–¹æ³• (ä¸Šæ¸¸å„ªå…ˆï¼Œè£œå…… Stage 2 ç‰¹å®šå­—æ®µ)
        merged_metadata = self._merge_upstream_metadata(upstream_metadata, stage2_metadata)

        return {
            'stage': 'stage2_orbital_computing',
            'satellites': satellites_by_constellation,
            'metadata': merged_metadata,
            'processing_stats': processing_stats,
            'next_stage_ready': True
        }

    def build_snapshot_data(
        self,
        processing_results: Dict[str, Any],
        processing_stats: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        æ§‹å»º Stage 2 é©—è­‰å¿«ç…§æ•¸æ“š

        åŸºé¡æœƒè‡ªå‹•æ·»åŠ : stage, stage_number, timestamp, validation_passed

        Args:
            processing_results: Stage 2 å®Œæ•´è™•ç†çµæœ
            processing_stats: è™•ç†çµ±è¨ˆ

        Returns:
            Stage 2 å°ˆç”¨å¿«ç…§å­—æ®µ
        """
        metadata = processing_results.get('metadata', {})

        # é©—è­‰åŸºæœ¬å®Œæ•´æ€§
        validation_passed = (
            processing_stats.get('successful_propagations', 0) > 0 and
            metadata.get('total_teme_positions', 0) > 0
        )

        return {
            'status': 'success' if validation_passed else 'failed',
            'validation_status': 'passed' if validation_passed else 'failed',
            'metadata': metadata,
            'processing_stats': processing_stats,
            'data_summary': {
                'total_satellites': metadata.get('total_satellites_processed', 0),
                'successful_propagations': metadata.get('successful_propagations', 0),
                'total_teme_positions': metadata.get('total_teme_positions', 0),
                'constellation_distribution': metadata.get('constellation_distribution', {})
            }
        }

    # ==================== Stage 2 Specific Extensions ====================

    def load_stage1_output(self) -> Dict[str, Any]:
        """
        è¼‰å…¥ Stage 1 è¼¸å‡ºæ•¸æ“š (Stage 2 å°ˆç”¨æ–¹æ³•)

        Returns:
            Dict[str, Any]: Stage 1 è¼¸å‡ºæ•¸æ“š

        Raises:
            FileNotFoundError: æ‰¾ä¸åˆ° Stage 1 è¼¸å‡ºæ–‡ä»¶
        """
        stage1_output_dir = "data/outputs/stage1"

        if not os.path.exists(stage1_output_dir):
            raise FileNotFoundError(f"Stage 1 è¼¸å‡ºç›®éŒ„ä¸å­˜åœ¨: {stage1_output_dir}")

        # å°‹æ‰¾æœ€æ–°çš„ Stage 1 è¼¸å‡ºæ–‡ä»¶
        patterns = [
            os.path.join(stage1_output_dir, "data_loading_output_*.json"),
            os.path.join(stage1_output_dir, "tle_data_loading_output_*.json")
        ]
        files = []
        for pattern in patterns:
            files.extend(glob.glob(pattern))

        if not files:
            raise FileNotFoundError(f"Stage 1 è¼¸å‡ºæ–‡ä»¶ä¸å­˜åœ¨")

        stage1_output_file = max(files, key=os.path.getmtime)
        self.logger.info(f"ğŸ“¥ è¼‰å…¥ Stage 1 è¼¸å‡º: {stage1_output_file}")

        with open(stage1_output_file, 'r', encoding='utf-8') as f:
            return json.load(f)

    def save_results(
        self,
        results: Dict[str, Any],
        output_format: str = 'both',
        custom_filename: Optional[str] = None
    ) -> str:
        """
        ä¿å­˜ Stage 2 è™•ç†çµæœ (è¦†å¯«åŸºé¡æ–¹æ³•ä»¥æ”¯æ´ HDF5)

        Args:
            results: è™•ç†çµæœæ•¸æ“š
            output_format: è¼¸å‡ºæ ¼å¼ ('json', 'hdf5', 'both')
            custom_filename: è‡ªè¨‚æ–‡ä»¶å (ä¸å«å‰¯æª”å)

        Returns:
            str: ä¸»è¦è¼¸å‡ºæ–‡ä»¶è·¯å¾‘

        Raises:
            IOError: ä¿å­˜å¤±æ•—
        """
        try:
            # ä½¿ç”¨åŸºé¡æ–¹æ³•å‰µå»ºç›®éŒ„å’Œç”Ÿæˆæ™‚é–“æˆ³
            output_dir = self._create_output_directory(self.get_stage_number())
            timestamp = self._generate_timestamp()

            # æ§‹å»ºåŸºç¤æ–‡ä»¶å
            if custom_filename:
                base_filename = f"{custom_filename}_{timestamp}"
            else:
                base_filename = f"orbital_propagation_output_{timestamp}"

            output_files = []

            # JSON æ ¼å¼ï¼ˆå‘å¾Œå…¼å®¹ï¼‰
            if output_format in ('json', 'both'):
                json_file = output_dir / f"{base_filename}.json"
                # ä½¿ç”¨åŸºé¡çš„ JSON ä¿å­˜æ–¹æ³•
                self._save_json(results, json_file)
                self.logger.info(f"ğŸ“ JSON æ ¼å¼å·²ä¿å­˜: {json_file}")
                output_files.append(str(json_file))

            # HDF5 æ ¼å¼ï¼ˆStage 2 å°ˆç”¨æ“´å±•ï¼‰
            if output_format in ('hdf5', 'both') and HDF5_AVAILABLE:
                hdf5_file = output_dir / f"{base_filename}.h5"
                self._save_results_hdf5(results, str(hdf5_file))
                self.logger.info(f"ğŸ“¦ HDF5 æ ¼å¼å·²ä¿å­˜: {hdf5_file}")
                output_files.append(str(hdf5_file))

            # è¿”å›ä¸»è¦æ ¼å¼è·¯å¾‘ï¼ˆHDF5 å„ªå…ˆï¼Œå¦å‰‡ JSONï¼‰
            return output_files[-1] if output_files else ""

        except Exception as e:
            self.logger.error(f"âŒ ä¿å­˜ Stage 2 çµæœå¤±æ•—: {e}")
            raise IOError(f"ç„¡æ³•ä¿å­˜ Stage 2 çµæœ: {e}")

    def _save_results_hdf5(self, results: Dict[str, Any], output_file: str):
        """
        ä¿å­˜çµæœç‚º HDF5 æ ¼å¼ (Stage 2 å°ˆç”¨æ“´å±•)

        å­¸è¡“æ¨™æº–æ ¼å¼ï¼Œæ”¯æ´é«˜æ•ˆå£“ç¸®å’Œå¤§è¦æ¨¡æ•¸æ“šå­˜å„²

        Args:
            results: è™•ç†çµæœæ•¸æ“š
            output_file: HDF5 è¼¸å‡ºæ–‡ä»¶è·¯å¾‘
        """
        if not HDF5_AVAILABLE:
            self.logger.warning("âš ï¸ h5py æœªå®‰è£ï¼Œè·³é HDF5 ä¿å­˜")
            return

        with h5py.File(output_file, 'w') as f:
            # ä¿å­˜å…ƒæ•¸æ“š
            metadata = results.get('metadata', {})
            f.attrs['stage'] = results.get('stage', 'stage2_orbital_computing')
            f.attrs['coordinate_system'] = metadata.get('coordinate_system', 'TEME')
            f.attrs['architecture_version'] = metadata.get('architecture_version', 'v3.0')
            f.attrs['timestamp'] = datetime.now(timezone.utc).isoformat()
            f.attrs['total_satellites'] = metadata.get('total_satellites_processed', 0)

            # ä¿å­˜è¡›æ˜Ÿæ•¸æ“šï¼ˆæŒ‰æ˜Ÿåº§åˆ†çµ„ï¼‰
            satellites_data = results.get('satellites', {})

            for constellation_name, constellation_sats in satellites_data.items():
                if not isinstance(constellation_sats, dict):
                    continue

                # å‰µå»ºæ˜Ÿåº§çµ„
                const_group = f.create_group(constellation_name)

                for sat_id, sat_data in constellation_sats.items():
                    # å‰µå»ºè¡›æ˜Ÿçµ„
                    sat_group = const_group.create_group(sat_id)

                    # æå–è»Œé“ç‹€æ…‹æ•¸æ“š
                    orbital_states = sat_data.get('orbital_states', [])
                    if not orbital_states:
                        continue

                    # TEME ä½ç½® (N x 3)
                    positions = np.array([
                        state['position_teme'] for state in orbital_states
                    ], dtype=np.float64)

                    # TEME é€Ÿåº¦ (N x 3)
                    velocities = np.array([
                        state['velocity_teme'] for state in orbital_states
                    ], dtype=np.float64)

                    # æ™‚é–“æˆ³ (N,)
                    timestamps = np.array([
                        state['timestamp'] for state in orbital_states
                    ], dtype='S32')

                    # ä¿å­˜æ•¸æ“šé›†ï¼ˆä½¿ç”¨ gzip å£“ç¸®ï¼‰
                    sat_group.create_dataset(
                        'position_teme_km',
                        data=positions,
                        compression='gzip',
                        compression_opts=6
                    )
                    sat_group.create_dataset(
                        'velocity_teme_km_s',
                        data=velocities,
                        compression='gzip',
                        compression_opts=6
                    )
                    sat_group.create_dataset(
                        'timestamps_utc',
                        data=timestamps
                    )

                    # è¡›æ˜Ÿå…ƒæ•¸æ“š
                    sat_group.attrs['constellation'] = sat_data.get('constellation', '')
                    sat_group.attrs['epoch_datetime'] = sat_data.get('epoch_datetime', '')
                    sat_group.attrs['algorithm_used'] = sat_data.get('algorithm_used', 'SGP4')
                    sat_group.attrs['total_positions'] = len(orbital_states)

        # è¨˜éŒ„å£“ç¸®æ•ˆæœ
        file_size_mb = os.path.getsize(output_file) / (1024 * 1024)
        self.logger.info(f"ğŸ“¦ HDF5 æ–‡ä»¶å¤§å°: {file_size_mb:.1f} MB")

    # ==================== Backward Compatibility Interface ====================

    def build_final_result(
        self,
        orbital_results: Dict[str, Any],
        start_time: datetime,
        processing_time: timedelta,
        input_data: Dict[str, Any],
        processing_stats: Dict[str, Any],
        coordinate_system: str,
        propagation_method: str,
        time_interval_seconds: float,
        dynamic_calculation: bool,
        coverage_cycles: float
    ) -> Dict[str, Any]:
        """
        å‘å¾Œå…¼å®¹æ¥å£: åŸ build_final_result() æ–¹æ³•

        ç›´æ¥èª¿ç”¨ build_stage_results() å¯¦ç¾
        """
        return self.build_stage_results(
            orbital_results=orbital_results,
            start_time=start_time,
            processing_time=processing_time,
            input_data=input_data,
            processing_stats=processing_stats,
            coordinate_system=coordinate_system,
            propagation_method=propagation_method,
            time_interval_seconds=time_interval_seconds,
            dynamic_calculation=dynamic_calculation,
            coverage_cycles=coverage_cycles
        )


# ==================== Factory Function ====================

def create_stage2_result_manager(
    logger_instance: Optional[logging.Logger] = None
) -> Stage2ResultManager:
    """
    å·¥å» å‡½æ•¸: å‰µå»º Stage 2 çµæœç®¡ç†å™¨å¯¦ä¾‹

    Args:
        logger_instance: æ—¥èªŒè¨˜éŒ„å™¨

    Returns:
        Stage2ResultManager å¯¦ä¾‹
    """
    return Stage2ResultManager(logger_instance=logger_instance)
