"""
ğŸ“Š Stage 2: çµæœç®¡ç†æ¨¡çµ„

è² è²¬ Stage 2 è™•ç†çµæœçš„æ§‹å»ºã€ä¿å­˜å’Œè¼‰å…¥æ“ä½œã€‚

æ”¯æ´æ ¼å¼ï¼š
- JSONï¼šå‘å¾Œå…¼å®¹ï¼Œæ˜“è®€æ€§é«˜
- HDF5ï¼šé«˜æ•ˆå£“ç¸®ï¼Œå­¸è¡“æ¨™æº–æ ¼å¼
"""

import logging
import json
import os
import glob
import numpy as np
from datetime import datetime, timezone, timedelta
from typing import Dict, List, Any, Optional

try:
    import h5py
    HDF5_AVAILABLE = True
except ImportError:
    HDF5_AVAILABLE = False
    logging.warning("âš ï¸ h5py æœªå®‰è£ï¼ŒHDF5 æ ¼å¼ä¸å¯ç”¨")

logger = logging.getLogger(__name__)


class Stage2ResultManager:
    """Stage 2 çµæœç®¡ç†å™¨"""

    def __init__(self, logger_instance: Optional[logging.Logger] = None):
        """åˆå§‹åŒ–çµæœç®¡ç†å™¨"""
        self.logger = logger_instance or logging.getLogger(f"{__name__}.Stage2ResultManager")

    def build_final_result(
        self,
        orbital_results: Dict[str, Any],
        start_time: datetime,
        processing_time: timedelta,
        input_data: Dict[str, Any],
        processing_stats: Dict[str, Any],
        coordinate_system: str,
        propagation_method: str,
        time_interval_seconds: float,
        dynamic_calculation: bool,
        coverage_cycles: float
    ) -> Dict[str, Any]:
        """
        æ§‹å»ºæœ€çµ‚çµæœ

        Args:
            orbital_results: è»Œé“è¨ˆç®—çµæœ
            start_time: è™•ç†é–‹å§‹æ™‚é–“
            processing_time: è™•ç†è€—æ™‚
            input_data: è¼¸å…¥æ•¸æ“š
            processing_stats: è™•ç†çµ±è¨ˆ
            coordinate_system: åº§æ¨™ç³»çµ±
            propagation_method: å‚³æ’­æ–¹æ³•
            time_interval_seconds: æ™‚é–“é–“éš”
            dynamic_calculation: æ˜¯å¦å‹•æ…‹è¨ˆç®—
            coverage_cycles: è¦†è“‹é€±æœŸ

        Returns:
            Dict[str, Any]: æœ€çµ‚çµæœæ•¸æ“š
        """
        # æŒ‰æ˜Ÿåº§åˆ†çµ„çµ±è¨ˆ
        constellation_stats = {}
        satellites_by_constellation = {}

        for satellite_id, result in orbital_results.items():
            constellation = result.constellation
            if constellation not in constellation_stats:
                constellation_stats[constellation] = 0
                satellites_by_constellation[constellation] = {}

            constellation_stats[constellation] += 1
            # è½‰æ›ç‚ºè¦æ ¼æ ¼å¼
            orbital_states = []
            for pos in result.teme_positions:
                orbital_state = {
                    'timestamp': pos.timestamp,
                    'position_teme': [pos.x, pos.y, pos.z],  # TEME åº§æ¨™ (km)
                    'velocity_teme': [pos.vx, pos.vy, pos.vz],  # TEME é€Ÿåº¦ (km/s)
                    'satellite_id': satellite_id,
                    # âœ… Grade A æ¨™æº–: ç§»é™¤ä¼°è¨ˆèª¤å·®å€¼
                    # SGP4 èª¤å·®æ‡‰å¾ç®—æ³•å¯¦éš›è¨ˆç®—ç²å–ï¼Œä¸ä½¿ç”¨ç¡¬ç·¨ç¢¼ä¼°ç®—å€¼
                    # åƒè€ƒ: Vallado 2013, Table 3.2 - SGP4 ç²¾åº¦ç¯„åœ 0.5-5 km (è¦– TLE æ–°èˆŠè€Œå®š)
                    # å¦‚éœ€æä¾›èª¤å·®ï¼Œæ‡‰å¾ Skyfield æˆ– SGP4 è¨ˆç®—çµæœç²å–
                }
                orbital_states.append(orbital_state)

            satellites_by_constellation[constellation][satellite_id] = {
                'satellite_id': satellite_id,
                'constellation': constellation,
                'epoch_datetime': result.epoch_datetime,
                'orbital_states': orbital_states,  # ç¬¦åˆè¦æ ¼çš„è»Œé“ç‹€æ…‹æ ¼å¼
                'propagation_successful': result.propagation_successful,
                'algorithm_used': result.algorithm_used,
                'coordinate_system': result.coordinate_system,
                'total_positions': len(result.teme_positions)
            }

        # è¨˜éŒ„çµ±è¨ˆä¿¡æ¯
        logger.info(f"ğŸ“Š æœ€çµ‚çµæœçµ±è¨ˆ:")
        for constellation, count in constellation_stats.items():
            logger.info(f"   {constellation}: {count} é¡†è¡›æ˜Ÿ")

        # âœ… ä¿ç•™ä¸Šæ¸¸ metadata (ç‰¹åˆ¥æ˜¯ constellation_configs)
        upstream_metadata = input_data.get('metadata', {})

        # åˆä½µ metadata: ä¿ç•™ä¸Šæ¸¸é…ç½®ï¼Œæ·»åŠ  Stage 2 è™•ç†ä¿¡æ¯
        merged_metadata = {
            **upstream_metadata,  # âœ… ä¿ç•™ Stage 1 çš„ constellation_configs å’Œ research_configuration
            # Stage 2 ç‰¹å®šä¿¡æ¯
            'processing_start_time': start_time.isoformat(),
            'processing_end_time': datetime.now(timezone.utc).isoformat(),
            'processing_duration_seconds': processing_time.total_seconds(),
            'total_satellites_processed': processing_stats['total_satellites_processed'],
            'successful_propagations': processing_stats['successful_propagations'],
            'failed_propagations': processing_stats['failed_propagations'],
            'total_teme_positions': processing_stats['total_teme_positions'],
            'constellation_distribution': constellation_stats,
            'coordinate_system': coordinate_system,
            'propagation_method': propagation_method,
            'time_interval_seconds': time_interval_seconds,
            'dynamic_calculation_enabled': dynamic_calculation,
            'coverage_cycles': coverage_cycles,
            'architecture_version': 'v3.0',
            'processing_grade': 'A',
            'stage_concept': 'orbital_state_propagation',  # æ–°æ¦‚å¿µæ¨™è¨˜
            'tle_reparse_prohibited': True,  # ç¢ºèªæœªé‡æ–°è§£æ TLE
            'epoch_datetime_source': 'stage1_provided'  # ç¢ºèªæ™‚é–“ä¾†æº
        }

        return {
            'stage': 'stage2_orbital_computing',
            'satellites': satellites_by_constellation,  # æŒ‰æ˜Ÿåº§åˆ†çµ„
            'metadata': merged_metadata,
            'processing_stats': processing_stats,
            'next_stage_ready': True  # ç‚º Stage 3 æº–å‚™å°±ç·’
        }

    def load_stage1_output(self) -> Dict[str, Any]:
        """
        è¼‰å…¥ Stage 1 è¼¸å‡ºæ•¸æ“š

        Returns:
            Dict[str, Any]: Stage 1 è¼¸å‡ºæ•¸æ“š

        Raises:
            FileNotFoundError: æ‰¾ä¸åˆ° Stage 1 è¼¸å‡ºæ–‡ä»¶
        """
        stage1_output_dir = "data/outputs/stage1"

        if not os.path.exists(stage1_output_dir):
            raise FileNotFoundError(f"Stage 1 è¼¸å‡ºç›®éŒ„ä¸å­˜åœ¨: {stage1_output_dir}")

        # å°‹æ‰¾æœ€æ–°çš„ Stage 1 è¼¸å‡ºæ–‡ä»¶
        patterns = [
            os.path.join(stage1_output_dir, "data_loading_output_*.json"),
            os.path.join(stage1_output_dir, "tle_data_loading_output_*.json")
        ]
        files = []
        for pattern in patterns:
            files.extend(glob.glob(pattern))

        if not files:
            raise FileNotFoundError(f"Stage 1 è¼¸å‡ºæ–‡ä»¶ä¸å­˜åœ¨")

        stage1_output_file = max(files, key=os.path.getmtime)
        self.logger.info(f"ğŸ“¥ è¼‰å…¥ Stage 1 è¼¸å‡º: {stage1_output_file}")

        with open(stage1_output_file, 'r', encoding='utf-8') as f:
            return json.load(f)

    def save_results(self, results: Dict[str, Any], output_format: str = 'both') -> str:
        """
        ä¿å­˜ Stage 2 è™•ç†çµæœåˆ°æ–‡ä»¶ï¼ˆæ”¯æ´ JSON/HDF5 é›™æ ¼å¼ï¼‰

        Args:
            results: è™•ç†çµæœæ•¸æ“š
            output_format: è¼¸å‡ºæ ¼å¼ ('json', 'hdf5', 'both')

        Returns:
            str: ä¸»è¦è¼¸å‡ºæ–‡ä»¶è·¯å¾‘

        Raises:
            IOError: ä¿å­˜å¤±æ•—
        """
        try:
            output_dir = "data/outputs/stage2"
            os.makedirs(output_dir, exist_ok=True)

            timestamp = datetime.now(timezone.utc).strftime("%Y%m%d_%H%M%S")
            output_files = []

            # JSON æ ¼å¼ï¼ˆå‘å¾Œå…¼å®¹ï¼‰
            if output_format in ('json', 'both'):
                json_file = os.path.join(output_dir, f"orbital_propagation_output_{timestamp}.json")
                with open(json_file, 'w', encoding='utf-8') as f:
                    json.dump(results, f, ensure_ascii=False, indent=2, default=str)
                self.logger.info(f"ğŸ“ JSON æ ¼å¼å·²ä¿å­˜: {json_file}")
                output_files.append(json_file)

            # HDF5 æ ¼å¼ï¼ˆé«˜æ•ˆå„²å­˜ï¼‰
            if output_format in ('hdf5', 'both') and HDF5_AVAILABLE:
                hdf5_file = os.path.join(output_dir, f"orbital_propagation_output_{timestamp}.h5")
                self._save_results_hdf5(results, hdf5_file)
                self.logger.info(f"ğŸ“¦ HDF5 æ ¼å¼å·²ä¿å­˜: {hdf5_file}")
                output_files.append(hdf5_file)

            # è¿”å›ä¸»è¦æ ¼å¼è·¯å¾‘ï¼ˆHDF5 å„ªå…ˆï¼Œå¦å‰‡ JSONï¼‰
            return output_files[-1] if output_files else ""

        except Exception as e:
            self.logger.error(f"âŒ ä¿å­˜ Stage 2 çµæœå¤±æ•—: {e}")
            raise IOError(f"ç„¡æ³•ä¿å­˜ Stage 2 çµæœ: {e}")

    def _save_results_hdf5(self, results: Dict[str, Any], output_file: str):
        """
        ä¿å­˜çµæœç‚º HDF5 æ ¼å¼ï¼ˆå­¸è¡“æ¨™æº–ï¼Œé«˜æ•ˆå£“ç¸®ï¼‰

        Args:
            results: è™•ç†çµæœæ•¸æ“š
            output_file: HDF5 è¼¸å‡ºæ–‡ä»¶è·¯å¾‘
        """
        if not HDF5_AVAILABLE:
            self.logger.warning("âš ï¸ h5py æœªå®‰è£ï¼Œè·³é HDF5 ä¿å­˜")
            return

        with h5py.File(output_file, 'w') as f:
            # ä¿å­˜å…ƒæ•¸æ“š
            metadata = results.get('metadata', {})
            f.attrs['stage'] = results.get('stage', 'stage2_orbital_computing')
            f.attrs['coordinate_system'] = metadata.get('coordinate_system', 'TEME')
            f.attrs['architecture_version'] = metadata.get('architecture_version', 'v3.0')
            f.attrs['timestamp'] = datetime.now(timezone.utc).isoformat()
            f.attrs['total_satellites'] = metadata.get('total_satellites_processed', 0)

            # ä¿å­˜è¡›æ˜Ÿæ•¸æ“šï¼ˆæŒ‰æ˜Ÿåº§åˆ†çµ„ï¼‰
            satellites_data = results.get('satellites', {})

            for constellation_name, constellation_sats in satellites_data.items():
                if not isinstance(constellation_sats, dict):
                    continue

                # å‰µå»ºæ˜Ÿåº§çµ„
                const_group = f.create_group(constellation_name)

                for sat_id, sat_data in constellation_sats.items():
                    # å‰µå»ºè¡›æ˜Ÿçµ„
                    sat_group = const_group.create_group(sat_id)

                    # æå–è»Œé“ç‹€æ…‹æ•¸æ“š
                    orbital_states = sat_data.get('orbital_states', [])
                    if not orbital_states:
                        continue

                    # TEME ä½ç½® (N x 3)
                    positions = np.array([
                        state['position_teme'] for state in orbital_states
                    ], dtype=np.float64)

                    # TEME é€Ÿåº¦ (N x 3)
                    velocities = np.array([
                        state['velocity_teme'] for state in orbital_states
                    ], dtype=np.float64)

                    # æ™‚é–“æˆ³ (N,)
                    timestamps = np.array([
                        state['timestamp'] for state in orbital_states
                    ], dtype='S32')

                    # ä¿å­˜æ•¸æ“šé›†ï¼ˆä½¿ç”¨ gzip å£“ç¸®ï¼‰
                    sat_group.create_dataset(
                        'position_teme_km',
                        data=positions,
                        compression='gzip',
                        compression_opts=6
                    )
                    sat_group.create_dataset(
                        'velocity_teme_km_s',
                        data=velocities,
                        compression='gzip',
                        compression_opts=6
                    )
                    sat_group.create_dataset(
                        'timestamps_utc',
                        data=timestamps
                    )

                    # è¡›æ˜Ÿå…ƒæ•¸æ“š
                    sat_group.attrs['constellation'] = sat_data.get('constellation', '')
                    sat_group.attrs['epoch_datetime'] = sat_data.get('epoch_datetime', '')
                    sat_group.attrs['algorithm_used'] = sat_data.get('algorithm_used', 'SGP4')
                    sat_group.attrs['total_positions'] = len(orbital_states)

        # è¨˜éŒ„å£“ç¸®æ•ˆæœ
        file_size_mb = os.path.getsize(output_file) / (1024 * 1024)
        self.logger.info(f"ğŸ“¦ HDF5 æ–‡ä»¶å¤§å°: {file_size_mb:.1f} MB")
