"""
ğŸ“Š Stage 2: çµæœç®¡ç†æ¨¡çµ„

è² è²¬ Stage 2 è™•ç†çµæœçš„æ§‹å»ºã€ä¿å­˜å’Œè¼‰å…¥æ“ä½œã€‚
"""

import logging
import json
import os
import glob
from datetime import datetime, timezone, timedelta
from typing import Dict, List, Any, Optional

logger = logging.getLogger(__name__)


class Stage2ResultManager:
    """Stage 2 çµæœç®¡ç†å™¨"""

    def __init__(self, logger_instance: Optional[logging.Logger] = None):
        """åˆå§‹åŒ–çµæœç®¡ç†å™¨"""
        self.logger = logger_instance or logging.getLogger(f"{__name__}.Stage2ResultManager")

    def build_final_result(
        self,
        orbital_results: Dict[str, Any],
        start_time: datetime,
        processing_time: timedelta,
        input_data: Dict[str, Any],
        processing_stats: Dict[str, Any],
        coordinate_system: str,
        propagation_method: str,
        time_interval_seconds: float,
        dynamic_calculation: bool,
        coverage_cycles: float
    ) -> Dict[str, Any]:
        """
        æ§‹å»ºæœ€çµ‚çµæœ

        Args:
            orbital_results: è»Œé“è¨ˆç®—çµæœ
            start_time: è™•ç†é–‹å§‹æ™‚é–“
            processing_time: è™•ç†è€—æ™‚
            input_data: è¼¸å…¥æ•¸æ“š
            processing_stats: è™•ç†çµ±è¨ˆ
            coordinate_system: åº§æ¨™ç³»çµ±
            propagation_method: å‚³æ’­æ–¹æ³•
            time_interval_seconds: æ™‚é–“é–“éš”
            dynamic_calculation: æ˜¯å¦å‹•æ…‹è¨ˆç®—
            coverage_cycles: è¦†è“‹é€±æœŸ

        Returns:
            Dict[str, Any]: æœ€çµ‚çµæœæ•¸æ“š
        """
        # æŒ‰æ˜Ÿåº§åˆ†çµ„çµ±è¨ˆ
        constellation_stats = {}
        satellites_by_constellation = {}

        for satellite_id, result in orbital_results.items():
            constellation = result.constellation
            if constellation not in constellation_stats:
                constellation_stats[constellation] = 0
                satellites_by_constellation[constellation] = {}

            constellation_stats[constellation] += 1
            # è½‰æ›ç‚ºè¦æ ¼æ ¼å¼
            orbital_states = []
            for pos in result.teme_positions:
                orbital_state = {
                    'timestamp': pos.timestamp,
                    'position_teme': [pos.x, pos.y, pos.z],  # TEME åº§æ¨™ (km)
                    'velocity_teme': [pos.vx, pos.vy, pos.vz],  # TEME é€Ÿåº¦ (km/s)
                    'satellite_id': satellite_id,
                    'propagation_error': 0.001  # km (ä¼°è¨ˆèª¤å·®ï¼Œç¬¦åˆSGP4ç²¾åº¦)
                }
                orbital_states.append(orbital_state)

            satellites_by_constellation[constellation][satellite_id] = {
                'satellite_id': satellite_id,
                'constellation': constellation,
                'epoch_datetime': result.epoch_datetime,
                'orbital_states': orbital_states,  # ç¬¦åˆè¦æ ¼çš„è»Œé“ç‹€æ…‹æ ¼å¼
                'propagation_successful': result.propagation_successful,
                'algorithm_used': result.algorithm_used,
                'coordinate_system': result.coordinate_system,
                'total_positions': len(result.teme_positions)
            }

        # è¨˜éŒ„çµ±è¨ˆä¿¡æ¯
        logger.info(f"ğŸ“Š æœ€çµ‚çµæœçµ±è¨ˆ:")
        for constellation, count in constellation_stats.items():
            logger.info(f"   {constellation}: {count} é¡†è¡›æ˜Ÿ")

        # âœ… ä¿ç•™ä¸Šæ¸¸ metadata (ç‰¹åˆ¥æ˜¯ constellation_configs)
        upstream_metadata = input_data.get('metadata', {})

        # åˆä½µ metadata: ä¿ç•™ä¸Šæ¸¸é…ç½®ï¼Œæ·»åŠ  Stage 2 è™•ç†ä¿¡æ¯
        merged_metadata = {
            **upstream_metadata,  # âœ… ä¿ç•™ Stage 1 çš„ constellation_configs å’Œ research_configuration
            # Stage 2 ç‰¹å®šä¿¡æ¯
            'processing_start_time': start_time.isoformat(),
            'processing_end_time': datetime.now(timezone.utc).isoformat(),
            'processing_duration_seconds': processing_time.total_seconds(),
            'total_satellites_processed': processing_stats['total_satellites_processed'],
            'successful_propagations': processing_stats['successful_propagations'],
            'failed_propagations': processing_stats['failed_propagations'],
            'total_teme_positions': processing_stats['total_teme_positions'],
            'constellation_distribution': constellation_stats,
            'coordinate_system': coordinate_system,
            'propagation_method': propagation_method,
            'time_interval_seconds': time_interval_seconds,
            'dynamic_calculation_enabled': dynamic_calculation,
            'coverage_cycles': coverage_cycles,
            'architecture_version': 'v3.0',
            'processing_grade': 'A',
            'stage_concept': 'orbital_state_propagation',  # æ–°æ¦‚å¿µæ¨™è¨˜
            'tle_reparse_prohibited': True,  # ç¢ºèªæœªé‡æ–°è§£æ TLE
            'epoch_datetime_source': 'stage1_provided'  # ç¢ºèªæ™‚é–“ä¾†æº
        }

        return {
            'stage': 'stage2_orbital_computing',
            'satellites': satellites_by_constellation,  # æŒ‰æ˜Ÿåº§åˆ†çµ„
            'metadata': merged_metadata,
            'processing_stats': processing_stats,
            'next_stage_ready': True  # ç‚º Stage 3 æº–å‚™å°±ç·’
        }

    def load_stage1_output(self) -> Dict[str, Any]:
        """
        è¼‰å…¥ Stage 1 è¼¸å‡ºæ•¸æ“š

        Returns:
            Dict[str, Any]: Stage 1 è¼¸å‡ºæ•¸æ“š

        Raises:
            FileNotFoundError: æ‰¾ä¸åˆ° Stage 1 è¼¸å‡ºæ–‡ä»¶
        """
        stage1_output_dir = "data/outputs/stage1"

        if not os.path.exists(stage1_output_dir):
            raise FileNotFoundError(f"Stage 1 è¼¸å‡ºç›®éŒ„ä¸å­˜åœ¨: {stage1_output_dir}")

        # å°‹æ‰¾æœ€æ–°çš„ Stage 1 è¼¸å‡ºæ–‡ä»¶
        patterns = [
            os.path.join(stage1_output_dir, "data_loading_output_*.json"),
            os.path.join(stage1_output_dir, "tle_data_loading_output_*.json")
        ]
        files = []
        for pattern in patterns:
            files.extend(glob.glob(pattern))

        if not files:
            raise FileNotFoundError(f"Stage 1 è¼¸å‡ºæ–‡ä»¶ä¸å­˜åœ¨")

        stage1_output_file = max(files, key=os.path.getmtime)
        self.logger.info(f"ğŸ“¥ è¼‰å…¥ Stage 1 è¼¸å‡º: {stage1_output_file}")

        with open(stage1_output_file, 'r', encoding='utf-8') as f:
            return json.load(f)

    def save_results(self, results: Dict[str, Any]) -> str:
        """
        ä¿å­˜ Stage 2 è™•ç†çµæœåˆ°æ–‡ä»¶

        Args:
            results: è™•ç†çµæœæ•¸æ“š

        Returns:
            str: è¼¸å‡ºæ–‡ä»¶è·¯å¾‘

        Raises:
            IOError: ä¿å­˜å¤±æ•—
        """
        try:
            output_dir = "data/outputs/stage2"
            os.makedirs(output_dir, exist_ok=True)

            timestamp = datetime.now(timezone.utc).strftime("%Y%m%d_%H%M%S")
            output_file = os.path.join(output_dir, f"orbital_propagation_output_{timestamp}.json")

            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(results, f, ensure_ascii=False, indent=2, default=str)

            self.logger.info(f"ğŸ“ Stage 2 çµæœå·²ä¿å­˜: {output_file}")
            return output_file

        except Exception as e:
            self.logger.error(f"âŒ ä¿å­˜ Stage 2 çµæœå¤±æ•—: {e}")
            raise IOError(f"ç„¡æ³•ä¿å­˜ Stage 2 çµæœ: {e}")
