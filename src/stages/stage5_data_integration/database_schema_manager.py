"""
Database Schema Manager - PostgreSQLæ¶æ§‹ç®¡ç†çµ„ä»¶
å°ˆè²¬æ•¸æ“šåº«è¡¨çµæ§‹å»ºç«‹ã€ç´¢å¼•å„ªåŒ–å’Œæ··åˆå­˜å„²é©—è­‰
"""

import logging
from typing import Dict, Any, Optional
import psycopg2

logger = logging.getLogger(__name__)

class DatabaseSchemaManager:
    """PostgreSQLæ•¸æ“šåº«æ¶æ§‹ç®¡ç†å™¨ - å°ˆè²¬è¡¨çµæ§‹å’Œç´¢å¼•ç®¡ç†"""

    def __init__(self, connection: psycopg2.extensions.connection, table_schemas: Dict[str, Any]):
        """
        åˆå§‹åŒ–æ•¸æ“šåº«æ¶æ§‹ç®¡ç†å™¨

        Args:
            connection: PostgreSQLæ•¸æ“šåº«é€£æ¥
            table_schemas: è¡¨çµæ§‹å®šç¾©
        """
        self.logger = logging.getLogger(__name__)
        self.connection = connection
        self.table_schemas = table_schemas
        self.schema_statistics = {
            "tables_created": 0,
            "indexes_created": 0,
            "storage_verified": False
        }

    def create_postgresql_tables(self) -> Dict[str, Any]:
        """å‰µå»ºPostgreSQLè¡¨çµæ§‹"""
        self.logger.info("ğŸ“‹ å‰µå»ºPostgreSQLè¡¨çµæ§‹...")

        result = {
            "success": True,
            "tables_created": [],
            "errors": []
        }

        cursor = self.connection.cursor()

        try:
            for table_info in self.table_schemas.values():
                table_name = table_info["table_name"]
                columns = table_info["columns"]

                # æª¢æŸ¥è¡¨æ˜¯å¦å·²å­˜åœ¨
                cursor.execute("""
                    SELECT EXISTS (
                        SELECT FROM information_schema.tables
                        WHERE table_name = %s
                    );
                """, (table_name,))

                table_exists = cursor.fetchone()[0]

                if not table_exists:
                    # å‰µå»ºè¡¨
                    columns_sql = ", ".join(columns)
                    create_sql = f"CREATE TABLE {table_name} ({columns_sql});"

                    cursor.execute(create_sql)
                    result["tables_created"].append(table_name)
                    self.schema_statistics["tables_created"] += 1
                    self.logger.info(f"   âœ… å‰µå»ºè¡¨: {table_name}")
                else:
                    self.logger.info(f"   ğŸ“‹ è¡¨å·²å­˜åœ¨: {table_name}")

            self.connection.commit()

        except Exception as e:
            self.connection.rollback()
            error_msg = f"è¡¨å‰µå»ºå¤±æ•—: {e}"
            result["success"] = False
            result["errors"].append(error_msg)
            self.logger.error(f"   âŒ {error_msg}")
        finally:
            cursor.close()

        return result

    def create_postgresql_indexes(self) -> Dict[str, Any]:
        """å‰µå»ºPostgreSQLç´¢å¼•ä»¥å„ªåŒ–æŸ¥è©¢æ€§èƒ½"""
        self.logger.info("ğŸš€ å‰µå»ºPostgreSQLç´¢å¼•å„ªåŒ–...")

        result = {
            "success": True,
            "indexes_created": [],
            "errors": []
        }

        # å®šç¾©é—œéµç´¢å¼• - åŸºæ–¼æ··åˆå­˜å„²æŸ¥è©¢æ¨¡å¼å„ªåŒ–
        indexes = [
            {
                "name": "idx_satellite_metadata_constellation",
                "table": "satellite_metadata",
                "columns": ["constellation", "satellite_id"],
                "type": "btree"
            },
            {
                "name": "idx_signal_statistics_timestamp",
                "table": "signal_statistics",
                "columns": ["timestamp", "satellite_id"],
                "type": "btree"
            },
            {
                "name": "idx_handover_events_type_timestamp",
                "table": "handover_events",
                "columns": ["event_type", "event_timestamp"],
                "type": "btree"
            },
            {
                "name": "idx_processing_summary_stage_timestamp",
                "table": "processing_summary",
                "columns": ["stage_name", "processing_timestamp"],
                "type": "btree"
            }
        ]

        cursor = self.connection.cursor()

        try:
            for index in indexes:
                # æª¢æŸ¥ç´¢å¼•æ˜¯å¦å·²å­˜åœ¨
                cursor.execute("""
                    SELECT EXISTS (
                        SELECT FROM pg_indexes
                        WHERE indexname = %s
                    );
                """, (index["name"],))

                index_exists = cursor.fetchone()[0]

                if not index_exists:
                    columns_sql = ", ".join(index["columns"])
                    create_sql = f"""
                        CREATE INDEX {index["name"]}
                        ON {index["table"]}
                        USING {index["type"]} ({columns_sql});
                    """

                    cursor.execute(create_sql)
                    result["indexes_created"].append(index["name"])
                    self.schema_statistics["indexes_created"] += 1
                    self.logger.info(f"   âœ… å‰µå»ºç´¢å¼•: {index['name']}")
                else:
                    self.logger.info(f"   ğŸš€ ç´¢å¼•å·²å­˜åœ¨: {index['name']}")

            self.connection.commit()

        except Exception as e:
            self.connection.rollback()
            error_msg = f"ç´¢å¼•å‰µå»ºå¤±æ•—: {e}"
            result["success"] = False
            result["errors"].append(error_msg)
            self.logger.error(f"   âŒ {error_msg}")
        finally:
            cursor.close()

        return result

    def verify_mixed_storage(self) -> Dict[str, Any]:
        """é©—è­‰æ··åˆå­˜å„²æ¶æ§‹çš„å®Œæ•´æ€§"""
        self.logger.info("ğŸ” é©—è­‰æ··åˆå­˜å„²æ¶æ§‹...")

        verification_result = {
            "postgresql_tables": {},
            "volume_files": {},
            "storage_balance": {},
            "success": True,
            "errors": []
        }

        cursor = self.connection.cursor()

        try:
            # é©—è­‰PostgreSQLè¡¨æ•¸æ“š
            for table_info in self.table_schemas.values():
                table_name = table_info["table_name"]

                cursor.execute(f"SELECT COUNT(*) FROM {table_name};")
                count = cursor.fetchone()[0]

                cursor.execute(f"""
                    SELECT pg_size_pretty(pg_total_relation_size('{table_name}'));
                """)
                size = cursor.fetchone()[0]

                verification_result["postgresql_tables"][table_name] = {
                    "row_count": count,
                    "table_size": size
                }

            # è¨ˆç®—å­˜å„²å¹³è¡¡
            cursor.execute("""
                SELECT pg_size_pretty(pg_database_size(current_database()));
            """)
            total_db_size = cursor.fetchone()[0]

            verification_result["storage_balance"] = {
                "postgresql_total_size": total_db_size,
                "mixed_storage_strategy": "postgresql_structured_volume_timeseries",
                "verification_status": "completed"
            }

            self.schema_statistics["storage_verified"] = True
            self.logger.info("   âœ… æ··åˆå­˜å„²æ¶æ§‹é©—è­‰å®Œæˆ")

        except Exception as e:
            error_msg = f"æ··åˆå­˜å„²é©—è­‰å¤±æ•—: {e}"
            verification_result["success"] = False
            verification_result["errors"].append(error_msg)
            self.logger.error(f"   âŒ {error_msg}")
        finally:
            cursor.close()

        return verification_result

    def get_schema_statistics(self) -> Dict[str, Any]:
        """ç²å–æ¶æ§‹ç®¡ç†çµ±è¨ˆä¿¡æ¯"""
        return self.schema_statistics.copy()