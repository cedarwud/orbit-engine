"""
ğŸ“Š æ•¸æ“šå“è³ªé©—è­‰å™¨ (Data Quality Validator)
Orbit Engine System - Stage 3 Enhanced Module

å°ˆé–€è² è²¬æ•¸æ“šå“è³ªã€æ¡æ¨£å’Œæ™‚é–“åºåˆ—çš„é©—è­‰
å¾ scientific_validator.py æ‹†åˆ†å‡ºä¾†çš„å°ˆæ¥­é©—è­‰å™¨

ç‰ˆæœ¬: v1.0 - Stage3å¢å¼·ç‰ˆæœ¬
æœ€å¾Œæ›´æ–°: 2025-09-19
"""

import logging
import json
import statistics
from typing import Dict, Any, List, Optional
from datetime import datetime, timezone

class DataQualityValidator:
    """
    æ•¸æ“šå“è³ªé©—è­‰å™¨

    å°ˆé–€è² è²¬ï¼š
    1. çœŸå¯¦æ•¸æ“šæ¡æ¨£é©—è­‰
    2. æ™‚é–“åºåˆ—å“è³ªæª¢æŸ¥
    3. æ˜Ÿåº§é–“çµ±è¨ˆé©—è­‰
    """

    def __init__(self):
        """åˆå§‹åŒ–æ•¸æ“šå“è³ªé©—è­‰å™¨"""
        self.logger = logging.getLogger(f"{__name__}.DataQualityValidator")

        # é æœŸçš„å¯è¦‹æ€§çµ±è¨ˆ
        self.EXPECTED_VISIBILITY_STATS = {
            "starlink": {"min_visible": 50, "max_visible": 300, "avg_elevation": 25},
            "oneweb": {"min_visible": 10, "max_visible": 80, "avg_elevation": 35}
        }

        self.logger.info("âœ… DataQualityValidator åˆå§‹åŒ–å®Œæˆ")

    def validate_real_data_sampling(self, visibility_output: Dict[str, Any]) -> Dict[str, Any]:
        """
        é©—è­‰çœŸå¯¦æ•¸æ“šæ¡æ¨£å“è³ª

        æª¢æŸ¥æ•¸æ“šæ˜¯å¦ä¾†è‡ªçœŸå¯¦TLEæ•¸æ“šï¼Œè€Œéæ¨¡æ“¬æˆ–ä¼°ç®—å€¼
        """
        self.logger.info("ğŸ”¹ åŸ·è¡ŒçœŸå¯¦æ•¸æ“šæ¡æ¨£é©—è­‰...")

        results = {
            "sampling_passed": True,
            "data_quality_score": 1.0,
            "sampling_issues": [],
            "authenticity_indicators": {}
        }

        try:
            # æª¢æŸ¥metadataä¸­çš„æ•¸æ“šä¾†æºä¿¡æ¯
            metadata = visibility_output.get("metadata", {})

            # é©—è­‰TLEæ•¸æ“šä¾†æº
            tle_info = metadata.get("tle_data_info", {})
            if tle_info:
                results["authenticity_indicators"]["tle_source"] = "verified"
                if "epoch" in tle_info:
                    results["authenticity_indicators"]["tle_epoch"] = tle_info["epoch"]
            else:
                results["sampling_issues"].append("ç¼ºå°‘TLEæ•¸æ“šä¾†æºé©—è­‰")
                results["data_quality_score"] -= 0.2

            # æª¢æŸ¥è¡›æ˜Ÿæ•¸æ“šåˆ†ä½ˆçš„è‡ªç„¶æ€§
            filtered_satellites = visibility_output.get("data", {}).get("filtered_satellites", {})

            for constellation, satellites in filtered_satellites.items():
                if not satellites:
                    continue

                # æª¢æŸ¥è¡›æ˜Ÿåˆ†ä½ˆçš„éš¨æ©Ÿæ€§ï¼ˆçœŸå¯¦æ•¸æ“šæ‡‰è©²æœ‰è‡ªç„¶è®ŠåŒ–ï¼‰
                elevations = []
                azimuths = []
                distances = []

                for satellite in satellites[:20]:  # æª¢æŸ¥å‰20é¡†è¡›æ˜Ÿ
                    timeseries = satellite.get("position_timeseries", [])
                    for position in timeseries[:1]:  # æ¯é¡†è¡›æ˜Ÿå–1å€‹ä½ç½®
                        relative_data = position.get("relative_to_observer", {})
                        if isinstance(relative_data, dict):
                            elev = relative_data.get("elevation_deg")
                            azim = relative_data.get("azimuth_deg")
                            dist = relative_data.get("distance_km")

                            if elev is not None:
                                elevations.append(elev)
                            if azim is not None:
                                azimuths.append(azim)
                            if dist is not None:
                                distances.append(dist)

                # åˆ†ææ•¸æ“šåˆ†ä½ˆçš„è‡ªç„¶æ€§
                if elevations:
                    # æª¢æŸ¥æ˜¯å¦å­˜åœ¨ä¸è‡ªç„¶çš„æ•¸æ“šæ¨¡å¼
                    if len(set(elevations)) == 1:  # æ‰€æœ‰å€¼ç›¸åŒ
                        results["sampling_issues"].append(f"{constellation}: ä»°è§’æ•¸æ“šéæ–¼ä¸€è‡´ï¼Œå¯èƒ½ç‚ºæ¨¡æ“¬æ•¸æ“š")
                        results["data_quality_score"] -= 0.3

                    # æª¢æŸ¥æ•¸æ“šç¯„åœåˆç†æ€§
                    elev_range = max(elevations) - min(elevations)
                    if elev_range < 5:  # ç¯„åœå¤ªå°
                        results["sampling_issues"].append(f"{constellation}: ä»°è§’è®ŠåŒ–ç¯„åœéå° {elev_range:.1f}Â°")
                        results["data_quality_score"] -= 0.1

                if distances:
                    # æª¢æŸ¥è·é›¢åˆ†ä½ˆçš„åˆç†æ€§
                    dist_std = statistics.stdev(distances) if len(distances) > 1 else 0
                    if dist_std < 100:  # æ¨™æº–å·®å¤ªå°
                        results["sampling_issues"].append(f"{constellation}: è·é›¢è®ŠåŒ–éå°ï¼Œæ¨™æº–å·®={dist_std:.1f}km")
                        results["data_quality_score"] -= 0.1

                # è¨˜éŒ„åˆ†ææŒ‡æ¨™
                results["authenticity_indicators"][f"{constellation}_data_points"] = len(elevations)
                if elevations:
                    results["authenticity_indicators"][f"{constellation}_elevation_range"] = max(elevations) - min(elevations)
                if distances:
                    results["authenticity_indicators"][f"{constellation}_distance_std"] = statistics.stdev(distances) if len(distances) > 1 else 0

            # æª¢æŸ¥è™•ç†æ™‚é–“æˆ³çš„çœŸå¯¦æ€§
            processing_timestamp = metadata.get("processing_timestamp")
            if processing_timestamp:
                try:
                    proc_time = datetime.fromisoformat(processing_timestamp.replace('Z', '+00:00'))
                    now = datetime.now(timezone.utc)
                    time_diff = abs((now - proc_time).total_seconds())

                    if time_diff > 3600:  # è¶…é1å°æ™‚
                        results["sampling_issues"].append(f"è™•ç†æ™‚é–“æˆ³ç•°å¸¸ï¼Œæ™‚å·®={time_diff/3600:.1f}å°æ™‚")
                        results["data_quality_score"] -= 0.1

                    results["authenticity_indicators"]["processing_time_freshness"] = f"{time_diff:.0f}ç§’å‰"
                except:
                    results["sampling_issues"].append("è™•ç†æ™‚é–“æˆ³æ ¼å¼ç„¡æ•ˆ")
                    results["data_quality_score"] -= 0.1

            # åˆ¤å®šæ¡æ¨£å“è³ªæ˜¯å¦é€šé
            if results["data_quality_score"] < 0.7:
                results["sampling_passed"] = False

            self.logger.info(f"ğŸ”¹ çœŸå¯¦æ•¸æ“šæ¡æ¨£é©—è­‰: é€šé={results['sampling_passed']}, "
                           f"å“è³ªåˆ†æ•¸={results['data_quality_score']:.3f}")

            return results

        except Exception as e:
            self.logger.error(f"âŒ çœŸå¯¦æ•¸æ“šæ¡æ¨£é©—è­‰å¤±æ•—: {e}")
            results.update({
                "sampling_passed": False,
                "data_quality_score": 0.0,
                "sampling_issues": [f"æ¡æ¨£é©—è­‰ç•°å¸¸: {e}"]
            })
            return results

    def validate_timeseries_quality(self, visibility_output: Dict[str, Any]) -> Dict[str, Any]:
        """
        é©—è­‰æ™‚é–“åºåˆ—æ•¸æ“šå“è³ª

        æª¢æŸ¥æ™‚é–“åºåˆ—çš„é€£çºŒæ€§ã€å®Œæ•´æ€§å’Œä¸€è‡´æ€§
        """
        self.logger.info("ğŸ”¹ åŸ·è¡Œæ™‚é–“åºåˆ—å“è³ªé©—è­‰...")

        results = {
            "timeseries_passed": True,
            "continuity_score": 1.0,
            "quality_issues": [],
            "timeseries_stats": {}
        }

        try:
            filtered_satellites = visibility_output.get("data", {}).get("filtered_satellites", {})

            total_satellites = 0
            quality_violations = 0

            for constellation, satellites in filtered_satellites.items():
                constellation_stats = {
                    "satellite_count": len(satellites),
                    "avg_timeseries_length": 0,
                    "continuity_issues": 0
                }

                timeseries_lengths = []

                for satellite in satellites[:10]:  # æª¢æŸ¥å‰10é¡†è¡›æ˜Ÿ
                    total_satellites += 1

                    timeseries = satellite.get("position_timeseries", [])
                    timeseries_lengths.append(len(timeseries))

                    if len(timeseries) < 2:  # æ™‚é–“åºåˆ—å¤ªçŸ­
                        quality_violations += 1
                        results["quality_issues"].append(f"{constellation}: æ™‚é–“åºåˆ—éçŸ­ ({len(timeseries)}å€‹é»)")
                        constellation_stats["continuity_issues"] += 1
                        continue

                    # æª¢æŸ¥æ™‚é–“åºåˆ—çš„æ™‚é–“æˆ³é€£çºŒæ€§
                    timestamps = []
                    for position in timeseries:
                        timestamp = position.get("timestamp")
                        if timestamp:
                            timestamps.append(timestamp)

                    if len(timestamps) != len(timeseries):
                        quality_violations += 1
                        results["quality_issues"].append(f"{constellation}: æ™‚é–“æˆ³ç¼ºå¤±")
                        constellation_stats["continuity_issues"] += 1

                    # æª¢æŸ¥æ•¸æ“šå®Œæ•´æ€§
                    for pos_idx, position in enumerate(timeseries):
                        relative_data = position.get("relative_to_observer", {})
                        if not isinstance(relative_data, dict):
                            quality_violations += 1
                            results["quality_issues"].append(f"{constellation}: ä½ç½®{pos_idx}ç¼ºå°‘ç›¸å°è§€æ¸¬è€…æ•¸æ“š")
                            constellation_stats["continuity_issues"] += 1
                            break

                        # æª¢æŸ¥é—œéµæ•¸æ“šå­—æ®µ
                        required_fields = ["elevation_deg", "azimuth_deg", "distance_km"]
                        missing_fields = [field for field in required_fields if relative_data.get(field) is None]

                        if missing_fields:
                            quality_violations += 1
                            results["quality_issues"].append(f"{constellation}: ä½ç½®{pos_idx}ç¼ºå°‘å­—æ®µ{missing_fields}")
                            constellation_stats["continuity_issues"] += 1
                            break

                # çµ±è¨ˆæ˜Ÿåº§æ•¸æ“šå“è³ª
                if timeseries_lengths:
                    constellation_stats["avg_timeseries_length"] = sum(timeseries_lengths) / len(timeseries_lengths)
                    constellation_stats["min_timeseries_length"] = min(timeseries_lengths)
                    constellation_stats["max_timeseries_length"] = max(timeseries_lengths)

                results["timeseries_stats"][constellation] = constellation_stats

            # è¨ˆç®—é€£çºŒæ€§åˆ†æ•¸
            if total_satellites > 0:
                violation_rate = quality_violations / total_satellites
                results["continuity_score"] = max(0.0, 1.0 - violation_rate * 1.0)

            # åˆ¤å®šæ™‚é–“åºåˆ—å“è³ªæ˜¯å¦é€šé
            if results["continuity_score"] < 0.8:
                results["timeseries_passed"] = False

            self.logger.info(f"ğŸ”¹ æ™‚é–“åºåˆ—å“è³ªé©—è­‰: é€šé={results['timeseries_passed']}, "
                           f"é€£çºŒæ€§åˆ†æ•¸={results['continuity_score']:.3f}, "
                           f"é•è¦={quality_violations}/{total_satellites}")

            return results

        except Exception as e:
            self.logger.error(f"âŒ æ™‚é–“åºåˆ—å“è³ªé©—è­‰å¤±æ•—: {e}")
            results.update({
                "timeseries_passed": False,
                "continuity_score": 0.0,
                "quality_issues": [f"æ™‚é–“åºåˆ—é©—è­‰ç•°å¸¸: {e}"]
            })
            return results

    def validate_inter_constellation_statistics(self, visibility_output: Dict[str, Any]) -> Dict[str, Any]:
        """
        é©—è­‰æ˜Ÿåº§é–“çµ±è¨ˆæ•¸æ“š

        æª¢æŸ¥ Starlink å’Œ OneWeb çš„ç›¸å°çµ±è¨ˆæ˜¯å¦ç¬¦åˆé æœŸ
        """
        self.logger.info("ğŸ”¹ åŸ·è¡Œæ˜Ÿåº§é–“çµ±è¨ˆé©—è­‰...")

        results = {
            "statistics_passed": True,
            "statistical_score": 1.0,
            "constellation_comparison": {}
        }

        try:
            filtered_satellites = visibility_output.get("data", {}).get("filtered_satellites", {})

            # åˆ†æå„æ˜Ÿåº§çµ±è¨ˆ
            for constellation, satellites in filtered_satellites.items():
                stats = {
                    "satellite_count": len(satellites),
                    "expected_range": self.EXPECTED_VISIBILITY_STATS.get(constellation, {}),
                    "meets_expectations": True
                }

                expected = self.EXPECTED_VISIBILITY_STATS.get(constellation, {})

                # æª¢æŸ¥è¡›æ˜Ÿæ•¸é‡æ˜¯å¦åœ¨é æœŸç¯„åœå…§
                if expected:
                    min_expected = expected.get("min_visible", 0)
                    max_expected = expected.get("max_visible", 1000)

                    if len(satellites) < min_expected:
                        stats["meets_expectations"] = False
                        stats["issue"] = f"è¡›æ˜Ÿæ•¸é‡éå°‘: {len(satellites)} < {min_expected}"
                    elif len(satellites) > max_expected:
                        stats["meets_expectations"] = False
                        stats["issue"] = f"è¡›æ˜Ÿæ•¸é‡éå¤š: {len(satellites)} > {max_expected}"

                results["constellation_comparison"][constellation] = stats

            # æª¢æŸ¥Starlink vs OneWebæ¯”ä¾‹
            starlink_count = len(filtered_satellites.get("starlink", []))
            oneweb_count = len(filtered_satellites.get("oneweb", []))

            if starlink_count > 0 and oneweb_count > 0:
                ratio = starlink_count / oneweb_count
                results["constellation_comparison"]["starlink_to_oneweb_ratio"] = ratio

                # Starlinké€šå¸¸æ‡‰è©²æ¯”OneWebå¤šï¼ˆä¸åŒè»Œé“é«˜åº¦ï¼‰
                if ratio < 2.0:  # é æœŸæ¯”ä¾‹è‡³å°‘2:1
                    results["statistical_score"] -= 0.2
                    results["constellation_comparison"]["ratio_issue"] = f"Starlink/OneWebæ¯”ä¾‹åä½: {ratio:.1f}"

            # è¨ˆç®—æ•´é«”çµ±è¨ˆåˆ†æ•¸
            failed_constellations = sum(1 for stats in results["constellation_comparison"].values()
                                      if isinstance(stats, dict) and not stats.get("meets_expectations", True))

            if len(filtered_satellites) > 0:
                success_rate = 1.0 - (failed_constellations / len(filtered_satellites))
                results["statistical_score"] *= success_rate

            # åˆ¤å®šçµ±è¨ˆé©—è­‰æ˜¯å¦é€šé
            if results["statistical_score"] < 0.7:
                results["statistics_passed"] = False

            self.logger.info(f"ğŸ”¹ æ˜Ÿåº§é–“çµ±è¨ˆé©—è­‰: é€šé={results['statistics_passed']}, "
                           f"çµ±è¨ˆåˆ†æ•¸={results['statistical_score']:.3f}")

            return results

        except Exception as e:
            self.logger.error(f"âŒ æ˜Ÿåº§é–“çµ±è¨ˆé©—è­‰å¤±æ•—: {e}")
            results.update({
                "statistics_passed": False,
                "statistical_score": 0.0,
                "constellation_comparison": {"error": str(e)}
            })
            return results