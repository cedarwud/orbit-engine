"""
çå‹µè¨ˆç®—å™¨ - Stage 6 ML è¨“ç·´æ•¸æ“šç”Ÿæˆçµ„ä»¶

å¯¦ç¾è¤‡åˆçå‹µå‡½æ•¸ï¼Œç”¨æ–¼å¼·åŒ–å­¸ç¿’æ›æ‰‹æ±ºç­–ã€‚

çå‹µçµ„æˆ:
1. QoS æ”¹å–„çå‹µ (+0.0 ~ +1.0)
2. ä¸­æ–·æ‡²ç½° (-0.5 ~ 0.0)
3. ä¿¡è™Ÿå“è³ªçå‹µ (+0.0 ~ +1.0)
4. æ›æ‰‹æˆæœ¬æ‡²ç½° (-0.1 ~ 0.0)

ä¾æ“š:
- docs/stages/stage6-research-optimization.md æ›æ‰‹æ±ºç­–ç›®æ¨™
- 3GPP TS 38.133 (ä¿¡è™Ÿå“è³ªè©•ä¼°æ¨™æº–)

Author: ORBIT Engine Team
Created: 2025-10-02

ğŸ“ å­¸è¡“åˆè¦æ€§æª¢æŸ¥æé†’:
- çå‹µå‡½æ•¸åŸºæ–¼å¯¦éš›ä¿¡è™Ÿæ¸¬é‡æŒ‡æ¨™
- æ‰€æœ‰é–¾å€¼ä¾†è‡ª 3GPP æ¨™æº–
"""

import logging
from typing import Dict, Any, Tuple


class RewardCalculator:
    """çå‹µè¨ˆç®—å™¨

    è² è²¬è¨ˆç®—å¼·åŒ–å­¸ç¿’ä¸­çš„çå‹µä¿¡è™Ÿï¼Œåæ˜ æ›æ‰‹æ±ºç­–çš„å“è³ªã€‚
    """

    def __init__(self):
        """åˆå§‹åŒ–è¨ˆç®—å™¨"""
        self.logger = logging.getLogger(__name__)

    def calculate_reward(
        self,
        current_state: Dict[str, Any],
        action: str,
        next_state: Dict[str, Any]
    ) -> Tuple[float, Dict[str, float]]:
        """è¨ˆç®—è¤‡åˆçå‹µå‡½æ•¸

        çå‹µçµ„æˆ:
        1. QoS æ”¹å–„çå‹µ (+0.0 ~ +1.0)
        2. ä¸­æ–·æ‡²ç½° (-0.5 ~ 0.0)
        3. ä¿¡è™Ÿå“è³ªçå‹µ (+0.0 ~ +1.0)
        4. æ›æ‰‹æˆæœ¬æ‡²ç½° (-0.1 ~ 0.0)

        Returns:
            (total_reward, reward_components)
        """
        reward_components = {}

        try:
            # 1. QoS æ”¹å–„
            current_signal = current_state.get('signal_quality', {})
            next_signal = next_state.get('signal_quality', {})

            current_rsrp = current_signal.get('rsrp_dbm', -120.0)
            next_rsrp = next_signal.get('rsrp_dbm', -120.0)

            rsrp_improvement = (next_rsrp - current_rsrp) / 20.0  # æ¨™æº–åŒ–åˆ° [-1, 1]
            reward_components['qos_improvement'] = max(0, rsrp_improvement)

            # 2. ä¸­æ–·æ‡²ç½°
            next_quality = next_state.get('quality_assessment', {})
            if not next_quality.get('is_usable', True):
                reward_components['interruption_penalty'] = -0.5
            else:
                reward_components['interruption_penalty'] = 0.0

            # 3. ä¿¡è™Ÿå“è³ªçå‹µ
            quality_score = next_quality.get('quality_score', 0.0)
            reward_components['signal_quality_gain'] = quality_score

            # 4. æ›æ‰‹æˆæœ¬
            if 'handover' in action:
                reward_components['handover_cost'] = -0.1
            else:
                reward_components['handover_cost'] = 0.0

            total_reward = sum(reward_components.values())

            return total_reward, reward_components

        except Exception as e:
            self.logger.warning(f"è¨ˆç®—çå‹µæ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
            return 0.0, {}
