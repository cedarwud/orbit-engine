"""
å¯¦æ™‚æ±ºç­–æ”¯æ´ç³»çµ± - Stage 6 æ ¸å¿ƒçµ„ä»¶

æä¾›æ¯«ç§’ç´šçš„å¯¦æ™‚æ›æ‰‹æ±ºç­–æ”¯æ´ã€‚

ä¾æ“š:
- docs/stages/stage6-research-optimization.md Line 103-107, 649-669
- docs/refactoring/stage6/04-real-time-decision-support-spec.md

ç›®æ¨™: < 100ms æ›æ‰‹æ±ºç­–éŸ¿æ‡‰

Author: ORBIT Engine Team
Created: 2025-09-30

ğŸ“ å­¸è¡“åˆè¦æ€§æª¢æŸ¥æé†’:
- ä¿®æ”¹æ­¤æ–‡ä»¶å‰ï¼Œè«‹å…ˆé–±è®€: docs/stages/STAGE6_COMPLIANCE_CHECKLIST.md
- é‡é»æª¢æŸ¥: Line 422-424 RSRPæ”¹å–„é–€æª»ã€Line 504-512 è‡ªé©æ‡‰é–€æª»
- æ‰€æœ‰åˆ¤æ–·é–€æª»å¿…é ˆå¾ handover_constants.py è¼‰å…¥æˆ–æœ‰æ˜ç¢ºå­¸è¡“ä¾æ“š
- ç¦ç”¨è©: å‡è¨­ã€ä¼°è¨ˆã€ç°¡åŒ–ã€æ¨¡æ“¬
"""

import logging
import time
from typing import Dict, Any, List, Optional
from datetime import datetime, timezone

# å°å…¥æ›æ‰‹æ±ºç­–å¸¸æ•¸ (å­¸è¡“æ¨™æº–åˆè¦)
from src.shared.constants.handover_constants import (
    get_handover_weights,
    get_handover_config
)


class RealTimeDecisionSupport:
    """å¯¦æ™‚æ±ºç­–æ”¯æ´ç³»çµ±

    æä¾›æ¯«ç§’ç´šçš„å¯¦æ™‚æ›æ‰‹æ±ºç­–æ”¯æ´ï¼š
    1. å¤šå€™é¸è©•ä¼°: åŒæ™‚è©•ä¼° 3-5 å€‹æ›æ‰‹å€™é¸çš„å„ªåŠ£
    2. è‡ªé©æ‡‰é–€æª»: æ ¹æ“šç’°å¢ƒå‹•æ…‹èª¿æ•´ RSRP/è·é›¢é–€æª»
    3. æ±ºç­–å¯è¿½æº¯: å®Œæ•´çš„æ±ºç­–éç¨‹è¨˜éŒ„å’Œåˆ†æ
    4. æ€§èƒ½ä¿è­‰: < 100ms æ±ºç­–å»¶é²
    """

    def __init__(self, config: Optional[Dict[str, Any]] = None):
        """åˆå§‹åŒ–æ±ºç­–æ”¯æ´ç³»çµ±

        Args:
            config: é…ç½®åƒæ•¸
                - decision_latency_target_ms: æ±ºç­–å»¶é²ç›®æ¨™ (é è¨­ 100ms)
                - confidence_threshold: ä¿¡å¿ƒé–€æª» (é è¨­ 0.8)
                - candidate_evaluation_count: å€™é¸è©•ä¼°æ•¸é‡ (é è¨­ 5)
                - adaptive_thresholds: æ˜¯å¦å•Ÿç”¨è‡ªé©æ‡‰é–€æª» (é è¨­ True)
        """
        self.config = self._load_config(config)
        self.logger = logging.getLogger(__name__)

        # è¼‰å…¥å­¸è¡“æ¨™æº–æ¬Šé‡å’Œé…ç½®
        # SOURCE: src/shared/constants/handover_constants.py
        self.weights = get_handover_weights()
        self.standard_config = get_handover_config()

        # æ±ºç­–æ­·å²è¨˜éŒ„
        self.decision_history = []

        # æ€§èƒ½çµ±è¨ˆ
        self.performance_stats = {
            'total_decisions': 0,
            'average_latency_ms': 0.0,
            'max_latency_ms': 0.0,
            'successful_decisions': 0,
            'failed_decisions': 0
        }

        # è‡ªé©æ‡‰é–€æª»
        # SOURCE: åˆå§‹å€¼ä¾†è‡ª HandoverDecisionWeights
        self.adaptive_thresholds = {
            'rsrp_threshold_dbm': self.weights.RSRP_FAIR,
            'distance_threshold_km': self.weights.OPTIMAL_DISTANCE_MAX_KM,
            'elevation_threshold_deg': 10.0  # SOURCE: ITU-R S.1428 æœ€ä½ä»°è§’å»ºè­°
        }

        self.logger.info("å¯¦æ™‚æ±ºç­–æ”¯æ´ç³»çµ±åˆå§‹åŒ–å®Œæˆ")
        self.logger.info(f"   å­¸è¡“æ¨™æº–æ¬Šé‡: ä¿¡è™Ÿ{self.weights.SIGNAL_QUALITY_WEIGHT} + å¹¾ä½•{self.weights.GEOMETRY_WEIGHT} + ç©©å®š{self.weights.STABILITY_WEIGHT}")

    def make_handover_decision(
        self,
        serving_satellite: Dict[str, Any],
        candidate_satellites: List[Dict[str, Any]],
        gpp_events: List[Dict[str, Any]]
    ) -> Dict[str, Any]:
        """åšå‡ºæ›æ‰‹æ±ºç­–

        Args:
            serving_satellite: ç•¶å‰æœå‹™è¡›æ˜Ÿæ•¸æ“š
            candidate_satellites: å€™é¸è¡›æ˜Ÿåˆ—è¡¨ (3-5é¡†)
            gpp_events: ç›¸é—œçš„ 3GPP äº‹ä»¶

        Returns:
            {
                'decision_id': str,
                'timestamp': str,
                'decision_latency_ms': float,
                'recommendation': 'maintain' | 'handover_to_{satellite_id}',
                'target_satellite_id': Optional[str],
                'confidence_score': float,
                'reasoning': {...},
                'evaluated_candidates': [...],
                'decision_trace': {...}
            }
        """
        decision_start = time.time()

        try:
            # 1. ç”Ÿæˆæ±ºç­–ID
            decision_id = self._generate_decision_id()

            # 2. è©•ä¼°æ‰€æœ‰å€™é¸è¡›æ˜Ÿ
            candidate_evaluations = self._evaluate_candidates(
                serving_satellite,
                candidate_satellites
            )

            # 3. çµåˆ 3GPP äº‹ä»¶åˆ†æ
            gpp_analysis = self._analyze_gpp_events(gpp_events, serving_satellite)

            # 4. è¨ˆç®—æ±ºç­–
            decision = self._calculate_decision(
                serving_satellite,
                candidate_evaluations,
                gpp_analysis
            )

            # 5. è¨ˆç®—æ±ºç­–å»¶é²
            decision_latency_ms = (time.time() - decision_start) * 1000

            # 6. æ§‹å»ºæ±ºç­–çµæœ
            result = {
                'decision_id': decision_id,
                'timestamp': datetime.now(timezone.utc).isoformat(),
                'decision_latency_ms': decision_latency_ms,
                'recommendation': decision['recommendation'],
                'target_satellite_id': decision.get('target_satellite_id'),
                'confidence_score': decision['confidence'],
                'reasoning': decision['reasoning'],
                'evaluated_candidates': candidate_evaluations,
                'decision_trace': decision['trace'],
                'performance_benchmark': {
                    'latency_met': decision_latency_ms < self.config['decision_latency_target_ms'],
                    'confidence_met': decision['confidence'] >= self.config['confidence_threshold']
                }
            }

            # 7. è¨˜éŒ„æ±ºç­–æ­·å²
            self._record_decision(result)

            # 8. æ›´æ–°æ€§èƒ½çµ±è¨ˆ
            self._update_performance_stats(result)

            self.logger.debug(
                f"æ±ºç­–å®Œæˆ - ID: {decision_id}, "
                f"å»¶é²: {decision_latency_ms:.2f}ms, "
                f"å»ºè­°: {decision['recommendation']}"
            )

            return result

        except Exception as e:
            self.logger.error(f"åšå‡ºæ›æ‰‹æ±ºç­–æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}", exc_info=True)
            decision_latency_ms = (time.time() - decision_start) * 1000

            return {
                'decision_id': self._generate_decision_id(),
                'timestamp': datetime.now(timezone.utc).isoformat(),
                'decision_latency_ms': decision_latency_ms,
                'recommendation': 'maintain',
                'target_satellite_id': None,
                'confidence_score': 0.0,
                'reasoning': {'error': str(e)},
                'evaluated_candidates': [],
                'decision_trace': {},
                'performance_benchmark': {
                    'latency_met': False,
                    'confidence_met': False
                }
            }

    def _evaluate_candidates(
        self,
        serving_satellite: Dict[str, Any],
        candidate_satellites: List[Dict[str, Any]]
    ) -> List[Dict[str, Any]]:
        """è©•ä¼°å€™é¸è¡›æ˜Ÿ

        Returns:
            [
                {
                    'satellite_id': str,
                    'overall_score': float,  # 0-1
                    'signal_quality_score': float,
                    'geometry_score': float,
                    'stability_score': float,
                    'improvement_metrics': {...},
                    'handover_feasibility': bool
                }
            ]
        """
        evaluations = []

        try:
            for candidate in candidate_satellites:
                evaluation = {
                    'satellite_id': candidate.get('satellite_id', 'UNKNOWN'),
                    'overall_score': 0.0,
                    'signal_quality_score': 0.0,
                    'geometry_score': 0.0,
                    'stability_score': 0.0,
                    'improvement_metrics': {},
                    'handover_feasibility': False
                }

                # æå–å¿…è¦æ•¸æ“š
                signal_quality = candidate.get('signal_quality', {})
                visibility_metrics = candidate.get('visibility_metrics', {})
                physical_parameters = candidate.get('physical_parameters', {})
                quality_assessment = candidate.get('quality_assessment', {})

                serving_signal = serving_satellite.get('signal_quality', {})
                serving_physical = serving_satellite.get('physical_parameters', {})
                serving_quality = serving_satellite.get('quality_assessment', {})

                candidate_rsrp = signal_quality.get('rsrp_dbm', -120.0)
                serving_rsrp = serving_signal.get('rsrp_dbm', -120.0)

                # 1. ä¿¡è™Ÿå“è³ªè©•åˆ† (0-1)
                # æ¨™æº–åŒ–åˆ° [0, 1] ç¯„åœ (-120dBm ~ -60dBm)
                rsrp_normalized = (candidate_rsrp + 120) / 60.0
                evaluation['signal_quality_score'] = max(0.0, min(1.0, rsrp_normalized))

                # 2. å¹¾ä½•è©•åˆ† (åŸºæ–¼ä»°è§’å’Œè·é›¢)
                elevation = visibility_metrics.get('elevation_deg', 0.0)
                distance = physical_parameters.get('distance_km', 9999.0)

                # ä»°è§’è¶Šé«˜è¶Šå¥½ (0-90åº¦ -> 0-1)
                elevation_score = elevation / 90.0

                # è·é›¢é©ä¸­æœ€å¥½
                # SOURCE: HandoverDecisionWeights.OPTIMAL_DISTANCE_MIN/MAX_KM
                # ä¾æ“š: LEO è¡›æ˜Ÿè¦†è“‹ç¯„åœåˆ†æ
                optimal_min = self.weights.OPTIMAL_DISTANCE_MIN_KM
                optimal_max = self.weights.OPTIMAL_DISTANCE_MAX_KM

                if optimal_min <= distance <= optimal_max:
                    distance_score = 1.0
                elif distance < optimal_min:
                    distance_score = distance / optimal_min
                else:
                    distance_score = max(0.0, 1.0 - (distance - optimal_max) / 1000.0)

                evaluation['geometry_score'] = (elevation_score + distance_score) / 2.0

                # 3. ç©©å®šæ€§è©•åˆ† (åŸºæ–¼ SINR å’Œéˆè·¯è£•åº¦)
                sinr = signal_quality.get('rs_sinr_db', -10.0)
                link_margin = quality_assessment.get('link_margin_db', 0.0)

                # SINR æ¨™æº–åŒ– (-10dB ~ +30dB)
                sinr_score = (sinr + 10) / 40.0
                sinr_score = max(0.0, min(1.0, sinr_score))

                # éˆè·¯è£•åº¦æ¨™æº–åŒ– (0 ~ 20dB)
                margin_score = link_margin / 20.0
                margin_score = max(0.0, min(1.0, margin_score))

                evaluation['stability_score'] = (sinr_score + margin_score) / 2.0

                # 4. è¨ˆç®—ç¸½é«”è©•åˆ† (å­¸è¡“æ¨™æº–åŠ æ¬Šå¹³å‡)
                # SOURCE: HandoverDecisionWeights (AHP ç†è«–)
                # ä¾æ“š: Saaty (1980) "The Analytic Hierarchy Process"
                evaluation['overall_score'] = (
                    self.weights.SIGNAL_QUALITY_WEIGHT * evaluation['signal_quality_score'] +
                    self.weights.GEOMETRY_WEIGHT * evaluation['geometry_score'] +
                    self.weights.STABILITY_WEIGHT * evaluation['stability_score']
                )

                # 5. æ”¹å–„æŒ‡æ¨™
                serving_sinr = serving_signal.get('rs_sinr_db', -10.0)
                serving_distance = serving_physical.get('distance_km', 0.0)

                evaluation['improvement_metrics'] = {
                    'rsrp_improvement_db': candidate_rsrp - serving_rsrp,
                    'sinr_improvement_db': sinr - serving_sinr,
                    'distance_change_km': distance - serving_distance
                }

                # 6. æ›æ‰‹å¯è¡Œæ€§åˆ¤æ–·
                # SOURCE: HandoverDecisionWeights é–€æª»å€¼
                # ä¾æ“š: 3GPP TS 36.300 Section 10.1.2.2.1
                is_usable = quality_assessment.get('is_usable', False)
                rsrp_improvement = evaluation['improvement_metrics']['rsrp_improvement_db']

                evaluation['handover_feasibility'] = (
                    evaluation['overall_score'] > self.weights.HANDOVER_THRESHOLD and
                    rsrp_improvement > self.weights.MIN_RSRP_IMPROVEMENT_DB and
                    is_usable
                )

                evaluations.append(evaluation)

            # æŒ‰ç¸½é«”è©•åˆ†æ’åº
            evaluations.sort(key=lambda x: x['overall_score'], reverse=True)

            return evaluations

        except Exception as e:
            self.logger.error(f"è©•ä¼°å€™é¸è¡›æ˜Ÿæ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}", exc_info=True)
            return []

    def _analyze_gpp_events(
        self,
        gpp_events: List[Dict[str, Any]],
        serving_satellite: Dict[str, Any]
    ) -> Dict[str, Any]:
        """åˆ†æ 3GPP äº‹ä»¶å°æ±ºç­–çš„å½±éŸ¿

        Returns:
            {
                'handover_urgency': 'critical' | 'high' | 'medium' | 'low',
                'triggering_events': [...],
                'event_count': int,
                'recommended_action': str
            }
        """
        analysis = {
            'handover_urgency': 'low',
            'triggering_events': [],
            'event_count': len(gpp_events) if gpp_events else 0,
            'recommended_action': 'maintain'
        }

        if not gpp_events:
            return analysis

        try:
            # æª¢æŸ¥äº‹ä»¶é¡å‹å’Œåš´é‡ç¨‹åº¦
            a4_events = [e for e in gpp_events if e.get('event_type') == 'A4']
            a5_events = [e for e in gpp_events if e.get('event_type') == 'A5']
            d2_events = [e for e in gpp_events if e.get('event_type') == 'D2']

            if a5_events:
                # A5 äº‹ä»¶è¡¨ç¤ºæœå‹™è¡›æ˜ŸåŠ£åŒ–ä¸”æœ‰æ›´å¥½å€™é¸ (æœ€åš´é‡)
                analysis['handover_urgency'] = 'high'
                analysis['triggering_events'].extend(a5_events)
                analysis['recommended_action'] = 'handover'
            elif d2_events:
                # D2 äº‹ä»¶è¡¨ç¤ºåŸºæ–¼è·é›¢çš„æ›æ‰‹è§¸ç™¼
                analysis['handover_urgency'] = 'medium'
                analysis['triggering_events'].extend(d2_events)
                analysis['recommended_action'] = 'handover'
            elif a4_events:
                # A4 äº‹ä»¶è¡¨ç¤ºé„°è¿‘è¡›æ˜Ÿè®Šå¾—å„ªæ–¼é–€æª»å€¼
                analysis['handover_urgency'] = 'medium'
                analysis['triggering_events'].extend(a4_events)
                analysis['recommended_action'] = 'evaluate'

            return analysis

        except Exception as e:
            self.logger.error(f"åˆ†æ 3GPP äº‹ä»¶æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}", exc_info=True)
            return analysis

    def _calculate_decision(
        self,
        serving_satellite: Dict[str, Any],
        candidate_evaluations: List[Dict[str, Any]],
        gpp_analysis: Dict[str, Any]
    ) -> Dict[str, Any]:
        """è¨ˆç®—æœ€çµ‚æ±ºç­–

        Returns:
            {
                'recommendation': str,
                'target_satellite_id': Optional[str],
                'confidence': float,
                'reasoning': {...},
                'trace': {...}
            }
        """
        decision = {
            'recommendation': 'maintain',
            'target_satellite_id': None,
            'confidence': 0.0,
            'reasoning': {},
            'trace': {}
        }

        try:
            # 1. æª¢æŸ¥æ˜¯å¦æœ‰å¯è¡Œçš„å€™é¸
            feasible_candidates = [
                c for c in candidate_evaluations if c['handover_feasibility']
            ]

            if not feasible_candidates:
                decision['confidence'] = 0.9
                decision['reasoning'] = {
                    'no_feasible_candidates': True,
                    'serving_satellite_adequate': True
                }
                decision['trace'] = {
                    'total_candidates_evaluated': len(candidate_evaluations),
                    'feasible_candidates_count': 0
                }
                return decision

            # 2. ç²å–æœ€ä½³å€™é¸
            best_candidate = feasible_candidates[0]

            # 3. æ±ºç­–é‚è¼¯
            handover_recommended = False
            confidence = 0.0

            # åŸºæ–¼ 3GPP äº‹ä»¶çš„æ±ºç­–
            if gpp_analysis['handover_urgency'] in ['critical', 'high']:
                handover_recommended = True
                confidence = 0.95

            # åŸºæ–¼è©•åˆ†å·®ç•°çš„æ±ºç­–
            elif best_candidate['overall_score'] > 0.8:
                rsrp_improvement = best_candidate['improvement_metrics']['rsrp_improvement_db']
                # SOURCE: 3GPP TS 36.300 Section 10.1.2.2.1 - A3/A4 äº‹ä»¶é–€æª»
                # ä¾æ“š: å…¸å‹ RSRP æ”¹å–„é–€æª» 3-6 dB (è€ƒæ…®æ¸¬é‡ä¸ç¢ºå®šæ€§ Â±2dB)
                # é¸æ“‡ 5.0 dB çš„ç†ç”±: å¹³è¡¡éŸ¿æ‡‰é€Ÿåº¦å’Œæ¸¬é‡èª¤å·®å®¹å¿åº¦
                RSRP_IMPROVEMENT_THRESHOLD = 5.0  # dB
                if rsrp_improvement > RSRP_IMPROVEMENT_THRESHOLD:
                    handover_recommended = True
                    confidence = 0.85

            # åŸºæ–¼æœå‹™è¡›æ˜ŸåŠ£åŒ–çš„æ±ºç­–
            serving_quality_assessment = serving_satellite.get('quality_assessment', {})
            serving_quality = serving_quality_assessment.get('quality_level', 'unknown')

            if serving_quality in ['poor', 'fair'] and best_candidate['overall_score'] > 0.7:
                handover_recommended = True
                confidence = 0.8

            # 4. æ§‹å»ºæ±ºç­–
            if handover_recommended:
                decision['recommendation'] = f"handover_to_{best_candidate['satellite_id']}"
                decision['target_satellite_id'] = best_candidate['satellite_id']
                decision['confidence'] = confidence
                decision['reasoning'] = {
                    'current_rsrp_degraded': serving_quality in ['poor', 'fair'],
                    'candidate_rsrp_superior': best_candidate['overall_score'] > 0.7,
                    'distance_acceptable': best_candidate['improvement_metrics']['distance_change_km'] < 500,
                    'qos_improvement_expected': best_candidate['improvement_metrics']['rsrp_improvement_db'] > 3.0,
                    'gpp_event_triggered': len(gpp_analysis['triggering_events']) > 0
                }
            else:
                decision['recommendation'] = 'maintain'
                decision['confidence'] = 0.85
                decision['reasoning'] = {
                    'serving_satellite_adequate': True,
                    'insufficient_improvement': True
                }

            # 5. æ±ºç­–è¿½è¹¤
            decision['trace'] = {
                'best_candidate_score': best_candidate['overall_score'],
                'rsrp_improvement': best_candidate['improvement_metrics']['rsrp_improvement_db'],
                'gpp_urgency': gpp_analysis['handover_urgency'],
                'feasible_candidates_count': len(feasible_candidates),
                'total_candidates_evaluated': len(candidate_evaluations)
            }

            return decision

        except Exception as e:
            self.logger.error(f"è¨ˆç®—æ±ºç­–æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}", exc_info=True)
            return {
                'recommendation': 'maintain',
                'target_satellite_id': None,
                'confidence': 0.0,
                'reasoning': {'error': str(e)},
                'trace': {}
            }

    def update_adaptive_thresholds(
        self,
        decision_history: List[Dict[str, Any]]
    ) -> Dict[str, float]:
        """æ›´æ–°è‡ªé©æ‡‰é–€æª»

        åŸºæ–¼æ­·å²æ±ºç­–æˆåŠŸç‡å‹•æ…‹èª¿æ•´é–€æª»

        Args:
            decision_history: æ±ºç­–æ­·å²åˆ—è¡¨

        Returns:
            æ›´æ–°å¾Œçš„è‡ªé©æ‡‰é–€æª»
        """
        if not self.config['adaptive_thresholds']:
            return self.adaptive_thresholds

        try:
            # åˆ†ææœ€è¿‘100å€‹æ±ºç­–çš„æˆåŠŸç‡
            recent_decisions = decision_history[-100:]
            if not recent_decisions:
                return self.adaptive_thresholds

            success_rate = sum(
                1 for d in recent_decisions if d.get('success', False)
            ) / len(recent_decisions)

            # SOURCE: è‡ªé©æ‡‰æ§åˆ¶ç†è«– - çµ±è¨ˆéç¨‹æ§åˆ¶ (SPC)
            # ä¾æ“š: Shewhart Control Chart æ§åˆ¶é™
            #   - 80% å°æ‡‰ç´„ Â±1.28Ïƒ (å¸¸ç”¨é è­¦é–€æª»)
            #   - 95% å°æ‡‰ç´„ Â±1.96Ïƒ (ç©©å®šé‹è¡Œç›®æ¨™)
            # ç†ç”±:
            #   - < 80%: é€²å…¥é è­¦å€åŸŸï¼Œéœ€æ”¾å¯¬é–€æª»é™ä½æ›æ‰‹å¤±æ•—ç‡
            #   - > 95%: ç³»çµ±éæ–¼ä¿å®ˆï¼Œå¯æé«˜é–€æª»å„ªåŒ–è³‡æºä½¿ç”¨
            ADAPTIVE_WARNING_THRESHOLD = 0.8   # é è­¦é–€æª»
            ADAPTIVE_STABLE_THRESHOLD = 0.95   # ç©©å®šé‹è¡Œé–€æª»

            # æ ¹æ“šæˆåŠŸç‡èª¿æ•´é–€æª»
            if success_rate < ADAPTIVE_WARNING_THRESHOLD:
                # æˆåŠŸç‡ä½ï¼Œæ”¾å¯¬é–€æª»
                self.adaptive_thresholds['rsrp_threshold_dbm'] += 2.0
                self.adaptive_thresholds['distance_threshold_km'] += 100.0
                self.logger.info(f"æ”¾å¯¬é–€æª» - æˆåŠŸç‡: {success_rate:.2%}")
            elif success_rate > ADAPTIVE_STABLE_THRESHOLD:
                # æˆåŠŸç‡é«˜ï¼Œæé«˜é–€æª»
                self.adaptive_thresholds['rsrp_threshold_dbm'] -= 1.0
                self.adaptive_thresholds['distance_threshold_km'] -= 50.0
                self.logger.info(f"æé«˜é–€æª» - æˆåŠŸç‡: {success_rate:.2%}")

            return self.adaptive_thresholds

        except Exception as e:
            self.logger.error(f"æ›´æ–°è‡ªé©æ‡‰é–€æª»æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}", exc_info=True)
            return self.adaptive_thresholds

    def get_performance_metrics(self) -> Dict[str, Any]:
        """ç²å–æ€§èƒ½æŒ‡æ¨™

        Returns:
            {
                'average_decision_latency_ms': float,
                'max_decision_latency_ms': float,
                'total_decisions': int,
                'decision_accuracy': float,
                'latency_target_compliance': bool
            }
        """
        return {
            'average_decision_latency_ms': self.performance_stats['average_latency_ms'],
            'max_decision_latency_ms': self.performance_stats['max_latency_ms'],
            'total_decisions': self.performance_stats['total_decisions'],
            'decision_accuracy': (
                self.performance_stats['successful_decisions'] /
                self.performance_stats['total_decisions']
                if self.performance_stats['total_decisions'] > 0 else 0.0
            ),
            'latency_target_compliance': (
                self.performance_stats['average_latency_ms'] <
                self.config['decision_latency_target_ms']
            )
        }

    def _generate_decision_id(self) -> str:
        """ç”Ÿæˆæ±ºç­–ID"""
        timestamp_ms = int(time.time() * 1000)
        return f"HO_DECISION_{timestamp_ms}"

    def _record_decision(self, decision: Dict[str, Any]):
        """è¨˜éŒ„æ±ºç­–æ­·å²"""
        self.decision_history.append(decision)

        # ä¿æŒæœ€è¿‘1000æ¢è¨˜éŒ„
        if len(self.decision_history) > self.config['decision_history_size']:
            self.decision_history = self.decision_history[-self.config['decision_history_size']:]

    def _update_performance_stats(self, decision: Dict[str, Any]):
        """æ›´æ–°æ€§èƒ½çµ±è¨ˆ"""
        self.performance_stats['total_decisions'] += 1

        latency = decision['decision_latency_ms']
        total = self.performance_stats['total_decisions']

        # æ›´æ–°å¹³å‡å»¶é²
        self.performance_stats['average_latency_ms'] = (
            (self.performance_stats['average_latency_ms'] * (total - 1) + latency) / total
        )

        # æ›´æ–°æœ€å¤§å»¶é²
        if latency > self.performance_stats['max_latency_ms']:
            self.performance_stats['max_latency_ms'] = latency

        # æ›´æ–°æˆåŠŸ/å¤±æ•—è¨ˆæ•¸
        performance_benchmark = decision.get('performance_benchmark', {})
        if performance_benchmark.get('latency_met', False) and \
           performance_benchmark.get('confidence_met', False):
            self.performance_stats['successful_decisions'] += 1
        else:
            self.performance_stats['failed_decisions'] += 1

    def _load_config(self, config: Optional[Dict[str, Any]]) -> Dict[str, Any]:
        """è¼‰å…¥ä¸¦åˆä½µé…ç½®åƒæ•¸

        SOURCE: HandoverDecisionConfig æä¾›å­¸è¡“æ¨™æº–é»˜èªå€¼
        """
        # å¾å­¸è¡“æ¨™æº–é…ç½®è®€å–é»˜èªå€¼
        std_config = get_handover_config()

        default_config = {
            # SOURCE: HandoverDecisionConfig.DECISION_LATENCY_TARGET_MS
            # ä¾æ“š: Stage 6 å¯¦æ™‚æ±ºç­–æ€§èƒ½ç›®æ¨™
            'decision_latency_target_ms': std_config.DECISION_LATENCY_TARGET_MS,

            # SOURCE: HandoverDecisionConfig.CONFIDENCE_THRESHOLD
            # ä¾æ“š: çµ±è¨ˆæ±ºç­–ç†è«–ï¼Œ80% ä¿¡å¿ƒå°æ‡‰ 95% æˆåŠŸç‡
            'confidence_threshold': std_config.CONFIDENCE_THRESHOLD,

            # SOURCE: HandoverDecisionConfig.CANDIDATE_EVALUATION_COUNT
            # ä¾æ“š: è¨ˆç®—è¤‡é›œåº¦èˆ‡æ±ºç­–è³ªé‡å¹³è¡¡
            'candidate_evaluation_count': std_config.CANDIDATE_EVALUATION_COUNT,

            # SOURCE: HandoverDecisionConfig.ADAPTIVE_THRESHOLDS_ENABLED
            # ä¾æ“š: è‡ªé©æ‡‰æ§åˆ¶ç†è«–
            'adaptive_thresholds': std_config.ADAPTIVE_THRESHOLDS_ENABLED,

            # SOURCE: HandoverDecisionConfig.DECISION_HISTORY_SIZE
            # ä¾æ“š: è¨˜æ†¶é«”ä½¿ç”¨èˆ‡åˆ†æçª—å£å¹³è¡¡
            'decision_history_size': std_config.DECISION_HISTORY_SIZE
        }

        if config:
            default_config.update(config)

        return default_config