"""
ğŸ”„ Stage 1: Main Processor (é‡æ§‹ç‰ˆæœ¬)

ç¬¦åˆæ–‡æª”è¦ç¯„çš„ä¸»è™•ç†å™¨ï¼Œå”èª¿å››å€‹æ ¸å¿ƒçµ„ä»¶ï¼š
1. TLE Loader - æª”æ¡ˆè®€å–å’Œè§£æ
2. Data Validator - æ ¼å¼é©—è­‰å’Œå“è³ªæª¢æŸ¥
3. Time Reference Manager - æ™‚é–“åŸºæº–å»ºç«‹
4. Main Processor - å”èª¿å’Œæµç¨‹æ§åˆ¶

Author: Claude (AI Assistant)
Created: 2025-09-24
Version: v2.0 (ç¬¦åˆ @orbit-engine/docs/stages/stage1-tle-loading.md)
"""

import logging
from datetime import datetime, timezone
from typing import Dict, List, Any, Optional
from pathlib import Path
import json

# å°å…¥v2.0æ¨¡çµ„åŒ–çµ„ä»¶
from .tle_data_loader import TLEDataLoader
from .data_validator import DataValidator
from .time_reference_manager import TimeReferenceManager

# å°å…¥æ¨™æº–æ¥å£
from shared.interfaces.processor_interface import ProcessingResult, ProcessingStatus, ProcessingMetrics
from shared.base_processor import BaseStageProcessor


logger = logging.getLogger(__name__)


class Stage1MainProcessor(BaseStageProcessor):
    """
    ğŸ—ï¸ Stage 1: Main Processor (v2.0æ¶æ§‹)

    æ–‡æª”åƒè€ƒ: @orbit-engine/docs/stages/stage1-tle-loading.md

    ğŸ“‹ æ ¸å¿ƒè·è²¬:
    - å”èª¿å››å€‹å­çµ„ä»¶çš„åŸ·è¡Œé †åº
    - æ•¸æ“šæµæ§åˆ¶
    - éŒ¯èª¤è™•ç†èˆ‡å›å ±
    - æ€§èƒ½ç›£æ§
    """

    def __init__(self, config: Optional[Dict[str, Any]] = None):
        super().__init__(stage_number=1, stage_name="tle_data_loading", config=config or {})

        # åˆå§‹åŒ–v2.0æ¨¡çµ„åŒ–çµ„ä»¶
        self.tle_loader = TLEDataLoader()
        self.data_validator = DataValidator()
        self.time_manager = TimeReferenceManager()

        logger.info("ğŸ—ï¸ Stage 1 Main Processor å·²åˆå§‹åŒ– (v2.0æ¶æ§‹)")

    def process(self, input_data: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
        """
        ğŸš€ Stage 1 ä¸»è™•ç†æµç¨‹

        æŒ‰ç…§æ–‡æª”v2.0è¦ç¯„åŸ·è¡Œå››éšæ®µè™•ç†ï¼š
        Phase 1: TLEæ•¸æ“šè¼‰å…¥
        Phase 2: æ•¸æ“šé©—è­‰
        Phase 3: æ™‚é–“åŸºæº–å»ºç«‹
        Phase 4: çµæœæ•´åˆ

        Args:
            input_data: è¼¸å…¥æ•¸æ“š (é€šå¸¸ç‚ºç©ºï¼Œå¾TLEæ–‡ä»¶è®€å–)

        Returns:
            Dict: è™•ç†çµæœ
        """
        start_time = datetime.now(timezone.utc)

        try:
            logger.info("ğŸš€ é–‹å§‹ Stage 1 Main Processor è™•ç†æµç¨‹...")

            # === Phase 1: åŸ·è¡ŒTLEæ•¸æ“šè¼‰å…¥ ===
            logger.info("ğŸ“ Phase 1: åŸ·è¡ŒTLEæ•¸æ“šè¼‰å…¥...")
            scan_result = self.tle_loader.scan_tle_data()
            satellites_data = self.tle_loader.load_satellite_data(
                scan_result,
                sample_mode=self.config.get('sample_mode', False),
                sample_size=self.config.get('sample_size', 500)
            )
            logger.info(f"âœ… Phase 1 å®Œæˆ: è¼‰å…¥ {len(satellites_data)} é¡†è¡›æ˜Ÿæ•¸æ“š")

            # === Phase 2: åŸ·è¡Œæ•¸æ“šé©—è­‰ ===
            logger.info("ğŸ” Phase 2: åŸ·è¡Œæ•¸æ“šé©—è­‰...")
            validation_result = self.data_validator.validate_tle_dataset(satellites_data)
            logger.info(f"âœ… æ•¸æ“šé©—è­‰é€šé (Grade: {validation_result.get('overall_grade', 'Unknown')})")

            # === Phase 3: åŸ·è¡Œæ™‚é–“åŸºæº–å»ºç«‹ ===
            logger.info("â° Phase 3: åŸ·è¡Œæ™‚é–“åŸºæº–å»ºç«‹...")
            time_metadata = self.time_manager.establish_time_reference(satellites_data)
            logger.info(f"âœ… æ™‚é–“åŸºæº–å»ºç«‹æˆåŠŸ: {len(satellites_data)}ç­†è¨˜éŒ„")

            # === Phase 4: åŸ·è¡Œçµæœæ•´åˆ ===
            logger.info("ğŸ“¦ Phase 4: åŸ·è¡Œçµæœæ•´åˆ...")
            result = self._integrate_results(satellites_data, validation_result, time_metadata, start_time)
            logger.info("âœ… Phase 4 å®Œæˆ: çµæœæ•´åˆæˆåŠŸ")

            # === Phase 5: ä¿å­˜è™•ç†çµæœ ===
            try:
                output_path = self.save_results(result)
                logger.info(f"ğŸ“„ Stage 1 é‡æ§‹çµæœå·²ä¿å­˜è‡³: {output_path}")
            except Exception as save_error:
                logger.warning(f"âš ï¸ çµæœä¿å­˜å¤±æ•—: {save_error}")
                # ä¸å½±éŸ¿ä¸»è¦è™•ç†æµç¨‹

            end_time = datetime.now(timezone.utc)
            duration = (end_time - start_time).total_seconds()
            logger.info(f"âœ… Stage 1 Main Processor è™•ç†å®Œæˆ ({duration:.2f}s)")

            return result

        except Exception as e:
            logger.error(f"âŒ Stage 1 è™•ç†å¤±æ•—: {e}")
            return {
                'stage': 1,
                'stage_name': 'tle_data_loading',
                'status': 'failed',
                'error': str(e),
                'satellites': [],
                'metadata': {
                    'processing_duration': (datetime.now(timezone.utc) - start_time).total_seconds()
                }
            }

    def _integrate_results(self, satellites_data: List[Dict], validation_result: Dict, time_metadata: Dict, start_time: datetime) -> Dict[str, Any]:
        """
        æ•´åˆè™•ç†çµæœ

        Args:
            satellites_data: è¡›æ˜Ÿæ•¸æ“šåˆ—è¡¨
            validation_result: é©—è­‰çµæœ
            time_metadata: æ™‚é–“åŸºæº–å…ƒæ•¸æ“š
            start_time: è™•ç†é–‹å§‹æ™‚é–“

        Returns:
            Dict: æ•´åˆå¾Œçš„çµæœ
        """
        end_time = datetime.now(timezone.utc)

        # æº–å‚™å…ƒæ•¸æ“š
        metadata = {
            'total_satellites': len(satellites_data),
            'processing_start_time': start_time.isoformat(),
            'processing_end_time': end_time.isoformat(),
            'processing_duration_seconds': (end_time - start_time).total_seconds(),
        }

        # æ•´åˆæ™‚é–“åŸºæº–å…ƒæ•¸æ“š
        metadata.update(time_metadata)

        # æ·»åŠ æ¨™æº–åŒ–çš„æ™‚é–“åŸºæº–å­—æ®µä¾›é©—è­‰ä½¿ç”¨
        if 'primary_epoch_time' in metadata:
            metadata['calculation_base_time'] = metadata['primary_epoch_time']
            metadata['tle_epoch_time'] = metadata['primary_epoch_time']

            # ğŸ¯ æ–‡æª”è¦æ±‚ï¼šæ·»åŠ æ™‚é–“åŸºæº–ä¾†æºå’Œç¹¼æ‰¿ä¿¡æ¯
            metadata['time_base_source'] = 'tle_epoch_derived'
            metadata['tle_epoch_compliance'] = True

            # v6.0 è¦æ±‚ï¼šStage 1 æ™‚é–“ç¹¼æ‰¿ä¿¡æ¯
            metadata['stage1_time_inheritance'] = {
                'exported_time_base': metadata['primary_epoch_time'],
                'inheritance_ready': True,
                'calculation_reference': 'tle_epoch_based'
            }

        # æ•´åˆé©—è­‰çµæœ
        metadata['validation_summary'] = validation_result

        # æ·»åŠ æ€§èƒ½çµ±è¨ˆ
        if hasattr(self.tle_loader, 'get_load_statistics'):
            metadata['performance_metrics'] = self.tle_loader.get_load_statistics()

        return {
            'stage': 1,
            'stage_name': 'tle_data_loading',
            'satellites': satellites_data,
            'metadata': metadata,
            'processing_stats': {
                'stage': 1,
                'stage_name': 'tle_data_loading',
                'processing_duration': (end_time - start_time).total_seconds(),
                'start_time': start_time.isoformat(),
                'end_time': end_time.isoformat()
            }
        }

    def validate_input(self, input_data: Any) -> Dict[str, Any]:
        """é©—è­‰è¼¸å…¥æ•¸æ“š"""
        return {'valid': True, 'errors': [], 'warnings': []}

    def validate_output(self, output_data: Any) -> Dict[str, Any]:
        """é©—è­‰è¼¸å‡ºæ•¸æ“š"""
        satellites = output_data.get('satellites', []) if isinstance(output_data, dict) else []
        return {'valid': len(satellites) > 0, 'errors': [] if len(satellites) > 0 else ['ç„¡è¡›æ˜Ÿæ•¸æ“š'], 'warnings': []}


# é‡æ§‹è™•ç†å™¨é¡åˆ¥
class Stage1RefactoredProcessor(BaseStageProcessor):
    """
    ğŸ“‹ Stage 1 é‡æ§‹è™•ç†å™¨

    æä¾›æ¨™æº– ProcessingResult æ¥å£ï¼ŒåŒ…è£ç¾æœ‰çš„ Stage1MainProcessor
    """

    def __init__(self, config: Optional[Dict[str, Any]] = None):
        super().__init__(
            stage_number=1,
            stage_name="refactored_tle_data_loading",
            config=config
        )

        # ä½¿ç”¨ç¾æœ‰çš„ä¸»è™•ç†å™¨ä½œç‚ºæ ¸å¿ƒ
        self.main_processor = Stage1MainProcessor(config)

        self.logger.info("ğŸ”§ Stage 1 é‡æ§‹è™•ç†å™¨åˆå§‹åŒ–å®Œæˆ")

        # åœ¨è™•ç†å‰æ¸…ç†èˆŠè¼¸å‡ºå’Œé©—è­‰å¿«ç…§
        self._cleanup_old_outputs()
        self._cleanup_validation_snapshots()

    def process(self, input_data: Optional[Any] = None) -> ProcessingResult:
        """
        åŸ·è¡Œ Stage 1 é‡æ§‹è™•ç†æµç¨‹

        Returns:
            ProcessingResult: æ¨™æº–åŒ–è™•ç†çµæœ
        """
        start_time = datetime.now(timezone.utc)

        try:
            self.logger.info("ğŸ”§ é–‹å§‹ Stage 1 é‡æ§‹è™•ç†...")

            # ä½¿ç”¨ä¸»è™•ç†å™¨åŸ·è¡Œæ ¸å¿ƒé‚è¼¯
            core_result = self.main_processor.process(input_data)

            # å‰µå»ºæ¨™æº–åŒ– ProcessingResult
            processing_result = ProcessingResult(
                status=ProcessingStatus.SUCCESS if core_result.get('error') is None else ProcessingStatus.FAILED,
                data=core_result,
                metadata=core_result.get('metadata', {}),
                errors=[core_result['error']] if core_result.get('error') else [],
                warnings=[]
            )

            # è¨­ç½®è™•ç†æŒ‡æ¨™
            end_time = datetime.now(timezone.utc)
            duration = (end_time - start_time).total_seconds()

            processing_result.metrics = ProcessingMetrics(
                start_time=start_time,
                end_time=end_time,
                duration_seconds=duration,
                input_records=0,
                output_records=len(core_result.get('satellites', [])),
                processed_records=len(core_result.get('satellites', [])),
                success_rate=1.0 if not core_result.get('error') else 0.0,
                throughput_per_second=len(core_result.get('satellites', [])) / max(duration, 0.001)
            )

            # å¢å¼·å…ƒæ•¸æ“š
            processing_result.metadata.update({
                'refactored_version': True,
                'interface_compliance': 'BaseStageProcessor_v2.0'
            })

            # ä¿å­˜é©—è­‰å¿«ç…§ (æª”æ¡ˆä¿å­˜ç”±åº•å±¤ Stage1MainProcessor è™•ç†)
            try:
                snapshot_saved = self.save_validation_snapshot(processing_result.data)
                if snapshot_saved:
                    self.logger.info("ğŸ“· é‡æ§‹ç‰ˆé©—è­‰å¿«ç…§å·²ä¿å­˜")

            except Exception as save_error:
                self.logger.error(f"âš ï¸ å¿«ç…§ä¿å­˜å¤±æ•—: {save_error}")
                # ä¸å½±éŸ¿ä¸»è¦è™•ç†æµç¨‹ï¼Œåªè¨˜éŒ„è­¦å‘Š

            self.logger.info(f"âœ… Stage 1 é‡æ§‹è™•ç†å®Œæˆï¼Œè€—æ™‚: {duration:.3f}ç§’")
            return processing_result

        except Exception as e:
            self.logger.error(f"âŒ Stage 1 é‡æ§‹è™•ç†å¤±æ•—: {e}")
            return ProcessingResult(
                status=ProcessingStatus.FAILED,
                data={},
                metadata={'error': str(e), 'refactored_version': True},
                errors=[str(e)],
                warnings=[]
            )

    def run_validation_checks(self, results: Dict[str, Any]) -> Dict[str, Any]:
        """åŸ·è¡Œ Stage 1 å°ˆç”¨é©—è­‰æª¢æŸ¥"""
        satellites = results.get('satellites', [])
        metadata = results.get('metadata', {})

        # åŸºæœ¬é©—è­‰æª¢æŸ¥
        checks_passed = 0
        total_checks = 5

        validation_details = {}

        # 1. æ•¸æ“šè¼‰å…¥æª¢æŸ¥
        if len(satellites) > 0:
            checks_passed += 1
            validation_details['tle_format_validation'] = {'passed': True, 'satellite_count': len(satellites)}
        else:
            validation_details['tle_format_validation'] = {'passed': False, 'error': 'ç„¡è¡›æ˜Ÿæ•¸æ“š'}

        # 2. checksumé©—è­‰ (å®Œæ•´å¯¦ä½œ)
        checksum_results = self._verify_tle_checksums(satellites)
        if checksum_results['pass_rate'] >= 0.95:  # 95% é€šéç‡è¦æ±‚
            checks_passed += 1
        validation_details['tle_checksum_verification'] = checksum_results

        # 3. æ•¸æ“šå®Œæ•´æ€§
        required_fields = ['stage', 'satellites', 'metadata']
        missing_fields = [f for f in required_fields if f not in results]
        if not missing_fields:
            checks_passed += 1
            validation_details['data_completeness_check'] = {'passed': True, 'completeness_score': 1.0}
        else:
            validation_details['data_completeness_check'] = {'passed': False, 'missing_fields': missing_fields}

        # 4. æ™‚é–“åŸºæº–æª¢æŸ¥
        time_fields = ['calculation_base_time', 'tle_epoch_time']
        missing_time = [f for f in time_fields if f not in metadata]
        if not missing_time:
            checks_passed += 1
            validation_details['time_base_establishment'] = {'passed': True, 'time_base_established': True}
        else:
            validation_details['time_base_establishment'] = {'passed': False, 'missing_time_fields': missing_time}

        # 5. è¡›æ˜Ÿæ•¸æ“šçµæ§‹æª¢æŸ¥
        if satellites and all(key in satellites[0] for key in ['satellite_id', 'tle_line1', 'tle_line2']):
            checks_passed += 1
            validation_details['satellite_data_structure'] = {'passed': True, 'valid_satellites': len(satellites)}
        else:
            validation_details['satellite_data_structure'] = {'passed': False, 'error': 'è¡›æ˜Ÿæ•¸æ“šçµæ§‹ä¸å®Œæ•´'}

        success_rate = checks_passed / total_checks

        # ç¢ºå®šé©—è­‰ç‹€æ…‹å’Œå“è³ªç­‰ç´š (ç¬¦åˆæ–‡æª” A+/A/B/C/F æ¨™æº–)
        if success_rate >= 1.0:
            validation_status = 'passed'
            overall_status = 'PASS'
            quality_grade = 'A+'
        elif success_rate >= 0.95:
            validation_status = 'passed'
            overall_status = 'PASS'
            quality_grade = 'A'
        elif success_rate >= 0.8:
            validation_status = 'passed'
            overall_status = 'PASS'
            quality_grade = 'B'
        elif success_rate >= 0.7:
            validation_status = 'warning'
            overall_status = 'WARNING'
            quality_grade = 'C'
        else:
            validation_status = 'failed'
            overall_status = 'FAIL'
            quality_grade = 'F'

        return {
            'validation_status': validation_status,
            'overall_status': overall_status,
            'quality_grade': quality_grade,
            'success_rate': success_rate,
            'validation_details': {
                **validation_details,
                'success_rate': success_rate,
                'quality_grade': quality_grade
            }
        }

    def save_validation_snapshot(self, processing_results: Dict[str, Any]) -> bool:
        """ä¿å­˜é©—è­‰å¿«ç…§"""
        try:
            validation_results = self.run_validation_checks(processing_results)
            satellite_count = len(processing_results.get('satellites', []))

            snapshot_data = {
                'stage': 1,
                'stage_name': 'refactored_tle_data_loading',
                'status': 'success' if validation_results['validation_status'] == 'passed' else 'failed',
                'timestamp': datetime.now(timezone.utc).isoformat(),
                'processing_duration': processing_results.get('metadata', {}).get('processing_duration_seconds', 0),
                'data_summary': {
                    'has_data': satellite_count > 0,
                    'satellite_count': satellite_count,
                    'data_keys': list(processing_results.keys()),
                    'metadata_keys': list(processing_results.get('metadata', {}).keys())
                },
                'validation_passed': validation_results['validation_status'] == 'passed',
                'next_stage_ready': satellite_count > 0 and validation_results['validation_status'] == 'passed',
                'refactored_version': True,
                'interface_compliance': True,
                'errors': [],
                'warnings': []
            }

            snapshot_path = self.validation_dir / 'stage1_validation.json'
            with open(snapshot_path, 'w', encoding='utf-8') as f:
                json.dump(snapshot_data, f, indent=2, ensure_ascii=False, default=str)

            self.logger.info(f"ğŸ“‹ é©—è­‰å¿«ç…§å·²ä¿å­˜è‡³: {snapshot_path}")
            return True

        except Exception as e:
            self.logger.error(f"âŒ å¿«ç…§ä¿å­˜å¤±æ•—: {e}")
            return False

    def validate_input(self, input_data: Any) -> Dict[str, Any]:
        """é©—è­‰è¼¸å…¥æ•¸æ“š"""
        return {
            'valid': True,
            'errors': [],
            'warnings': []
        }

    def validate_output(self, output_data: Any) -> Dict[str, Any]:
        """é©—è­‰è¼¸å‡ºæ•¸æ“š"""
        satellites = output_data.get('satellites', []) if isinstance(output_data, dict) else []
        return {
            'valid': len(satellites) > 0,
            'errors': [] if len(satellites) > 0 else ['ç„¡è¡›æ˜Ÿæ•¸æ“š'],
            'warnings': [],
            'satellite_count': len(satellites)
        }

    def save_results(self, results: Dict[str, Any]) -> str:
        """
        ä¿å­˜è™•ç†çµæœ (é‡æ§‹ç‰ˆæœ¬)

        Args:
            results: è™•ç†çµæœæ•¸æ“š

        Returns:
            str: è¼¸å‡ºæª”æ¡ˆè·¯å¾‘
        """
        try:
            # ç”Ÿæˆæ™‚é–“æˆ³æª”å (æ¨™æº–æ ¼å¼)
            from datetime import datetime
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            output_filename = f"tle_data_loading_output_{timestamp}.json"
            output_path = self.output_dir / output_filename

            # ç¢ºä¿è¼¸å‡ºç›®éŒ„å­˜åœ¨
            self.output_dir.mkdir(parents=True, exist_ok=True)

            # ä¿å­˜çµæœ
            import json
            with open(output_path, 'w', encoding='utf-8') as f:
                json.dump(results, f, indent=2, ensure_ascii=False, default=str)

            self.logger.info(f"ğŸ“„ Stage 1 é‡æ§‹çµæœå·²ä¿å­˜è‡³: {output_path}")
            return str(output_path)

        except Exception as e:
            self.logger.error(f"âŒ ä¿å­˜çµæœå¤±æ•—: {e}")
            raise RuntimeError(f"Stage 1 çµæœä¿å­˜å¤±æ•—: {e}")

    def _cleanup_old_outputs(self) -> None:
        """æ¸…ç†èˆŠçš„è¼¸å‡ºæª”æ¡ˆ"""
        try:
            if not self.output_dir.exists():
                return

            # æ¸…ç†æ‰€æœ‰èˆŠçš„è¼¸å‡ºæª”æ¡ˆ
            import glob
            import os

            # æŸ¥æ‰¾æ‰€æœ‰è¼¸å‡ºæª”æ¡ˆ
            output_patterns = [
                "tle_data_loading_output_*.json",
                "tle_orbital_calculation_output*.json",
                "data_loading_output_*.json",
                "refactored_tle_data_loading_output_*.json"  # æ¸…ç†èˆŠçš„é‡æ§‹æª”æ¡ˆ
            ]

            all_files = []
            for pattern in output_patterns:
                files = glob.glob(str(self.output_dir / pattern))
                all_files.extend(files)

            if not all_files:
                return

            # åˆªé™¤æ‰€æœ‰èˆŠè¼¸å‡ºæª”æ¡ˆ
            deleted_count = 0
            for file_path in all_files:
                try:
                    os.remove(file_path)
                    deleted_count += 1
                    self.logger.debug(f"ğŸ—‘ï¸ å·²åˆªé™¤èˆŠè¼¸å‡ºæª”æ¡ˆ: {os.path.basename(file_path)}")
                except Exception as e:
                    self.logger.warning(f"âš ï¸ ç„¡æ³•åˆªé™¤æª”æ¡ˆ {file_path}: {e}")

            if deleted_count > 0:
                self.logger.info(f"ğŸ§¹ æ¸…ç†å®Œæˆ: åˆªé™¤æ‰€æœ‰ {deleted_count} å€‹èˆŠè¼¸å‡ºæª”æ¡ˆ")

        except Exception as e:
            self.logger.warning(f"âš ï¸ æ¸…ç†èˆŠè¼¸å‡ºæ™‚å‡ºç¾å•é¡Œ: {e}")

    def _cleanup_validation_snapshots(self) -> None:
        """æ¸…ç†èˆŠçš„é©—è­‰å¿«ç…§æª”æ¡ˆ"""
        try:
            if not self.validation_dir.exists():
                return

            import glob
            import os

            # æŸ¥æ‰¾ Stage 1 ç›¸é—œçš„é©—è­‰å¿«ç…§æª”æ¡ˆ
            snapshot_patterns = [
                "stage1_validation*.json",
                "*stage1*.json"
            ]

            all_snapshots = []
            for pattern in snapshot_patterns:
                files = glob.glob(str(self.validation_dir / pattern))
                all_snapshots.extend(files)

            if not all_snapshots:
                return

            # åˆªé™¤æ‰€æœ‰èˆŠçš„é©—è­‰å¿«ç…§
            deleted_count = 0
            for file_path in all_snapshots:
                try:
                    os.remove(file_path)
                    deleted_count += 1
                    self.logger.debug(f"ğŸ—‘ï¸ å·²åˆªé™¤èˆŠé©—è­‰å¿«ç…§: {os.path.basename(file_path)}")
                except Exception as e:
                    self.logger.warning(f"âš ï¸ ç„¡æ³•åˆªé™¤é©—è­‰å¿«ç…§ {file_path}: {e}")

            if deleted_count > 0:
                self.logger.info(f"ğŸ§¹ æ¸…ç†é©—è­‰å¿«ç…§å®Œæˆ: åˆªé™¤ {deleted_count} å€‹èˆŠå¿«ç…§æª”æ¡ˆ")

        except Exception as e:
            self.logger.warning(f"âš ï¸ æ¸…ç†é©—è­‰å¿«ç…§æ™‚å‡ºç¾å•é¡Œ: {e}")

    def _verify_tle_checksums(self, satellites: List[Dict]) -> Dict[str, Any]:
        """
        é©—è­‰ TLE æ•¸æ“šçš„ checksum

        å¯¦ä½œ Modulo 10 å®˜æ–¹ç®—æ³•

        Args:
            satellites: è¡›æ˜Ÿæ•¸æ“šåˆ—è¡¨

        Returns:
            Dict: checksum é©—è­‰çµæœ
        """
        if not satellites:
            return {
                'passed': False,
                'pass_rate': 0.0,
                'total_checked': 0,
                'valid_count': 0,
                'error': 'ç„¡è¡›æ˜Ÿæ•¸æ“šé€²è¡Œ checksum é©—è­‰'
            }

        total_lines = 0
        valid_lines = 0

        for satellite in satellites:
            # æª¢æŸ¥ Line 1
            line1 = satellite.get('tle_line1', '')
            if line1 and len(line1) >= 69:
                if self._calculate_tle_checksum(line1[:-1]) == int(line1[-1]):
                    valid_lines += 1
                total_lines += 1

            # æª¢æŸ¥ Line 2
            line2 = satellite.get('tle_line2', '')
            if line2 and len(line2) >= 69:
                if self._calculate_tle_checksum(line2[:-1]) == int(line2[-1]):
                    valid_lines += 1
                total_lines += 1

        pass_rate = valid_lines / max(total_lines, 1)

        return {
            'passed': pass_rate >= 0.95,
            'pass_rate': pass_rate,
            'total_checked': total_lines,
            'valid_count': valid_lines,
            'checksum_algorithm': 'modulo_10_official'
        }

    def _calculate_tle_checksum(self, line: str) -> int:
        """
        è¨ˆç®— TLE è¡Œçš„ checksum (å®˜æ–¹ Modulo 10 ç®—æ³•)

        åŸºæ–¼ NORAD/NASA å®˜æ–¹ TLE æ ¼å¼è¦ç¯„:
        - æ•¸å­— 0-9: åŠ ä¸Šæ•¸å­—å€¼
        - è² è™Ÿ '-': åŠ  1
        - æ­£è™Ÿ '+': åŠ  1
        - å…¶ä»–å­—ç¬¦: å¿½ç•¥

        åƒè€ƒ: https://celestrak.org/NORAD/documentation/tle-fmt.php

        Args:
            line: TLE è¡Œæ•¸æ“š (ä¸å« checksum ä½)

        Returns:
            int: è¨ˆç®—å¾—å‡ºçš„ checksum
        """
        checksum = 0
        for char in line:
            if char.isdigit():
                checksum += int(char)
            elif char == '-':
                checksum += 1  # è² è™Ÿç®—ä½œ 1
            elif char == '+':
                checksum += 1  # æ­£è™Ÿç®—ä½œ 1 (ä¿®å¾©: ä¹‹å‰éºæ¼)
            # å…¶ä»–å­—ç¬¦ (å­—æ¯ã€ç©ºæ ¼ã€å¥é»ç­‰) è¢«å¿½ç•¥

        return checksum % 10


# å·¥å» å‡½æ•¸
def create_stage1_refactored_processor(config: Optional[Dict[str, Any]] = None) -> Stage1RefactoredProcessor:
    """å‰µå»ºé‡æ§‹å¾Œçš„ Stage 1 è™•ç†å™¨å¯¦ä¾‹"""
    return Stage1RefactoredProcessor(config=config)


def create_stage1_main_processor(config: Optional[Dict[str, Any]] = None) -> Stage1MainProcessor:
    """å‰µå»º Stage 1 ä¸»è™•ç†å™¨å¯¦ä¾‹ (å‘å¾Œå…¼å®¹)"""
    return Stage1MainProcessor(config=config)


if __name__ == "__main__":
    # æ¸¬è©¦é‡æ§‹å¾Œçš„è™•ç†å™¨
    processor = create_stage1_refactored_processor({'sample_mode': True, 'sample_size': 10})
    result = processor.execute()
    print(f"é‡æ§‹è™•ç†çµæœ: {result.status} - {len(result.data.get('satellites', []))} é¡†è¡›æ˜Ÿ")