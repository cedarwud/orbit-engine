#!/usr/bin/env python3
"""
Stage 3: åº§æ¨™ç³»çµ±è½‰æ›å±¤è™•ç†å™¨ - v3.1 æ¨¡çµ„åŒ–æ¶æ§‹

ğŸ¯ v3.1 æ¶æ§‹æ ¸å¿ƒè·è²¬ï¼š
- å”èª¿å„å°ˆæ¥­æ¨¡çµ„å®Œæˆåº§æ¨™è½‰æ›æµç¨‹
- ç´” Skyfield å°ˆæ¥­ç´š TEMEâ†’WGS84 åº§æ¨™è½‰æ›
- è™•ç†æ‰€æœ‰è¡›æ˜Ÿï¼ˆç„¡å¯è¦‹æ€§ç¯©é¸ï¼Œå·²ç§»è‡³ Stage 4ï¼‰
- ä½¿ç”¨çœŸå¯¦ IERS åœ°çƒå®šå‘åƒæ•¸å’Œå®˜æ–¹ WGS84 åƒæ•¸
- ç¬¦åˆ IAU 2000/2006 æ¨™æº–

ğŸš« v3.1 æ¶æ§‹æ˜ç¢ºæ’é™¤ï¼š
- âŒ å¯è¦‹æ€§åˆ†æï¼ˆä»°è§’/æ–¹ä½è§’è¨ˆç®— â†’ Stage 4ï¼‰
- âŒ è¡›æ˜Ÿç¯©é¸ï¼ˆå‹•æ…‹æ± è¦åŠƒ â†’ Stage 4ï¼‰
- âŒ ä¿¡è™Ÿè¨ˆç®—ï¼ˆRSRP/RSRQ â†’ Stage 5ï¼‰
- âŒ äº‹ä»¶æª¢æ¸¬ï¼ˆ3GPP NTN â†’ Stage 6ï¼‰

âœ… åš´æ ¼éµå¾ª CRITICAL DEVELOPMENT PRINCIPLE:
- ä½¿ç”¨å®˜æ–¹ Skyfield å°ˆæ¥­åº«
- çœŸå¯¦ IERS åœ°çƒå®šå‘åƒæ•¸
- å®Œæ•´ IAU æ¨™æº–è½‰æ›éˆ
- å®˜æ–¹ WGS84 æ©¢çƒåƒæ•¸
- ç„¡ä»»ä½•ç¡¬ç·¨ç¢¼æˆ–ç°¡åŒ–

å­¸è¡“åˆè¦ï¼šGrade A æ¨™æº–ï¼Œç¬¦åˆ IAU 2000/2006 è¦ç¯„
æ¥å£æ¨™æº–ï¼š100% BaseStageProcessor åˆè¦

ğŸ—ï¸ v3.1 æ¨¡çµ„åŒ–æ¶æ§‹ï¼š
- Stage3DataValidator: è¼¸å…¥/è¼¸å‡ºé©—è­‰
- Stage3DataExtractor: TEME æ•¸æ“šæå–
- Stage3TransformationEngine: æ ¸å¿ƒåº§æ¨™è½‰æ›
- Stage3ComplianceValidator: å­¸è¡“åˆè¦æª¢æŸ¥
- Stage3ResultsManager: çµæœç®¡ç†
- GeometricPrefilter: å¹¾ä½•é ç¯©é¸ï¼ˆå„ªåŒ–ï¼‰
"""

import logging
from datetime import datetime, timezone
from typing import Dict, Any, Optional
from pathlib import Path

# çœŸå¯¦åº§æ¨™è½‰æ›å¼•æ“
try:
    from src.shared.coordinate_systems.iers_data_manager import get_iers_manager
    from src.shared.coordinate_systems.wgs84_manager import get_wgs84_manager
    from src.shared.coordinate_systems.skyfield_coordinate_engine import get_coordinate_engine
    from src.stages.stage3_coordinate_transformation.geometric_prefilter import create_geometric_prefilter
    REAL_COORDINATE_SYSTEM_AVAILABLE = True
except ImportError as e:
    logging.error(f"çœŸå¯¦åº§æ¨™ç³»çµ±æ¨¡çµ„æœªå®‰è£: {e}")
    REAL_COORDINATE_SYSTEM_AVAILABLE = False

# v3.1 å°ˆæ¥­æ¨¡çµ„
from src.stages.stage3_coordinate_transformation.stage3_data_validator import create_data_validator
from src.stages.stage3_coordinate_transformation.stage3_data_extractor import create_data_extractor
from src.stages.stage3_coordinate_transformation.stage3_transformation_engine import create_transformation_engine
from src.stages.stage3_coordinate_transformation.stage3_compliance_validator import create_compliance_validator
from src.stages.stage3_coordinate_transformation.stage3_results_manager import create_results_manager

# å…±äº«æ¨¡çµ„å°å…¥
from src.shared.base_processor import BaseStageProcessor
from src.shared.interfaces import ProcessingStatus, ProcessingResult, create_processing_result

logger = logging.getLogger(__name__)


class Stage3CoordinateTransformProcessor(BaseStageProcessor):
    """
    Stage 3: åº§æ¨™ç³»çµ±è½‰æ›å±¤è™•ç†å™¨ - v3.1 æ¨¡çµ„åŒ–æ¶æ§‹

    v3.1 æ ¸å¿ƒè·è²¬ï¼š
    1. å”èª¿å„å°ˆæ¥­æ¨¡çµ„å®Œæˆåº§æ¨™è½‰æ›æµç¨‹
    2. ç´” Skyfield å°ˆæ¥­ç´š TEMEâ†’ICRSâ†’ITRSâ†’WGS84 åº§æ¨™è½‰æ›
    3. è™•ç†æ‰€æœ‰è¡›æ˜Ÿï¼ˆç„¡å¯è¦‹æ€§ç¯©é¸ï¼Œå·²ç§»è‡³ Stage 4ï¼‰
    4. ä½¿ç”¨çœŸå¯¦ IERS åœ°çƒå®šå‘åƒæ•¸
    5. ä½¿ç”¨å®˜æ–¹ WGS84 åƒæ•¸
    6. å®Œæ•´ç²¾åº¦é©—è­‰å’Œå“è³ªä¿è­‰
    """

    def __init__(self, config: Optional[Dict[str, Any]] = None):
        super().__init__(stage_number=3, stage_name="coordinate_system_transformation", config=config or {})

        # æª¢æŸ¥çœŸå¯¦åº§æ¨™ç³»çµ±å¯ç”¨æ€§
        if not REAL_COORDINATE_SYSTEM_AVAILABLE:
            raise ImportError("CRITICAL: å¿…é ˆå®‰è£çœŸå¯¦åº§æ¨™ç³»çµ±æ¨¡çµ„ä»¥ç¬¦åˆ Grade A è¦æ±‚")

        # åº§æ¨™è½‰æ›é…ç½®
        self.coordinate_config = self.config.get('coordinate_config', {
            'source_frame': 'TEME',
            'target_frame': 'WGS84',
            'time_corrections': True,
            'polar_motion': True,
            'nutation_model': 'IAU2000A',
            'use_real_iers_data': True,
            'use_official_wgs84': True
        })

        # ç²¾åº¦é…ç½®
        self.precision_config = self.config.get('precision_config', {
            'target_accuracy_m': 0.5,
            'iau_standard_compliance': True,
            'professional_grade': True
        })

        # ğŸš€ å¹¾ä½•é ç¯©é¸é…ç½®
        self.prefilter_enabled = self.config.get('enable_geometric_prefilter', True)
        self.ground_station_config = self.config.get('ground_station', {
            'latitude_deg': 24.9438888888889,
            'longitude_deg': 121.370833333333,
            'altitude_m': 0.0
        })

        # åˆå§‹åŒ–çœŸå¯¦åº§æ¨™ç³»çµ±ç®¡ç†å™¨
        try:
            self.coordinate_engine = get_coordinate_engine()
            self.iers_manager = get_iers_manager()
            self.wgs84_manager = get_wgs84_manager()
            self.logger.info("âœ… çœŸå¯¦åº§æ¨™è½‰æ›å¼•æ“å·²åˆå§‹åŒ–")

            # ğŸš€ åˆå§‹åŒ–å¹¾ä½•é ç¯©é¸å™¨ï¼ˆå¦‚å•Ÿç”¨ï¼‰
            if self.prefilter_enabled:
                self.geometric_prefilter = create_geometric_prefilter(
                    ground_station_lat_deg=self.ground_station_config['latitude_deg'],
                    ground_station_lon_deg=self.ground_station_config['longitude_deg'],
                    ground_station_alt_m=self.ground_station_config.get('altitude_m', 0.0)
                )
                self.logger.info("âœ… å¹¾ä½•é ç¯©é¸å™¨å·²å•Ÿç”¨ (å„ªåŒ–æ¨¡å¼)")
            else:
                self.geometric_prefilter = None
                self.logger.info("â„¹ï¸ å¹¾ä½•é ç¯©é¸å™¨å·²ç¦ç”¨ (å…¨é‡è¨ˆç®—æ¨¡å¼)")

        except FileNotFoundError as e:
            self.logger.error(f"âŒ å®˜æ–¹æ•¸æ“šæ–‡ä»¶ç¼ºå¤±: {e}")
            raise FileNotFoundError(
                f"Stage 3 åˆå§‹åŒ–å¤±æ•—ï¼šå®˜æ–¹æ•¸æ“šæ–‡ä»¶ç¼ºå¤±\n"
                f"Grade Aæ¨™æº–ç¦æ­¢ä½¿ç”¨å›é€€å€¼\n"
                f"è©³ç´°éŒ¯èª¤: {e}"
            )
        except Exception as e:
            self.logger.error(f"âŒ çœŸå¯¦åº§æ¨™è½‰æ›å¼•æ“åˆå§‹åŒ–å¤±æ•—: {e}")
            raise RuntimeError(f"ç„¡æ³•åˆå§‹åŒ–çœŸå¯¦åº§æ¨™ç³»çµ±: {e}")

        # ğŸ—ï¸ v3.1 åˆå§‹åŒ–å°ˆæ¥­æ¨¡çµ„
        self.data_validator = create_data_validator(self.config)
        self.data_extractor = create_data_extractor(self.config)
        self.transformation_engine = create_transformation_engine(self.config)
        self.compliance_validator = create_compliance_validator(self.config)
        self.results_manager = create_results_manager(
            output_dir=self.output_dir,
            compliance_validator=self.compliance_validator,
            config=self.config
        )

        # è™•ç†çµ±è¨ˆ
        self.processing_stats = {
            'total_satellites_processed': 0,
            'total_coordinate_points': 0,
            'successful_transformations': 0,
            'transformation_errors': 0,
            'average_accuracy_m': 0.0,
            'real_iers_data_used': 0,
            'official_wgs84_used': 0,
            # ğŸš€ é ç¯©é¸çµ±è¨ˆ
            'prefilter_enabled': self.prefilter_enabled,
            'satellites_before_prefilter': 0,
            'satellites_after_prefilter': 0,
            'prefilter_retention_rate': 0.0
        }

        # é©—è­‰çœŸå¯¦æ•¸æ“šæºå¯ç”¨æ€§
        self._validate_real_data_sources()

        version_info = "v3.1 æ¨¡çµ„åŒ–æ¶æ§‹ (å„ªåŒ–)" if self.prefilter_enabled else "v3.1 æ¨¡çµ„åŒ–æ¶æ§‹ (æ¨™æº–)"
        self.logger.info(f"âœ… Stage 3 åº§æ¨™ç³»çµ±è½‰æ›è™•ç†å™¨å·²åˆå§‹åŒ– - {version_info}")

    def _validate_real_data_sources(self):
        """é©—è­‰çœŸå¯¦æ•¸æ“šæºå¯ç”¨æ€§"""
        try:
            # é©—è­‰ IERS æ•¸æ“šç®¡ç†å™¨
            iers_quality = self.iers_manager.get_data_quality_report()
            if iers_quality.get('cache_size', 0) == 0:
                self.logger.warning("âš ï¸ IERS æ•¸æ“šç·©å­˜ç‚ºç©ºï¼Œå°‡å˜—è©¦ç²å–")
                test_time = datetime.now(timezone.utc)
                try:
                    self.iers_manager.get_earth_orientation_parameters(test_time)
                    self.logger.info("âœ… IERS æ•¸æ“šç²å–æˆåŠŸ")
                except Exception as e:
                    self.logger.error(f"âŒ IERS æ•¸æ“šç²å–å¤±æ•—: {e}")

            # é©—è­‰ WGS84 åƒæ•¸ç®¡ç†å™¨
            wgs84_params = self.wgs84_manager.get_wgs84_parameters()
            validation = self.wgs84_manager.validate_parameters(wgs84_params)
            if not validation.get('validation_passed', False):
                self.logger.error(f"âŒ WGS84 åƒæ•¸é©—è­‰å¤±æ•—: {validation.get('errors', [])}")
                raise ValueError("WGS84 åƒæ•¸ç„¡æ•ˆ")
            else:
                self.logger.info("âœ… WGS84 åƒæ•¸é©—è­‰é€šé")

            # é©—è­‰åº§æ¨™è½‰æ›å¼•æ“
            engine_status = self.coordinate_engine.get_engine_status()
            if not engine_status.get('skyfield_available', False):
                raise RuntimeError("Skyfield å°ˆæ¥­åº«ä¸å¯ç”¨")

            self.logger.info("âœ… æ‰€æœ‰çœŸå¯¦æ•¸æ“šæºé©—è­‰é€šé")

        except Exception as e:
            self.logger.error(f"âŒ çœŸå¯¦æ•¸æ“šæºé©—è­‰å¤±æ•—: {e}")
            raise RuntimeError(f"çœŸå¯¦æ•¸æ“šæºä¸å¯ç”¨: {e}")

    def execute(self, input_data: Any) -> ProcessingResult:
        """
        åŸ·è¡Œ Stage 3 åº§æ¨™ç³»çµ±è½‰æ›è™•ç†

        v3.1 æ¶æ§‹: è¿”å›æ¨™æº– ProcessingResult æ ¼å¼
        100% BaseStageProcessor æ¥å£åˆè¦
        """
        result = self.process(input_data)

        # ç„¡è«–æˆåŠŸæˆ–å¤±æ•—ï¼Œéƒ½å˜—è©¦ä¿å­˜çµæœ
        if result.status == ProcessingStatus.SUCCESS:
            try:
                output_file = self.results_manager.save_results(result.data)
                self.logger.info(f"Stage 3 çµæœå·²ä¿å­˜: {output_file}")
            except Exception as e:
                self.logger.warning(f"ä¿å­˜ Stage 3 çµæœå¤±æ•—: {e}")

            try:
                snapshot_success = self.results_manager.save_validation_snapshot(
                    result.data,
                    self.processing_stats
                )
                if snapshot_success:
                    self.logger.info("âœ… Stage 3 é©—è­‰å¿«ç…§ä¿å­˜æˆåŠŸ")
            except Exception as e:
                self.logger.warning(f"âš ï¸ Stage 3 é©—è­‰å¿«ç…§ä¿å­˜å¤±æ•—: {e}")

        return result

    def process(self, input_data: Any) -> ProcessingResult:
        """
        ä¸»è¦è™•ç†æ–¹æ³• - Stage 3 v3.1 æ¨¡çµ„åŒ–åº§æ¨™è½‰æ›

        v3.1 è·è²¬ï¼šå”èª¿å„å°ˆæ¥­æ¨¡çµ„å®Œæˆ TEMEâ†’WGS84 åº§æ¨™è½‰æ›
        âœ¨ æ–°å¢ï¼šHDF5 ç·©å­˜æ”¯æ´ï¼ˆæ­·å²è³‡æ–™é‡ç¾å„ªåŒ–ï¼‰
        """
        start_time = datetime.now(timezone.utc)
        self.logger.info("ğŸš€ é–‹å§‹ Stage 3 v3.1 åº§æ¨™ç³»çµ±è½‰æ›è™•ç†...")

        try:
            # âœ… æ­¥é©Ÿ 1: é©—è­‰è¼¸å…¥æ•¸æ“š
            if not self.data_validator.validate_stage2_output(input_data):
                return create_processing_result(
                    status=ProcessingStatus.VALIDATION_FAILED,
                    data={},
                    message="Stage 2 è¼¸å‡ºæ•¸æ“šé©—è­‰å¤±æ•—"
                )

            # ğŸš€ æ­¥é©Ÿ 1.5: æª¢æŸ¥ HDF5 ç·©å­˜
            cache_key = self.results_manager.generate_cache_key(input_data)
            is_cached, cache_file = self.results_manager.check_cache(cache_key)

            if is_cached:
                self.logger.info("âš¡ å¾ç·©å­˜è¼‰å…¥åº§æ¨™æ•¸æ“šï¼ˆè·³éåº§æ¨™è½‰æ›ï¼‰")
                cached_data = self.results_manager.load_from_cache(cache_file)

                if cached_data:
                    # ä½¿ç”¨ç·©å­˜æ•¸æ“š
                    geographic_coordinates = cached_data['geographic_coordinates']
                    cached_metadata = cached_data.get('metadata', {})

                    # æ›´æ–°è™•ç†çµ±è¨ˆ
                    self.processing_stats.update({
                        'total_satellites_processed': len(geographic_coordinates),
                        'total_coordinate_points': sum(
                            len(v['time_series']) for v in geographic_coordinates.values()
                        ),
                        'successful_transformations': sum(
                            len(v['time_series']) for v in geographic_coordinates.values()
                        ),
                        'transformation_errors': 0,
                        'cache_hit': True,
                        'cache_file': cache_file
                    })

                    processing_time = datetime.now(timezone.utc) - start_time

                    # ä¿ç•™ä¸Šæ¸¸ metadata
                    upstream_metadata = input_data.get('metadata', {})

                    # åˆä½µå…ƒæ•¸æ“šï¼ˆå„ªå…ˆä½¿ç”¨ä¸Šæ¸¸é…ç½®ï¼‰
                    merged_metadata = {
                        **cached_metadata,
                        **upstream_metadata,
                        'cache_used': True,
                        'cache_key': cache_key,
                        'processing_duration_seconds': processing_time.total_seconds()
                    }

                    result_data = {
                        'stage': 3,
                        'stage_name': 'coordinate_system_transformation',
                        'geographic_coordinates': geographic_coordinates,
                        'metadata': merged_metadata
                    }

                    self.logger.info(
                        f"âœ… ç·©å­˜è¼‰å…¥å®Œæˆ: {self.processing_stats['total_satellites_processed']} é¡†è¡›æ˜Ÿ, "
                        f"{self.processing_stats['total_coordinate_points']:,} åº§æ¨™é», "
                        f"ç”¨æ™‚ {processing_time.total_seconds():.2f} ç§’"
                    )

                    return create_processing_result(
                        status=ProcessingStatus.SUCCESS,
                        data=result_data,
                        message=f"å¾ç·©å­˜è¼‰å…¥ {self.processing_stats['total_satellites_processed']} é¡†è¡›æ˜Ÿçš„åº§æ¨™"
                    )
                else:
                    self.logger.warning("âš ï¸ ç·©å­˜è¼‰å…¥å¤±æ•—ï¼Œç¹¼çºŒåŸ·è¡Œåº§æ¨™è½‰æ›")

            # âœ… æ­¥é©Ÿ 2: æå– TEME åº§æ¨™æ•¸æ“šï¼ˆç·©å­˜æœªå‘½ä¸­æˆ–å¤±æ•ˆï¼‰
            self.logger.info("ğŸ”„ ç·©å­˜æœªå‘½ä¸­ï¼ŒåŸ·è¡Œå®Œæ•´åº§æ¨™è½‰æ›")
            teme_data = self.data_extractor.extract_teme_coordinates(input_data)
            if not teme_data:
                return create_processing_result(
                    status=ProcessingStatus.ERROR,
                    data={},
                    message="æœªæ‰¾åˆ°æœ‰æ•ˆçš„ TEME åº§æ¨™æ•¸æ“š"
                )

            # âœ… æ­¥é©Ÿ 3: åŸ·è¡Œå¹¾ä½•é ç¯©é¸ï¼ˆå¦‚å•Ÿç”¨ï¼‰
            self.processing_stats['satellites_before_prefilter'] = len(teme_data)

            if self.prefilter_enabled and self.geometric_prefilter is not None:
                self.logger.info("ğŸ” åŸ·è¡Œå¹¾ä½•é ç¯©é¸å„ªåŒ–...")
                teme_data = self.geometric_prefilter.filter_satellite_candidates(teme_data)
                self.processing_stats['satellites_after_prefilter'] = len(teme_data)

                if self.processing_stats['satellites_before_prefilter'] > 0:
                    retention_rate = (
                        self.processing_stats['satellites_after_prefilter'] /
                        self.processing_stats['satellites_before_prefilter']
                    ) * 100
                    self.processing_stats['prefilter_retention_rate'] = retention_rate

                    filtered_count = (
                        self.processing_stats['satellites_before_prefilter'] -
                        self.processing_stats['satellites_after_prefilter']
                    )
                    self.logger.info(
                        f"âœ… é ç¯©é¸å®Œæˆ: ä¿ç•™ {len(teme_data)} é¡† ({retention_rate:.1f}%), "
                        f"æ’é™¤ {filtered_count} é¡† ({100-retention_rate:.1f}%)"
                    )
            else:
                self.processing_stats['satellites_after_prefilter'] = len(teme_data)
                self.processing_stats['prefilter_retention_rate'] = 100.0

            # âœ… æ­¥é©Ÿ 4: åŸ·è¡Œæ‰¹é‡åº§æ¨™è½‰æ›
            geographic_coordinates = self.transformation_engine.perform_batch_transformation(teme_data)

            # âœ… æ­¥é©Ÿ 5: æ›´æ–°è™•ç†çµ±è¨ˆ
            transformation_stats = self.transformation_engine.get_transformation_statistics()
            self.processing_stats.update({
                'total_satellites_processed': len(geographic_coordinates),
                'total_coordinate_points': transformation_stats['total_coordinate_points'],
                'successful_transformations': transformation_stats['successful_transformations'],
                'transformation_errors': transformation_stats['transformation_errors'],
                'average_accuracy_m': transformation_stats['average_accuracy_m'],
                'real_iers_data_used': transformation_stats['real_iers_data_used'],
                'official_wgs84_used': transformation_stats['official_wgs84_used']
            })

            # âœ… æ­¥é©Ÿ 6: å»ºç«‹è¼¸å‡ºæ•¸æ“š
            processing_time = datetime.now(timezone.utc) - start_time

            # ç²å–çœŸå¯¦ç³»çµ±ç‹€æ…‹
            engine_status = self.coordinate_engine.get_engine_status()
            iers_quality = self.iers_manager.get_data_quality_report()
            wgs84_summary = self.wgs84_manager.get_parameter_summary()

            # ä¿ç•™ä¸Šæ¸¸ metadata
            upstream_metadata = input_data.get('metadata', {})

            # å‰µå»ºåˆä½µçš„ metadata
            merged_metadata = self.results_manager.create_processing_metadata(
                processing_stats=self.processing_stats,
                upstream_metadata=upstream_metadata,
                coordinate_config=self.coordinate_config,
                precision_config=self.precision_config,
                engine_status=engine_status,
                iers_quality=iers_quality,
                wgs84_summary=wgs84_summary,
                processing_time_seconds=processing_time.total_seconds()
            )

            result_data = {
                'stage': 3,
                'stage_name': 'coordinate_system_transformation',
                'geographic_coordinates': geographic_coordinates,
                'metadata': merged_metadata
            }

            # ğŸš€ æ­¥é©Ÿ 7: ä¿å­˜åˆ° HDF5 ç·©å­˜ï¼ˆç•°æ­¥ï¼Œä¸å½±éŸ¿ä¸»æµç¨‹ï¼‰
            try:
                cache_saved = self.results_manager.save_to_cache(
                    cache_key=cache_key,
                    geographic_coordinates=geographic_coordinates,
                    metadata=merged_metadata
                )
                if cache_saved:
                    self.logger.info("ğŸ’¾ åº§æ¨™æ•¸æ“šå·²ä¿å­˜åˆ°ç·©å­˜ï¼Œä¸‹æ¬¡åŸ·è¡Œå°‡ç›´æ¥ä½¿ç”¨ç·©å­˜")
            except Exception as cache_error:
                self.logger.warning(f"âš ï¸ ç·©å­˜ä¿å­˜å¤±æ•—ï¼ˆä¸å½±éŸ¿çµæœï¼‰: {cache_error}")

            return create_processing_result(
                status=ProcessingStatus.SUCCESS,
                data=result_data,
                message=f"æˆåŠŸè½‰æ› {self.processing_stats['total_satellites_processed']} é¡†è¡›æ˜Ÿçš„åº§æ¨™"
            )

        except Exception as e:
            self.logger.error(f"âŒ Stage 3 çœŸå¯¦åº§æ¨™è½‰æ›å¤±æ•—: {e}")
            return create_processing_result(
                status=ProcessingStatus.ERROR,
                data={},
                message=f"çœŸå¯¦åº§æ¨™è½‰æ›éŒ¯èª¤: {str(e)}"
            )

    def validate_input(self, input_data: Any) -> Dict[str, Any]:
        """é©—è­‰è¼¸å…¥æ•¸æ“š"""
        return self.data_validator.validate_input(input_data)

    def validate_output(self, output_data: Any) -> Dict[str, Any]:
        """é©—è­‰è¼¸å‡ºæ•¸æ“š"""
        return self.data_validator.validate_output(output_data)

    def run_validation_checks(self, results: Dict[str, Any]) -> Dict[str, Any]:
        """åŸ·è¡ŒçœŸå¯¦ç®—æ³•é©—è­‰æª¢æŸ¥"""
        return self.compliance_validator.run_validation_checks(results)

    def extract_key_metrics(self) -> Dict[str, Any]:
        """æå–é—œéµæŒ‡æ¨™"""
        return self.results_manager.extract_key_metrics(self.processing_stats)

    def save_results(self, results: Dict[str, Any]) -> str:
        """ä¿å­˜è™•ç†çµæœåˆ°æ–‡ä»¶"""
        return self.results_manager.save_results(results)

    def save_validation_snapshot(self, processing_results: Dict[str, Any]) -> bool:
        """ä¿å­˜ Stage 3 é©—è­‰å¿«ç…§"""
        return self.results_manager.save_validation_snapshot(
            processing_results,
            self.processing_stats
        )


def create_stage3_processor(config: Optional[Dict[str, Any]] = None) -> Stage3CoordinateTransformProcessor:
    """å‰µå»º Stage 3 v3.1 æ¨¡çµ„åŒ–æ¶æ§‹è™•ç†å™¨å¯¦ä¾‹"""
    return Stage3CoordinateTransformProcessor(config)
