"""
ä¿¡è™Ÿå“è³ªç·©å­˜ç®¡ç†å™¨

çµ±ä¸€ç®¡ç†ç³»çµ±ä¸­æ‰€æœ‰ä¿¡è™Ÿå“è³ªè¨ˆç®—çµæœçš„ç·©å­˜ï¼Œ
é¿å…åœ¨å„éšæ®µé‡è¤‡è¨ˆç®—ç›¸åŒçš„ RSRP å’Œä¿¡è™Ÿå“è³ªæŒ‡æ¨™ã€‚

ä½œè€…: NTN Stack Team
ç‰ˆæœ¬: 1.0.0
å‰µå»ºæ—¥æœŸ: 2025-08-19
"""

import json
import hashlib
from datetime import datetime, timezone
from pathlib import Path
from typing import Dict, List, Optional, Any, Tuple
from dataclasses import dataclass, asdict
import logging

logger = logging.getLogger(__name__)


@dataclass
class SignalQualityEntry:
    """ä¿¡è™Ÿå“è³ªç·©å­˜æ¢ç›®"""
    satellite_id: str
    constellation: str
    elevation_deg: float
    rsrp_dbm: float
    snr_db: Optional[float] = None
    distance_km: Optional[float] = None
    calculation_timestamp: str = None
    calculation_method: str = "ITU-R_P.618_Ka_band"
    
    def __post_init__(self):
        if self.calculation_timestamp is None:
            self.calculation_timestamp = datetime.now(timezone.utc).isoformat()
    
    def get_cache_key(self) -> str:
        """ç”Ÿæˆç·©å­˜éµå€¼"""
        key_data = f"{self.satellite_id}_{self.constellation}_{self.elevation_deg:.1f}"
        return hashlib.md5(key_data.encode()).hexdigest()


@dataclass 
class SignalCalculationParams:
    """ä¿¡è™Ÿè¨ˆç®—åƒæ•¸"""
    observer_lat: float
    observer_lon: float
    frequency_ghz: float = 12.0  # Kué »æ®µ
    tx_power_dbm: float = 43.0   # æ¨™æº–ç™¼å°„åŠŸç‡
    calculation_standard: str = "ITU-R_P.618_20GHz_Ka_band"


class SignalQualityCache:
    """
    ä¿¡è™Ÿå“è³ªç·©å­˜ç®¡ç†å™¨
    
    è² è²¬ç®¡ç†ä¿¡è™Ÿå“è³ªè¨ˆç®—çµæœçš„ç·©å­˜ï¼Œé¿å…é‡è¤‡è¨ˆç®—ï¼š
    1. Stage3 è¨ˆç®—å¾Œå­˜å…¥ç·©å­˜
    2. Stage5/6 éœ€è¦æ™‚å¾ç·©å­˜è®€å–
    3. æ”¯æ´å¤šç¨®ç·©å­˜ç­–ç•¥ (è¨˜æ†¶é«”ã€æª”æ¡ˆã€æ··åˆ)
    """
    
    def __init__(self, cache_dir: str = "data/signal_cache", 
                 cache_size_limit: int = 10000):
        """
        åˆå§‹åŒ–ä¿¡è™Ÿå“è³ªç·©å­˜
        
        Args:
            cache_dir: ç·©å­˜æª”æ¡ˆå­˜å„²ç›®éŒ„
            cache_size_limit: è¨˜æ†¶é«”ç·©å­˜æ¢ç›®æ•¸é‡é™åˆ¶
        """
        self.cache_dir = Path(cache_dir)
        # ğŸš« ç§»é™¤è‡ªå‹•å‰µå»ºç›®éŒ„ - signal_cache åŠŸèƒ½æœªè¢«ä½¿ç”¨
        # self.cache_dir.mkdir(parents=True, exist_ok=True)
        
        self.cache_size_limit = cache_size_limit
        
        # è¨˜æ†¶é«”ç·©å­˜ (å¿«é€Ÿå­˜å–)
        self._memory_cache: Dict[str, SignalQualityEntry] = {}
        
        # ç·©å­˜çµ±è¨ˆ
        self._cache_stats = {
            "hits": 0,
            "misses": 0,
            "writes": 0,
            "cache_creation_time": datetime.now(timezone.utc).isoformat()
        }
        
        # ğŸš« ç§»é™¤è¼‰å…¥å·²å­˜åœ¨ç·©å­˜çš„é‚è¼¯ - é¿å…ä¸å¿…è¦çš„æ–‡ä»¶æ“ä½œ
        # self._load_existing_cache()
        
        logger.info("âš ï¸ ä¿¡è™Ÿå“è³ªç·©å­˜ç®¡ç†å™¨åˆå§‹åŒ– (æœªå•Ÿç”¨æ¨¡å¼)")
        logger.info(f"  ç·©å­˜ç›®éŒ„: {self.cache_dir} (ä¸æœƒè‡ªå‹•å‰µå»º)")
        logger.info(f"  è¨˜æ†¶é«”ç·©å­˜é™åˆ¶: {self.cache_size_limit} æ¢ç›®")
        logger.info(f"  ç¾æœ‰ç·©å­˜æ¢ç›®: {len(self._memory_cache)} å€‹ (æœªè¼‰å…¥)")
    
    def get_cached_rsrp(self, satellite_id: str, constellation: str, 
                       elevation_deg: float) -> Optional[float]:
        """
        å¾ç·©å­˜ç²å– RSRP å€¼
        
        Args:
            satellite_id: è¡›æ˜ŸID
            constellation: æ˜Ÿåº§åç¨±
            elevation_deg: ä»°è§’ (åº¦)
        
        Returns:
            RSRP å€¼ (dBm) æˆ– None (å¦‚æœæœªç·©å­˜)
        """
        cache_key = self._generate_cache_key(satellite_id, constellation, elevation_deg)
        
        # å„ªå…ˆå¾è¨˜æ†¶é«”ç·©å­˜æŸ¥æ‰¾
        if cache_key in self._memory_cache:
            self._cache_stats["hits"] += 1
            entry = self._memory_cache[cache_key]
            logger.debug(f"ç·©å­˜å‘½ä¸­: {satellite_id} @ {elevation_deg}Â° = {entry.rsrp_dbm} dBm")
            return entry.rsrp_dbm
        
        # å¾æª”æ¡ˆç·©å­˜æŸ¥æ‰¾
        file_cached_entry = self._load_from_file_cache(cache_key)
        if file_cached_entry:
            # è¼‰å…¥åˆ°è¨˜æ†¶é«”ç·©å­˜
            self._memory_cache[cache_key] = file_cached_entry
            self._cache_stats["hits"] += 1
            logger.debug(f"æª”æ¡ˆç·©å­˜å‘½ä¸­: {satellite_id} @ {elevation_deg}Â° = {file_cached_entry.rsrp_dbm} dBm")
            return file_cached_entry.rsrp_dbm
        
        # ç·©å­˜æœªå‘½ä¸­
        self._cache_stats["misses"] += 1
        logger.debug(f"ç·©å­˜æœªå‘½ä¸­: {satellite_id} @ {elevation_deg}Â°")
        return None
    
    def cache_rsrp_calculation(self, satellite_id: str, constellation: str,
                              elevation_deg: float, rsrp_dbm: float,
                              distance_km: Optional[float] = None,
                              snr_db: Optional[float] = None) -> None:
        """
        ç·©å­˜ RSRP è¨ˆç®—çµæœ
        
        Args:
            satellite_id: è¡›æ˜ŸID
            constellation: æ˜Ÿåº§åç¨±
            elevation_deg: ä»°è§’ (åº¦)
            rsrp_dbm: RSRP å€¼ (dBm)
            distance_km: è·é›¢ (å…¬é‡Œ)
            snr_db: ä¿¡å™ªæ¯” (dB)
        """
        entry = SignalQualityEntry(
            satellite_id=satellite_id,
            constellation=constellation,
            elevation_deg=elevation_deg,
            rsrp_dbm=rsrp_dbm,
            distance_km=distance_km,
            snr_db=snr_db
        )
        
        cache_key = entry.get_cache_key()
        
        # å­˜å…¥è¨˜æ†¶é«”ç·©å­˜
        self._memory_cache[cache_key] = entry
        self._cache_stats["writes"] += 1
        
        # æª¢æŸ¥è¨˜æ†¶é«”ç·©å­˜å¤§å°é™åˆ¶
        if len(self._memory_cache) > self.cache_size_limit:
            self._evict_oldest_entries()
        
        # ç•°æ­¥å­˜å…¥æª”æ¡ˆç·©å­˜
        self._save_to_file_cache(cache_key, entry)
        
        logger.debug(f"ç·©å­˜å¯«å…¥: {satellite_id} @ {elevation_deg}Â° = {rsrp_dbm} dBm")
    
    def batch_cache_satellite_signals(self, satellite_data: Dict[str, Any], 
                                     calculation_params: SignalCalculationParams) -> Dict[str, Any]:
        """
        æ‰¹æ¬¡ç·©å­˜è¡›æ˜Ÿä¿¡è™Ÿè¨ˆç®—çµæœ (ç”¨æ–¼ Stage3 å®Œæˆå¾Œçš„æ‰¹æ¬¡å­˜å„²)
        
        Args:
            satellite_data: åŒ…å«ä¿¡è™Ÿè¨ˆç®—çµæœçš„è¡›æ˜Ÿæ•¸æ“š
            calculation_params: è¨ˆç®—åƒæ•¸
        
        Returns:
            ç·©å­˜çµ±è¨ˆçµæœ
        """
        cached_count = 0
        skipped_count = 0
        
        logger.info("ğŸ“¦ é–‹å§‹æ‰¹æ¬¡ç·©å­˜è¡›æ˜Ÿä¿¡è™Ÿè¨ˆç®—çµæœ")
        
        for constellation, data in satellite_data.get('constellations', {}).items():
            satellites = data.get('satellites', [])
            
            for satellite in satellites:
                satellite_id = satellite.get('satellite_id')
                if not satellite_id:
                    continue
                
                # ç·©å­˜å¤šå€‹ä»°è§’çš„ä¿¡è™Ÿæ•¸æ“š
                signal_quality = satellite.get('signal_quality', {})
                rsrp_by_elevation = signal_quality.get('rsrp_by_elevation', {})
                
                for elev_key, rsrp_value in rsrp_by_elevation.items():
                    # è§£æä»°è§’å€¼ (æ ¼å¼: "elev_5deg" -> 5.0)
                    try:
                        elevation = float(elev_key.replace('elev_', '').replace('deg', ''))
                        
                        # æª¢æŸ¥æ˜¯å¦å·²ç·©å­˜
                        existing_rsrp = self.get_cached_rsrp(satellite_id, constellation, elevation)
                        if existing_rsrp is None:
                            # ç·©å­˜æ–°çš„è¨ˆç®—çµæœ
                            self.cache_rsrp_calculation(
                                satellite_id=satellite_id,
                                constellation=constellation,
                                elevation_deg=elevation,
                                rsrp_dbm=rsrp_value,
                                distance_km=satellite.get('range_km'),
                                snr_db=signal_quality.get('snr_estimate_db')
                            )
                            cached_count += 1
                        else:
                            skipped_count += 1
                    except (ValueError, TypeError) as e:
                        logger.warning(f"ç„¡æ³•è§£æä»°è§’éµå€¼ {elev_key}: {e}")
                        continue
        
        result = {
            "cached_entries": cached_count,
            "skipped_entries": skipped_count,
            "total_cache_size": len(self._memory_cache),
            "cache_hit_rate": self._calculate_hit_rate()
        }
        
        logger.info(f"âœ… æ‰¹æ¬¡ç·©å­˜å®Œæˆ: {cached_count} æ–°å¢, {skipped_count} è·³é")
        return result
    
    def get_cached_satellite_signals(self, satellite_id: str, constellation: str,
                                   elevation_angles: List[float]) -> Dict[str, Optional[float]]:
        """
        æ‰¹æ¬¡ç²å–è¡›æ˜Ÿåœ¨å¤šå€‹ä»°è§’çš„ç·©å­˜ä¿¡è™Ÿæ•¸æ“š
        
        Args:
            satellite_id: è¡›æ˜ŸID
            constellation: æ˜Ÿåº§åç¨±
            elevation_angles: ä»°è§’åˆ—è¡¨
        
        Returns:
            ä»°è§’èˆ‡ RSRP çš„æ˜ å°„å­—å…¸
        """
        results = {}
        
        for elevation in elevation_angles:
            rsrp = self.get_cached_rsrp(satellite_id, constellation, elevation)
            results[f"elev_{int(elevation)}deg"] = rsrp
        
        return results
    
    def clear_cache(self, older_than_hours: Optional[int] = None) -> Dict[str, int]:
        """
        æ¸…ç†ç·©å­˜
        
        Args:
            older_than_hours: æ¸…ç†è¶…éæŒ‡å®šå°æ™‚çš„ç·©å­˜ï¼ŒNoneè¡¨ç¤ºæ¸…ç†å…¨éƒ¨
        
        Returns:
            æ¸…ç†çµ±è¨ˆçµæœ
        """
        if older_than_hours is None:
            # æ¸…ç†å…¨éƒ¨
            memory_cleared = len(self._memory_cache)
            self._memory_cache.clear()
            
            # æ¸…ç†æª”æ¡ˆç·©å­˜
            file_cleared = 0
            for cache_file in self.cache_dir.glob("*.json"):
                cache_file.unlink()
                file_cleared += 1
            
            logger.info(f"ğŸ—‘ï¸ æ¸…ç†å…¨éƒ¨ç·©å­˜: è¨˜æ†¶é«” {memory_cleared} å€‹, æª”æ¡ˆ {file_cleared} å€‹")
            
        else:
            # æ¸…ç†éæœŸç·©å­˜
            cutoff_time = datetime.now(timezone.utc).timestamp() - (older_than_hours * 3600)
            memory_cleared = 0
            file_cleared = 0
            
            # æ¸…ç†è¨˜æ†¶é«”ç·©å­˜
            keys_to_remove = []
            for key, entry in self._memory_cache.items():
                entry_time = datetime.fromisoformat(entry.calculation_timestamp.replace('Z', '+00:00')).timestamp()
                if entry_time < cutoff_time:
                    keys_to_remove.append(key)
            
            for key in keys_to_remove:
                del self._memory_cache[key]
                memory_cleared += 1
            
            # æ¸…ç†æª”æ¡ˆç·©å­˜
            for cache_file in self.cache_dir.glob("*.json"):
                if cache_file.stat().st_mtime < cutoff_time:
                    cache_file.unlink()
                    file_cleared += 1
            
            logger.info(f"ğŸ—‘ï¸ æ¸…ç†éæœŸç·©å­˜ ({older_than_hours}å°æ™‚): è¨˜æ†¶é«” {memory_cleared} å€‹, æª”æ¡ˆ {file_cleared} å€‹")
        
        return {
            "memory_cleared": memory_cleared,
            "file_cleared": file_cleared,
            "remaining_memory_entries": len(self._memory_cache)
        }
    
    def get_cache_statistics(self) -> Dict[str, Any]:
        """ç²å–ç·©å­˜çµ±è¨ˆä¿¡æ¯"""
        return {
            **self._cache_stats,
            "memory_cache_size": len(self._memory_cache),
            "file_cache_directory": str(self.cache_dir),
            "cache_hit_rate": self._calculate_hit_rate(),
            "memory_usage_estimate_mb": len(self._memory_cache) * 0.001,  # ç²—ç•¥ä¼°ç®—
        }
    
    def _generate_cache_key(self, satellite_id: str, constellation: str, elevation_deg: float) -> str:
        """ç”Ÿæˆç·©å­˜éµå€¼"""
        key_data = f"{satellite_id}_{constellation}_{elevation_deg:.1f}"
        return hashlib.md5(key_data.encode()).hexdigest()
    
    def _load_existing_cache(self) -> None:
        """è¼‰å…¥ç¾æœ‰çš„æª”æ¡ˆç·©å­˜åˆ°è¨˜æ†¶é«”"""
        cache_files = list(self.cache_dir.glob("*.json"))
        loaded_count = 0
        
        for cache_file in cache_files:
            try:
                with open(cache_file, 'r') as f:
                    data = json.load(f)
                
                entry = SignalQualityEntry(**data)
                cache_key = entry.get_cache_key()
                self._memory_cache[cache_key] = entry
                loaded_count += 1
                
                # æª¢æŸ¥è¨˜æ†¶é«”é™åˆ¶
                if len(self._memory_cache) >= self.cache_size_limit:
                    break
                    
            except Exception as e:
                logger.warning(f"è¼‰å…¥ç·©å­˜æª”æ¡ˆå¤±æ•— {cache_file}: {e}")
        
        if loaded_count > 0:
            logger.info(f"ğŸ“‚ è¼‰å…¥ç¾æœ‰ç·©å­˜: {loaded_count} å€‹æ¢ç›®")
    
    def _save_to_file_cache(self, cache_key: str, entry: SignalQualityEntry) -> None:
        """ä¿å­˜ç·©å­˜æ¢ç›®åˆ°æª”æ¡ˆ"""
        try:
            cache_file = self.cache_dir / f"{cache_key}.json"
            with open(cache_file, 'w') as f:
                json.dump(asdict(entry), f, indent=2)
        except Exception as e:
            logger.warning(f"ä¿å­˜ç·©å­˜æª”æ¡ˆå¤±æ•— {cache_key}: {e}")
    
    def _load_from_file_cache(self, cache_key: str) -> Optional[SignalQualityEntry]:
        """å¾æª”æ¡ˆè¼‰å…¥ç·©å­˜æ¢ç›®"""
        try:
            cache_file = self.cache_dir / f"{cache_key}.json"
            if cache_file.exists():
                with open(cache_file, 'r') as f:
                    data = json.load(f)
                return SignalQualityEntry(**data)
        except Exception as e:
            logger.warning(f"è¼‰å…¥ç·©å­˜æª”æ¡ˆå¤±æ•— {cache_key}: {e}")
        
        return None
    
    def _evict_oldest_entries(self) -> None:
        """ç§»é™¤æœ€èˆŠçš„ç·©å­˜æ¢ç›® (LRUç­–ç•¥)"""
        if len(self._memory_cache) <= self.cache_size_limit:
            return
        
        # ç°¡å–®çš„FIFOç­–ç•¥ï¼šç§»é™¤10%çš„æ¢ç›®
        entries_to_remove = len(self._memory_cache) - int(self.cache_size_limit * 0.9)
        keys_to_remove = list(self._memory_cache.keys())[:entries_to_remove]
        
        for key in keys_to_remove:
            del self._memory_cache[key]
        
        logger.debug(f"ğŸ—‘ï¸ ç·©å­˜æ¸…ç†: ç§»é™¤ {len(keys_to_remove)} å€‹èˆŠæ¢ç›®")
    
    def _calculate_hit_rate(self) -> float:
        """è¨ˆç®—ç·©å­˜å‘½ä¸­ç‡"""
        total_requests = self._cache_stats["hits"] + self._cache_stats["misses"]
        if total_requests == 0:
            return 0.0
        return self._cache_stats["hits"] / total_requests


# å…¨å±€å¯¦ä¾‹ (å–®ä¾‹æ¨¡å¼)
_global_signal_cache = None

def get_signal_quality_cache() -> SignalQualityCache:
    """ç²å–å…¨å±€ä¿¡è™Ÿå“è³ªç·©å­˜å¯¦ä¾‹"""
    global _global_signal_cache
    if _global_signal_cache is None:
        # ğŸ”§ ä¿®å¾©ï¼šæ™ºèƒ½æª¢æ¸¬ç’°å¢ƒï¼Œä½¿ç”¨æ­£ç¢ºçš„è·¯å¾‘
        import os
        if os.path.exists("/orbit-engine"):
            # å®¹å™¨å…§ç’°å¢ƒ
            cache_dir = "data/signal_cache"
        else:
            # ä¸»æ©Ÿç’°å¢ƒ
            cache_dir = "/home/sat/ntn-stack/data/signal_cache"
        
        if not os.path.exists(cache_dir):
            os.makedirs(cache_dir, exist_ok=True)
        _global_signal_cache = SignalQualityCache(cache_dir=cache_dir)
    return _global_signal_cache


# ä¾¿æ·å‡½æ•¸
def get_cached_rsrp(satellite_id: str, constellation: str, elevation_deg: float) -> Optional[float]:
    """å¿«é€Ÿç²å–ç·©å­˜çš„ RSRP å€¼"""
    return get_signal_quality_cache().get_cached_rsrp(satellite_id, constellation, elevation_deg)

def cache_rsrp_result(satellite_id: str, constellation: str, elevation_deg: float, rsrp_dbm: float) -> None:
    """å¿«é€Ÿç·©å­˜ RSRP çµæœ"""
    get_signal_quality_cache().cache_rsrp_calculation(satellite_id, constellation, elevation_deg, rsrp_dbm)


if __name__ == "__main__":
    # æ¸¬è©¦ä¿¡è™Ÿå“è³ªç·©å­˜
    cache = get_signal_quality_cache()
    
    print("ğŸ§ª æ¸¬è©¦ä¿¡è™Ÿå“è³ªç·©å­˜ç®¡ç†å™¨")
    print("=" * 50)
    
    # æ¸¬è©¦ç·©å­˜å¯«å…¥
    cache.cache_rsrp_calculation("STARLINK-1234", "starlink", 15.0, -85.5, distance_km=1200.5)
    cache.cache_rsrp_calculation("ONEWEB-5678", "oneweb", 20.0, -78.2, distance_km=950.0)
    
    # æ¸¬è©¦ç·©å­˜è®€å–
    rsrp1 = cache.get_cached_rsrp("STARLINK-1234", "starlink", 15.0)
    rsrp2 = cache.get_cached_rsrp("ONEWEB-5678", "oneweb", 20.0)
    rsrp3 = cache.get_cached_rsrp("UNKNOWN-9999", "starlink", 10.0)  # æ‡‰è©²è¿”å› None
    
    print(f"Starlink-1234 @ 15Â°: {rsrp1} dBm")
    print(f"OneWeb-5678 @ 20Â°: {rsrp2} dBm")
    print(f"Unknown-9999 @ 10Â°: {rsrp3}")
    
    # æ¸¬è©¦æ‰¹æ¬¡ç²å–
    batch_results = cache.get_cached_satellite_signals("STARLINK-1234", "starlink", [10.0, 15.0, 30.0])
    print(f"æ‰¹æ¬¡æŸ¥è©¢çµæœ: {batch_results}")
    
    # æ¸¬è©¦çµ±è¨ˆ
    stats = cache.get_cache_statistics()
    print(f"ç·©å­˜çµ±è¨ˆ: å‘½ä¸­ç‡ {stats['cache_hit_rate']:.2%}, æ¢ç›®æ•¸ {stats['memory_cache_size']}")
    
    print("\nâœ… ä¿¡è™Ÿå“è³ªç·©å­˜ç®¡ç†å™¨æ¸¬è©¦å®Œæˆ")