#!/usr/bin/env python3
"""
çµ±ä¸€æ—¥èªŒç®¡ç†å™¨
çµ±ä¸€ç®¡ç†å…­éšæ®µè™•ç†çš„æ—¥èªŒå’Œå ±å‘Šè¼¸å‡º
"""

import json
import logging
import os
import shutil
from datetime import datetime, timezone
from pathlib import Path
from typing import Dict, Any, Optional, List
import uuid

class UnifiedLogManager:
    """çµ±ä¸€æ—¥èªŒç®¡ç†å™¨"""
    
    def __init__(self, project_root: str = "/home/sat/ntn-stack", container_data_dir: str = "data"):
        """
        åˆå§‹åŒ–çµ±ä¸€æ—¥èªŒç®¡ç†å™¨
        
        Args:
            project_root: é …ç›®æ ¹ç›®éŒ„
            container_data_dir: å®¹å™¨å…§æ•¸æ“šç›®éŒ„
        """
        self.project_root = Path(project_root)
        self.container_data_dir = Path(container_data_dir)
        
        # å‰µå»º logs ç›®éŒ„çµæ§‹
        self.logs_dir = self.project_root / "logs"
        self.logs_dir.mkdir(exist_ok=True)
        
        # å­ç›®éŒ„çµæ§‹
        self.execution_logs_dir = self.logs_dir / "execution"
        self.stage_reports_dir = self.logs_dir / "stage_reports" 
        self.validation_logs_dir = self.logs_dir / "validation"
        self.summary_reports_dir = self.logs_dir / "summary"
        
        # å‰µå»ºæ‰€æœ‰å­ç›®éŒ„
        for dir_path in [self.execution_logs_dir, self.stage_reports_dir, 
                        self.validation_logs_dir, self.summary_reports_dir]:
            dir_path.mkdir(exist_ok=True)
            
        # ç•¶å‰åŸ·è¡ŒID
        self.execution_id = datetime.now().strftime("%Y%m%d_%H%M%S")
        self.execution_start_time = datetime.now(timezone.utc)
        
        # æ—¥èªŒé…ç½®
        self.logger = logging.getLogger(f"unified_log_manager_{self.execution_id}")
        
        # åŸ·è¡Œç‹€æ…‹è¿½è¹¤
        self.execution_status = {
            'execution_id': self.execution_id,
            'start_time': self.execution_start_time.isoformat(),
            'tle_sources': {},
            'stage_results': {},
            'validation_results': {},
            'total_processing_time': 0
        }
        
    def clear_old_logs(self):
        """æ¸…ç†èˆŠçš„æ—¥èªŒå’Œå ±å‘Š"""
        print("ğŸ—‘ï¸ æ¸…ç†èˆŠçš„æ—¥èªŒå’Œå ±å‘Š...")
        
        # æ¸…ç† logs ç›®éŒ„ä¸‹çš„èˆŠæ–‡ä»¶
        for subdir in [self.execution_logs_dir, self.stage_reports_dir, 
                      self.validation_logs_dir, self.summary_reports_dir]:
            if subdir.exists():
                for file in subdir.glob("*"):
                    try:
                        if file.is_file():
                            file.unlink()
                        elif file.is_dir():
                            shutil.rmtree(file)
                        print(f"   âœ… å·²åˆªé™¤: {file}")
                    except Exception as e:
                        print(f"   âš ï¸ åˆªé™¤å¤±æ•—: {file} - {e}")
        
        # æ¸…ç†å®¹å™¨å…§çš„èˆŠå ±å‘Šæ–‡ä»¶
        old_reports = [
            ".build_status",
            ".build_validation_status", 
            ".final_build_report.json",
            ".build_summary.txt"
        ]
        
        for report_file in old_reports:
            report_path = self.container_data_dir / report_file
            if report_path.exists():
                try:
                    report_path.unlink()
                    print(f"   âœ… å·²åˆªé™¤èˆŠå ±å‘Š: {report_file}")
                except Exception as e:
                    print(f"   âš ï¸ åˆªé™¤å¤±æ•—: {report_file} - {e}")
                    
        print("âœ… èˆŠæ—¥èªŒæ¸…ç†å®Œæˆ")
        
    def initialize_execution_log(self, tle_sources: Dict[str, str]):
        """
        åˆå§‹åŒ–åŸ·è¡Œæ—¥èªŒ
        
        Args:
            tle_sources: TLEæ•¸æ“šä¾†æºå­—å…¸ {'starlink': 'starlink_20241201.tle', 'oneweb': 'oneweb_20241201.tle'}
        """
        self.execution_status['tle_sources'] = tle_sources
        
        # å¯«å…¥åŸ·è¡Œé–‹å§‹æ—¥èªŒ
        execution_log = self.execution_logs_dir / f"execution_{self.execution_id}.log"
        with open(execution_log, 'w', encoding='utf-8') as f:
            f.write(f"ğŸ“Š å…­éšæ®µæ•¸æ“šè™•ç†åŸ·è¡Œæ—¥èªŒ\n")
            f.write(f"=" * 50 + "\n")
            f.write(f"ğŸ†” åŸ·è¡ŒID: {self.execution_id}\n")
            f.write(f"â° é–‹å§‹æ™‚é–“: {self.execution_start_time.strftime('%Y-%m-%d %H:%M:%S UTC')}\n")
            f.write(f"ğŸ›°ï¸ ä½¿ç”¨çš„TLEæ•¸æ“š:\n")
            for constellation, tle_file in tle_sources.items():
                f.write(f"   {constellation.upper()}: {tle_file}\n")
            f.write("\n")
            
        print(f"ğŸ“ å·²åˆå§‹åŒ–åŸ·è¡Œæ—¥èªŒ: {execution_log}")
        
    def log_stage_start(self, stage_num: int, stage_name: str):
        """è¨˜éŒ„éšæ®µé–‹å§‹"""
        stage_start_time = datetime.now(timezone.utc)
        
        self.execution_status['stage_results'][f'stage_{stage_num}'] = {
            'stage_name': stage_name,
            'start_time': stage_start_time.isoformat(),
            'status': 'running'
        }
        
        # è¿½åŠ åˆ°åŸ·è¡Œæ—¥èªŒ
        execution_log = self.execution_logs_dir / f"execution_{self.execution_id}.log"
        with open(execution_log, 'a', encoding='utf-8') as f:
            f.write(f"ğŸš€ éšæ®µ{stage_num}é–‹å§‹: {stage_name}\n")
            f.write(f"   é–‹å§‹æ™‚é–“: {stage_start_time.strftime('%Y-%m-%d %H:%M:%S UTC')}\n")
            
        print(f"ğŸš€ éšæ®µ{stage_num}é–‹å§‹: {stage_name}")
        
    def log_stage_completion(self, stage_num: int, stage_name: str, 
                           processing_results: Dict[str, Any], 
                           validation_passed: bool, validation_message: str):
        """
        è¨˜éŒ„éšæ®µå®Œæˆ
        
        Args:
            stage_num: éšæ®µç·¨è™Ÿ
            stage_name: éšæ®µåç¨±
            processing_results: è™•ç†çµæœ
            validation_passed: é©—è­‰æ˜¯å¦é€šé
            validation_message: é©—è­‰è¨Šæ¯
        """
        stage_end_time = datetime.now(timezone.utc)
        stage_key = f'stage_{stage_num}'
        
        # è¨ˆç®—éšæ®µåŸ·è¡Œæ™‚é–“
        if stage_key in self.execution_status['stage_results']:
            start_time_str = self.execution_status['stage_results'][stage_key]['start_time']
            start_time = datetime.fromisoformat(start_time_str.replace('Z', '+00:00'))
            duration_seconds = (stage_end_time - start_time).total_seconds()
            duration_minutes = duration_seconds / 60
        else:
            duration_minutes = 0
            
        # æ›´æ–°åŸ·è¡Œç‹€æ…‹
        self.execution_status['stage_results'][stage_key].update({
            'end_time': stage_end_time.isoformat(),
            'duration_minutes': duration_minutes,
            'status': 'completed' if validation_passed else 'failed',
            'validation_passed': validation_passed,
            'validation_message': validation_message,
            'output_count': len(processing_results) if processing_results else 0
        })
        
        # è¨˜éŒ„é©—è­‰çµæœ
        self.execution_status['validation_results'][stage_key] = {
            'passed': validation_passed,
            'message': validation_message,
            'timestamp': stage_end_time.isoformat()
        }
        
        # å¯«å…¥éšæ®µå ±å‘Š
        stage_report_file = self.stage_reports_dir / f"stage_{stage_num}_{self.execution_id}.json"
        stage_report = {
            'execution_id': self.execution_id,
            'stage_number': stage_num,
            'stage_name': stage_name,
            'start_time': self.execution_status['stage_results'][stage_key]['start_time'],
            'end_time': stage_end_time.isoformat(),
            'duration_minutes': duration_minutes,
            'processing_results_count': len(processing_results) if processing_results else 0,
            'validation': {
                'passed': validation_passed,
                'message': validation_message
            },
            'processing_summary': self._generate_processing_summary(processing_results)
        }
        
        with open(stage_report_file, 'w', encoding='utf-8') as f:
            json.dump(stage_report, f, ensure_ascii=False, indent=2)
            
        # è¿½åŠ åˆ°åŸ·è¡Œæ—¥èªŒ
        execution_log = self.execution_logs_dir / f"execution_{self.execution_id}.log"
        with open(execution_log, 'a', encoding='utf-8') as f:
            status_emoji = "âœ…" if validation_passed else "âŒ"
            f.write(f"{status_emoji} éšæ®µ{stage_num}å®Œæˆ: {stage_name}\n")
            f.write(f"   çµæŸæ™‚é–“: {stage_end_time.strftime('%Y-%m-%d %H:%M:%S UTC')}\n")
            f.write(f"   åŸ·è¡Œæ™‚é–“: {duration_minutes:.2f} åˆ†é˜\n")
            f.write(f"   é©—è­‰çµæœ: {validation_message}\n")
            f.write(f"   è¼¸å‡ºæ•¸é‡: {len(processing_results) if processing_results else 0}\n\n")
            
        print(f"{'âœ…' if validation_passed else 'âŒ'} éšæ®µ{stage_num}å®Œæˆ - {duration_minutes:.2f}åˆ†é˜")
        
    def generate_final_summary_report(self):
        """ç”Ÿæˆæœ€çµ‚ç¶œåˆå ±å‘Š"""
        end_time = datetime.now(timezone.utc)
        total_duration = (end_time - self.execution_start_time).total_seconds() / 60
        
        self.execution_status.update({
            'end_time': end_time.isoformat(),
            'total_processing_time': total_duration,
            'overall_status': self._determine_overall_status()
        })
        
        # ç”Ÿæˆç¶œåˆå ±å‘Š
        summary_report = {
            'execution_metadata': {
                'execution_id': self.execution_id,
                'start_time': self.execution_start_time.isoformat(),
                'end_time': end_time.isoformat(),
                'total_duration_minutes': total_duration,
                'report_generation_time': datetime.now(timezone.utc).isoformat()
            },
            'tle_data_sources': self.execution_status['tle_sources'],
            'stage_execution_summary': self.execution_status['stage_results'],
            'validation_summary': self.execution_status['validation_results'],
            'overall_status': self.execution_status['overall_status'],
            'statistics': self._generate_execution_statistics()
        }
        
        # å¯«å…¥JSONè©³ç´°å ±å‘Š
        summary_json = self.summary_reports_dir / f"final_summary_{self.execution_id}.json"
        with open(summary_json, 'w', encoding='utf-8') as f:
            json.dump(summary_report, f, ensure_ascii=False, indent=2)
            
        # å¯«å…¥äººé¡å¯è®€æ‘˜è¦
        summary_text = self.summary_reports_dir / f"final_summary_{self.execution_id}.txt"
        with open(summary_text, 'w', encoding='utf-8') as f:
            f.write(self._generate_human_readable_summary(summary_report))
            
        # å¯«å…¥åŸ·è¡Œæ—¥èªŒæœ€çµ‚ç‹€æ…‹
        execution_log = self.execution_logs_dir / f"execution_{self.execution_id}.log"
        with open(execution_log, 'a', encoding='utf-8') as f:
            f.write("=" * 50 + "\n")
            f.write(f"ğŸ åŸ·è¡Œå®Œæˆ\n")
            f.write(f"â° çµæŸæ™‚é–“: {end_time.strftime('%Y-%m-%d %H:%M:%S UTC')}\n")
            f.write(f"â±ï¸ ç¸½åŸ·è¡Œæ™‚é–“: {total_duration:.2f} åˆ†é˜\n")
            f.write(f"ğŸ“Š æ•´é«”ç‹€æ…‹: {self.execution_status['overall_status']}\n")
            f.write("=" * 50 + "\n")
            
        print(f"ğŸ“Š æœ€çµ‚å ±å‘Šå·²ç”Ÿæˆ:")
        print(f"   è©³ç´°å ±å‘Š: {summary_json}")
        print(f"   æ‘˜è¦å ±å‘Š: {summary_text}")
        print(f"   åŸ·è¡Œæ—¥èªŒ: {execution_log}")
        
        return summary_report
        
    def _generate_processing_summary(self, processing_results: Dict[str, Any]) -> Dict[str, Any]:
        """ç”Ÿæˆè™•ç†çµæœæ‘˜è¦"""
        if not processing_results:
            return {'status': 'no_results'}
            
        summary = {
            'total_items': len(processing_results),
            'has_data': bool(processing_results),
            'keys': list(processing_results.keys())[:10]  # åªè¨˜éŒ„å‰10å€‹éµ
        }
        
        # å¦‚æœæ˜¯è¡›æ˜Ÿæ•¸æ“šï¼Œè¨ˆç®—ä¸€äº›çµ±è¨ˆ
        if isinstance(processing_results, dict) and 'satellites' in str(processing_results).lower():
            summary['data_type'] = 'satellite_data'
            
        return summary
        
    def _determine_overall_status(self) -> str:
        """ç¢ºå®šæ•´é«”åŸ·è¡Œç‹€æ…‹"""
        stage_results = self.execution_status['stage_results']
        validation_results = self.execution_status['validation_results']
        
        if not stage_results:
            return 'NO_EXECUTION'
            
        completed_stages = 0
        failed_stages = 0
        
        for stage_key, stage_data in stage_results.items():
            if stage_data.get('status') == 'completed':
                completed_stages += 1
            elif stage_data.get('status') == 'failed':
                failed_stages += 1
                
        total_expected = 6
        
        if completed_stages == total_expected:
            return 'FULLY_SUCCESS'
        elif completed_stages > 0:
            return f'PARTIAL_SUCCESS_{completed_stages}_{total_expected}'
        else:
            return 'COMPLETE_FAILURE'
            
    def _generate_execution_statistics(self) -> Dict[str, Any]:
        """ç”ŸæˆåŸ·è¡Œçµ±è¨ˆè³‡æ–™"""
        stage_results = self.execution_status['stage_results']
        validation_results = self.execution_status['validation_results']
        
        stats = {
            'total_stages': len(stage_results),
            'completed_stages': sum(1 for s in stage_results.values() if s.get('status') == 'completed'),
            'failed_stages': sum(1 for s in stage_results.values() if s.get('status') == 'failed'),
            'validation_passed': sum(1 for v in validation_results.values() if v.get('passed')),
            'validation_failed': sum(1 for v in validation_results.values() if not v.get('passed')),
            'average_stage_duration': 0
        }
        
        # è¨ˆç®—å¹³å‡åŸ·è¡Œæ™‚é–“
        durations = [s.get('duration_minutes', 0) for s in stage_results.values()]
        if durations:
            stats['average_stage_duration'] = sum(durations) / len(durations)
            
        return stats
        
    def _generate_human_readable_summary(self, summary_report: Dict[str, Any]) -> str:
        """ç”Ÿæˆäººé¡å¯è®€çš„æ‘˜è¦å ±å‘Š"""
        metadata = summary_report['execution_metadata']
        tle_sources = summary_report['tle_data_sources']
        stages = summary_report['stage_execution_summary']
        overall_status = summary_report['overall_status']
        stats = summary_report['statistics']
        
        lines = [
            "ğŸ“Š å…­éšæ®µæ•¸æ“šè™•ç†åŸ·è¡Œæ‘˜è¦å ±å‘Š",
            "=" * 60,
            f"ğŸ†” åŸ·è¡ŒID: {metadata['execution_id']}",
            f"â° åŸ·è¡Œæ™‚é–“: {metadata['start_time']} ~ {metadata['end_time']}",
            f"â±ï¸ ç¸½è€—æ™‚: {metadata['total_duration_minutes']:.2f} åˆ†é˜",
            f"ğŸ“Š æ•´é«”ç‹€æ…‹: {overall_status}",
            "",
            "ğŸ›°ï¸ ä½¿ç”¨çš„TLEæ•¸æ“šæº:",
        ]
        
        for constellation, tle_file in tle_sources.items():
            lines.append(f"   {constellation.upper()}: {tle_file}")
            
        lines.extend([
            "",
            "âš¡ å„éšæ®µåŸ·è¡Œè©³æƒ…:",
            "-" * 40
        ])
        
        for stage_key, stage_data in stages.items():
            stage_num = stage_key.split('_')[1]
            status_emoji = "âœ…" if stage_data.get('validation_passed') else "âŒ"
            lines.append(
                f"{status_emoji} éšæ®µ{stage_num}: {stage_data['stage_name']} "
                f"({stage_data.get('duration_minutes', 0):.2f}åˆ†é˜)"
            )
            
        lines.extend([
            "",
            "ğŸ“ˆ åŸ·è¡Œçµ±è¨ˆ:",
            f"   å®Œæˆéšæ®µ: {stats['completed_stages']}/{stats['total_stages']}",
            f"   é©—è­‰é€šé: {stats['validation_passed']}/{stats['validation_failed'] + stats['validation_passed']}",
            f"   å¹³å‡è€—æ™‚: {stats['average_stage_duration']:.2f} åˆ†é˜/éšæ®µ",
            "",
            "ğŸ“ ç›¸é—œæª”æ¡ˆä½ç½®:",
            f"   è©³ç´°JSONå ±å‘Š: logs/summary/final_summary_{metadata['execution_id']}.json",
            f"   åŸ·è¡Œæ—¥èªŒ: logs/execution/execution_{metadata['execution_id']}.log",
            f"   éšæ®µå ±å‘Š: logs/stage_reports/stage_*_{metadata['execution_id']}.json",
            "",
            f"ğŸ“ å ±å‘Šç”Ÿæˆæ™‚é–“: {metadata['report_generation_time']}",
            "=" * 60
        ])
        
        return "\n".join(lines)

def create_unified_log_manager(project_root: str = "/home/sat/ntn-stack", 
                             container_data_dir: str = "data") -> UnifiedLogManager:
    """å‰µå»ºçµ±ä¸€æ—¥èªŒç®¡ç†å™¨å¯¦ä¾‹"""
    return UnifiedLogManager(project_root, container_data_dir)