#!/usr/bin/env python3
"""
ç«¯åˆ°ç«¯æ¸¬è©¦è…³æœ¬

åŠŸèƒ½:
1. é©—è­‰æ‰€æœ‰ Phase å¯ä»¥é †åˆ©é‹è¡Œ
2. æª¢æŸ¥æ•¸æ“šæµå®Œæ•´æ€§
3. å¿«é€Ÿç™¼ç¾æ½›åœ¨å•é¡Œ

åŸ·è¡Œ:
    python tests/test_end_to_end.py

é æœŸçµæœ:
    âœ… Phase 1: Data Loading PASSED
    âœ… Phase 2: Baseline Methods PASSED
    âœ… Phase 3: RL Environment PASSED
    âœ… All tests PASSED!
"""

import subprocess
import sys
from pathlib import Path


def test_phase(phase_name: str, script_path: str) -> bool:
    """
    é‹è¡Œå–®å€‹ Phase ä¸¦æª¢æŸ¥çµæœ

    Args:
        phase_name: Phase åç¨±
        script_path: Python è…³æœ¬è·¯å¾‘

    Returns:
        success: æ˜¯å¦æˆåŠŸ
    """
    print(f"\n{'='*70}")
    print(f"Testing {phase_name}")
    print(f"{'='*70}")

    try:
        result = subprocess.run(
            [sys.executable, script_path],
            capture_output=True,
            text=True,
            timeout=300  # 5åˆ†é˜è¶…æ™‚
        )

        if result.returncode != 0:
            print(f"âŒ {phase_name} FAILED")
            print("\n--- STDERR ---")
            print(result.stderr)
            print("\n--- STDOUT ---")
            print(result.stdout)
            return False

        print(f"âœ… {phase_name} PASSED")

        # é¡¯ç¤ºé—œéµè¼¸å‡º
        if "âœ…" in result.stdout:
            for line in result.stdout.split('\n'):
                if "âœ…" in line:
                    print(f"   {line.strip()}")

        return True

    except subprocess.TimeoutExpired:
        print(f"âŒ {phase_name} TIMEOUT (è¶…é5åˆ†é˜)")
        return False
    except Exception as e:
        print(f"âŒ {phase_name} ERROR: {e}")
        return False


def verify_outputs() -> bool:
    """é©—è­‰é—œéµè¼¸å‡ºæ–‡ä»¶æ˜¯å¦å­˜åœ¨"""
    print(f"\n{'='*70}")
    print("Verifying Output Files")
    print(f"{'='*70}")

    required_files = [
        "data/train_episodes.pkl",
        "data/val_episodes.pkl",
        "data/test_episodes.pkl",
        "data/data_statistics.json",
        "results/baseline_results.json",
        "results/baseline_comparison.txt"
    ]

    all_exist = True
    for file_path in required_files:
        path = Path(file_path)
        if path.exists():
            size_kb = path.stat().st_size / 1024
            print(f"   âœ… {file_path} ({size_kb:.1f} KB)")
        else:
            print(f"   âŒ {file_path} NOT FOUND")
            all_exist = False

    return all_exist


def verify_data_integrity() -> bool:
    """é©—è­‰æ•¸æ“šå®Œæ•´æ€§ï¼ˆæ·±åº¦æª¢æŸ¥ï¼‰"""
    print(f"\n{'='*70}")
    print("Verifying Data Integrity")
    print(f"{'='*70}")

    try:
        import pickle
        import json

        # æª¢æŸ¥ Episodes æ•¸æ“š
        print("\nğŸ“Š æª¢æŸ¥ Episode æ•¸æ“š...")
        with open("data/train_episodes.pkl", 'rb') as f:
            train_eps = pickle.load(f)

        with open("data/val_episodes.pkl", 'rb') as f:
            val_eps = pickle.load(f)

        with open("data/test_episodes.pkl", 'rb') as f:
            test_eps = pickle.load(f)

        total_eps = len(train_eps) + len(val_eps) + len(test_eps)
        print(f"   âœ… ç¸½ Episodes: {total_eps}")
        print(f"   âœ… è¨“ç·´é›†: {len(train_eps)} ({len(train_eps)/total_eps*100:.1f}%)")
        print(f"   âœ… é©—è­‰é›†: {len(val_eps)} ({len(val_eps)/total_eps*100:.1f}%)")
        print(f"   âœ… æ¸¬è©¦é›†: {len(test_eps)} ({len(test_eps)/total_eps*100:.1f}%)")

        # æª¢æŸ¥ç¬¬ä¸€å€‹ Episode çš„çµæ§‹
        if len(train_eps) > 0:
            first_ep = train_eps[0]
            print(f"\nğŸ“‹ æª¢æŸ¥ Episode çµæ§‹...")

            # æª¢æŸ¥å¿…è¦çš„éµ
            required_keys = ['satellite_id', 'constellation', 'time_series', 'episode_length']
            for key in required_keys:
                if key in first_ep:
                    print(f"   âœ… {key}: å­˜åœ¨")
                else:
                    print(f"   âŒ {key}: ç¼ºå¤±")
                    return False

            # æª¢æŸ¥æ™‚é–“åºåˆ—é•·åº¦
            time_series_length = len(first_ep.get('time_series', []))
            print(f"   âœ… æ™‚é–“åºåˆ—é•·åº¦: {time_series_length} é»")

            # æª¢æŸ¥ç‰¹å¾µå®Œæ•´æ€§ï¼ˆ12 ç¶­ï¼‰
            if time_series_length > 0:
                first_point = first_ep['time_series'][0]
                feature_keys = [
                    'rsrp_dbm', 'rsrq_db', 'rs_sinr_db',  # ä¿¡è™Ÿå“è³ª (3)
                    'distance_km', 'elevation_deg', 'doppler_shift_hz', 'radial_velocity_ms',  # ç‰©ç†åƒæ•¸ (4/7)
                    'atmospheric_loss_db', 'path_loss_db', 'propagation_delay_ms',  # ç‰©ç†åƒæ•¸ (3/7)
                    'offset_mo_db', 'cell_offset_db'  # 3GPP åç§» (2)
                ]

                print(f"\nğŸ” æª¢æŸ¥ç‰¹å¾µå®Œæ•´æ€§ï¼ˆ12 ç¶­ï¼‰...")
                missing_features = []
                for key in feature_keys:
                    if key in first_point:
                        print(f"   âœ… {key}")
                    else:
                        print(f"   âŒ {key}: ç¼ºå¤±")
                        missing_features.append(key)

                if missing_features:
                    print(f"\n   âš ï¸  ç¼ºå¤±ç‰¹å¾µ: {missing_features}")
                    return False
                else:
                    print(f"\n   âœ… æ‰€æœ‰ 12 ç¶­ç‰¹å¾µå®Œæ•´")

        # æª¢æŸ¥çµ±è¨ˆæ•¸æ“š
        print(f"\nğŸ“Š æª¢æŸ¥çµ±è¨ˆæ•¸æ“š...")
        with open("data/data_statistics.json", 'r') as f:
            stats = json.load(f)

        print(f"   âœ… ç¸½ Episodes: {stats['total_episodes']}")
        print(f"   âœ… æ˜Ÿåº§åˆ†å¸ƒ: {stats['constellation_distribution']}")

        # æª¢æŸ¥ç‰¹å¾µçµ±è¨ˆ
        feature_stats = stats.get('feature_statistics', {})
        print(f"   âœ… ç‰¹å¾µçµ±è¨ˆ: {len(feature_stats)} å€‹ç‰¹å¾µ")

        # æª¢æŸ¥ Baseline çµæœ
        print(f"\nğŸ“ˆ æª¢æŸ¥ Baseline çµæœ...")
        with open("results/baseline_results.json", 'r') as f:
            baseline_results = json.load(f)

        methods = baseline_results.get('methods', {})
        print(f"   âœ… Baseline æ–¹æ³•æ•¸: {len(methods)}")
        for method_name in methods.keys():
            print(f"   âœ… {method_name}")

        print(f"\nâœ… æ‰€æœ‰æ•¸æ“šå®Œæ•´æ€§æª¢æŸ¥é€šé")
        return True

    except Exception as e:
        print(f"\nâŒ æ•¸æ“šå®Œæ•´æ€§æª¢æŸ¥å¤±æ•—: {e}")
        import traceback
        traceback.print_exc()
        return False


def main():
    """ä¸»æ¸¬è©¦æµç¨‹"""
    print("=" * 70)
    print("Handover-RL End-to-End Test Suite")
    print("=" * 70)
    print("\nğŸ¯ ç›®æ¨™: é©—è­‰æ‰€æœ‰ Phase å¯ä»¥é †åˆ©é‹è¡Œ")
    print("â±ï¸  é è¨ˆæ™‚é–“: 2-5 åˆ†é˜\n")

    # æ¸¬è©¦åºåˆ—
    test_sequence = [
        ("Phase 1: Data Loading", "phase1_data_loader_v2.py"),
        ("Phase 2: Baseline Methods", "phase2_baseline_methods.py"),
        ("Phase 3: RL Environment", "phase3_rl_environment.py"),
    ]

    all_passed = True

    # é‹è¡Œå„ Phase æ¸¬è©¦
    for phase_name, script in test_sequence:
        if not test_phase(phase_name, script):
            all_passed = False
            break

    # é©—è­‰è¼¸å‡ºæ–‡ä»¶
    if all_passed:
        if not verify_outputs():
            all_passed = False

        # æ·±åº¦é©—è­‰æ•¸æ“šå®Œæ•´æ€§
        if all_passed:
            if not verify_data_integrity():
                all_passed = False

    # æœ€çµ‚çµæœ
    print("\n" + "=" * 70)
    if all_passed:
        print("ğŸ‰ All tests PASSED!")
        print("=" * 70)
        print("\nâœ… æ‰€æœ‰ Phase é‹è¡Œæ­£å¸¸")
        print("âœ… æ‰€æœ‰è¼¸å‡ºæ–‡ä»¶å·²ç”Ÿæˆ")
        print("\nä¸‹ä¸€æ­¥:")
        print("  1. é‹è¡Œå®Œæ•´è¨“ç·´: python phase4_rl_training.py")
        print("  2. æˆ–ä½¿ç”¨ä¸€éµè…³æœ¬: ./run_all.sh")
        return 0
    else:
        print("âŒ Some tests FAILED!")
        print("=" * 70)
        print("\nè«‹æª¢æŸ¥ä¸Šè¿°éŒ¯èª¤ä¿¡æ¯ä¸¦ä¿®å¾©")
        return 1


if __name__ == "__main__":
    sys.exit(main())
