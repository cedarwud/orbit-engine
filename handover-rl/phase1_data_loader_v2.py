#!/usr/bin/env python3
"""
Phase 1: æ•¸æ“šè¼‰å…¥èˆ‡è™•ç†ï¼ˆå­¸è¡“æ¨™æº–ç‰ˆ - ç„¡ç°¡åŒ–å‡è¨­ï¼‰

âœ¨ é—œéµæ”¹é€²ï¼ˆç›¸è¼ƒæ–¼èˆŠç‰ˆï¼‰ï¼š
1. æå– Stage 5 å®Œæ•´ 12 ç¶­ç‰¹å¾µï¼ˆRSRP/RSRQ/SINR/distance/elevation/doppler/velocity/atmospheric_loss...ï¼‰
2. åŸºæ–¼è»Œé“é€±æœŸå‰µå»º Episodesï¼ˆä¿æŒæ™‚é–“é€£çºŒæ€§ï¼‰
3. å……åˆ†åˆ©ç”¨ Stage 5 çš„æ™‚é–“åºåˆ—çµæ§‹ï¼ˆ~220 æ™‚é–“é»/è»Œé“é€±æœŸï¼‰
4. âœ… æ§‹å»ºæ™‚é–“æˆ³ç´¢å¼• - ç”¨æ–¼çœŸå¯¦é„°å±…è¡›æ˜ŸæŸ¥æ‰¾ï¼ˆæ¶ˆé™¤ Phase 2/3/5 çš„ç°¡åŒ–å‡è¨­ï¼‰

åŠŸèƒ½ï¼š
1. å¾ orbit-engine è¼‰å…¥ Stage 5 (ä¿¡è™Ÿå“è³ª) å’Œ Stage 6 (3GPP äº‹ä»¶) å®Œæ•´æ•¸æ“š
2. æå– 12 ç¶­ç‹€æ…‹ç‰¹å¾µ
3. åŸºæ–¼è»Œé“é€±æœŸå‰µå»º Episodes
4. âœ… æ§‹å»ºæ™‚é–“æˆ³ç´¢å¼•ï¼ˆæ¯å€‹æ™‚åˆ» 10-15 é¡†åŒæ™‚å¯è¦‹è¡›æ˜Ÿï¼‰
5. åˆ†å‰²è¨“ç·´é›†/é©—è­‰é›†/æ¸¬è©¦é›†
6. ä¿å­˜è™•ç†å¾Œçš„æ•¸æ“š

åŸ·è¡Œï¼š
    python phase1_data_loader_v2.py

è¼¸å‡ºï¼š
    data/train_episodes.pkl          - è¨“ç·´é›† Episodes
    data/val_episodes.pkl            - é©—è­‰é›† Episodes
    data/test_episodes.pkl           - æ¸¬è©¦é›† Episodes
    data/timestamp_index.pkl         - âœ… æ™‚é–“æˆ³ç´¢å¼•ï¼ˆçœŸå¯¦é„°å±…æŸ¥æ‰¾ï¼‰
    data/data_statistics.json        - æ•¸æ“šçµ±è¨ˆ
"""

import json
import glob
import yaml
import numpy as np
import pickle
from pathlib import Path
from typing import Dict, List, Tuple
from datetime import datetime
from collections import defaultdict


class Episode:
    """
    å–®é¡†è¡›æ˜Ÿçš„å®Œæ•´è»Œé“é€±æœŸ Episode

    æ¯å€‹ Episode åŒ…å«ï¼š
    - satellite_id: è¡›æ˜Ÿ ID
    - constellation: æ˜Ÿåº§åç¨±ï¼ˆStarlink/OneWebï¼‰
    - time_series: å®Œæ•´æ™‚é–“åºåˆ—æ•¸æ“šï¼ˆ~220 å€‹æ™‚é–“é»ï¼Œ12 ç¶­ç‰¹å¾µï¼‰
    - gpp_events: è©²è¡›æ˜Ÿè§¸ç™¼çš„ 3GPP äº‹ä»¶åˆ—è¡¨
    - episode_length: Episode é•·åº¦ï¼ˆæ™‚é–“é»æ•¸ï¼‰
    """

    def __init__(self, satellite_id: str, constellation: str):
        self.satellite_id = satellite_id
        self.constellation = constellation
        self.time_series = []
        self.gpp_events = []
        self.episode_length = 0

    def add_time_point(self, time_point: Dict):
        """æ·»åŠ æ™‚é–“é»æ•¸æ“šï¼ˆåŒ…å«å®Œæ•´ 12 ç¶­ç‰¹å¾µï¼‰"""
        self.time_series.append(time_point)
        self.episode_length += 1

    def add_gpp_event(self, event: Dict):
        """æ·»åŠ  3GPP äº‹ä»¶"""
        self.gpp_events.append(event)

    def to_dict(self) -> Dict:
        """è½‰æ›ç‚ºå­—å…¸ï¼ˆç”¨æ–¼ä¿å­˜ï¼‰"""
        return {
            'satellite_id': self.satellite_id,
            'constellation': self.constellation,
            'time_series': self.time_series,
            'gpp_events': self.gpp_events,
            'episode_length': self.episode_length
        }


class OrbitEngineDataLoader:
    """
    å¾ orbit-engine è¼‰å…¥å®Œæ•´æ•¸æ“šï¼ˆå­¸è¡“æ¨™æº–ç‰ˆï¼‰

    è¨­è¨ˆåŸå‰‡ï¼ˆSOURCE: rl.md è©•ä¼°å ±å‘Šï¼‰ï¼š
    - å……åˆ†åˆ©ç”¨ Stage 5 çš„æ‰€æœ‰ç‰©ç†/ä¿¡è™Ÿç‰¹å¾µï¼ˆ12 ç¶­ï¼‰
    - ä¿æŒæ™‚é–“åºåˆ—çµæ§‹ï¼ˆåŸºæ–¼è»Œé“é€±æœŸï¼‰
    - èˆ‡ 3GPP äº‹ä»¶è‡ªç„¶å°æ‡‰
    """

    def __init__(self, config_path: str = "config/data_config.yaml"):
        with open(config_path, 'r') as f:
            self.config = yaml.safe_load(f)

        self.orbit_engine_root = Path(self.config['orbit_engine']['root'])
        self.stage5_data = None
        self.stage6_data = None

        print(f"âœ… é…ç½®è¼‰å…¥å®Œæˆ")
        print(f"   orbit-engine è·¯å¾‘: {self.orbit_engine_root}")

    def load_stage5(self) -> Dict:
        """
        è¼‰å…¥ Stage 5 æ•¸æ“šï¼ˆå®Œæ•´æ™‚é–“åºåˆ—ï¼‰

        SOURCE: orbit-engine Stage 5 ä¿¡è™Ÿå“è³ªåˆ†æè¼¸å‡º
        åŒ…å«ï¼šsignal_analysis (æ¯é¡†è¡›æ˜Ÿçš„å®Œæ•´è»Œé“é€±æœŸæ™‚é–“åºåˆ—)
        """
        stage5_config = self.config['orbit_engine']['stage5']
        stage5_path = Path(stage5_config['path'])
        pattern = stage5_config['pattern']

        files = sorted(glob.glob(str(stage5_path / pattern)))
        if not files:
            raise FileNotFoundError(f"âŒ æœªæ‰¾åˆ° Stage 5 è¼¸å‡º: {stage5_path / pattern}")

        latest_file = files[-1]
        print(f"\nğŸ“¥ è¼‰å…¥ Stage 5: {latest_file}")

        with open(latest_file, 'r') as f:
            self.stage5_data = json.load(f)

        satellites = len(self.stage5_data['signal_analysis'])

        # çµ±è¨ˆç¸½æ™‚é–“é»æ•¸
        total_time_points = 0
        for sat_data in self.stage5_data['signal_analysis'].values():
            total_time_points += len(sat_data['time_series'])

        print(f"   è¡›æ˜Ÿæ•¸é‡: {satellites}")
        print(f"   ç¸½æ™‚é–“é»æ•¸: {total_time_points:,}")
        print(f"   å¹³å‡æ™‚é–“é»/è¡›æ˜Ÿ: {total_time_points / satellites:.1f}")

        return self.stage5_data

    def load_stage6(self) -> Dict:
        """
        è¼‰å…¥ Stage 6 æ•¸æ“šï¼ˆ3GPP äº‹ä»¶ï¼‰

        SOURCE: orbit-engine Stage 6 ç ”ç©¶å„ªåŒ–è¼¸å‡º
        åŒ…å«ï¼šgpp_events (A3/A4/A5/D2 æ›æ‰‹äº‹ä»¶)
        """
        stage6_config = self.config['orbit_engine']['stage6']
        stage6_path = Path(stage6_config['path'])
        pattern = stage6_config['pattern']

        files = sorted(glob.glob(str(stage6_path / pattern)))
        if not files:
            raise FileNotFoundError(f"âŒ æœªæ‰¾åˆ° Stage 6 è¼¸å‡º: {stage6_path / pattern}")

        latest_file = files[-1]
        print(f"\nğŸ“¥ è¼‰å…¥ Stage 6: {latest_file}")

        with open(latest_file, 'r') as f:
            self.stage6_data = json.load(f)

        events = self.stage6_data['gpp_events']
        total = sum([
            len(events.get('a3_events', [])),
            len(events.get('a4_events', [])),
            len(events.get('a5_events', [])),
            len(events.get('d2_events', []))
        ])

        print(f"   A3 äº‹ä»¶: {len(events.get('a3_events', []))}")
        print(f"   A4 äº‹ä»¶: {len(events.get('a4_events', []))}")
        print(f"   A5 äº‹ä»¶: {len(events.get('a5_events', []))}")
        print(f"   D2 äº‹ä»¶: {len(events.get('d2_events', []))}")
        print(f"   ç¸½è¨ˆ: {total:,} å€‹äº‹ä»¶")

        return self.stage6_data

    def extract_full_features(self, time_point: Dict) -> Dict:
        """
        å¾æ™‚é–“é»æå–å®Œæ•´çš„ 12 ç¶­ç‰¹å¾µ

        âœ¨ é€™æ˜¯ç›¸è¼ƒæ–¼èˆŠç‰ˆçš„é—œéµæ”¹é€²ï¼

        ç‰¹å¾µåˆ—è¡¨ï¼ˆå­¸è¡“æ¨™æº–ï¼‰:
        1-3. ä¿¡è™Ÿå“è³ª (3 ç¶­): RSRP, RSRQ, RS-SINR
        4-10. ç‰©ç†åƒæ•¸ (7 ç¶­): Distance, Elevation, Doppler, Velocity, Atmospheric Loss, Path Loss, Delay
        11-12. 3GPP åç§» (2 ç¶­): Offset MO, Cell Offset

        SOURCE:
        - orbit-engine Stage 5 ä¿¡è™Ÿå“è³ªåˆ†æ
        - ITU-R P.676-13 (å¤§æ°£è¡°æ¸›æ¨¡å‹)
        - 3GPP TS 38.214 (ä¿¡è™Ÿå“è³ªè¨ˆç®—)
        - rl.md Line 68-77 (å­¸è¡“æ–‡ç»è­‰æ“š)

        Args:
            time_point: Stage 5 çš„å–®å€‹æ™‚é–“é»æ•¸æ“š

        Returns:
            features: å®Œæ•´çš„ 12 ç¶­ç‰¹å¾µå­—å…¸
        """
        signal_quality = time_point.get('signal_quality', {})
        physical_params = time_point.get('physical_parameters', {})

        features = {
            # ä¿¡è™Ÿå“è³ª (3 ç¶­)
            'rsrp_dbm': signal_quality.get('rsrp_dbm', -999),
            'rsrq_db': signal_quality.get('rsrq_db', -999),
            'rs_sinr_db': signal_quality.get('rs_sinr_db', -999),

            # ç‰©ç†åƒæ•¸ (7 ç¶­)
            'distance_km': physical_params.get('distance_km', -999),
            'elevation_deg': physical_params.get('elevation_deg', -999),
            'doppler_shift_hz': physical_params.get('doppler_shift_hz', -999),
            'radial_velocity_ms': physical_params.get('radial_velocity_ms', -999),
            'atmospheric_loss_db': physical_params.get('atmospheric_loss_db', -999),
            'path_loss_db': physical_params.get('path_loss_db', -999),
            'propagation_delay_ms': physical_params.get('propagation_delay_ms', -999),

            # 3GPP åç§» (2 ç¶­)
            'offset_mo_db': signal_quality.get('offset_mo_db', 0),
            'cell_offset_db': signal_quality.get('cell_offset_db', 0),

            # å…ƒæ•¸æ“š
            'timestamp': time_point.get('timestamp', ''),
            'is_connectable': time_point.get('is_connectable', False)
        }

        return features

    def create_episodes(self) -> List[Episode]:
        """
        å‰µå»ºåŸºæ–¼è»Œé“é€±æœŸçš„ Episodes

        âœ¨ é€™æ˜¯ç›¸è¼ƒæ–¼èˆŠç‰ˆçš„é—œéµæ”¹é€²ï¼

        è¨­è¨ˆåŸå‰‡ï¼š
        - æ¯å€‹ Episode = ä¸€é¡†è¡›æ˜Ÿçš„å®Œæ•´è»Œé“é€±æœŸï¼ˆ~220 æ™‚é–“é»ï¼‰
        - ä¿æŒæ™‚é–“é€£çºŒæ€§ï¼ˆ5 ç§’é–“éš”ï¼‰
        - é—œè¯å°æ‡‰çš„ 3GPP äº‹ä»¶

        SOURCE:
        - docs/final.md Line 74-84 (è»Œé“é€±æœŸåˆ†æ)
        - Starlink: ~90-95 åˆ†é˜è»Œé“é€±æœŸ
        - OneWeb: ~109-115 åˆ†é˜è»Œé“é€±æœŸ
        - rl.md Line 108-165 (Episode è¨­è¨ˆå•é¡Œåˆ†æ)

        Returns:
            episodes: Episode å°è±¡åˆ—è¡¨
        """
        if self.stage5_data is None or self.stage6_data is None:
            raise ValueError("âŒ è«‹å…ˆè¼‰å…¥ Stage 5 å’Œ Stage 6 æ•¸æ“š")

        print("\nğŸ”¨ å‰µå»ºåŸºæ–¼è»Œé“é€±æœŸçš„ Episodes...")

        episodes = []
        signal_analysis = self.stage5_data['signal_analysis']
        gpp_events = self.stage6_data['gpp_events']

        # æŒ‰è¡›æ˜Ÿçµ„ç¹” 3GPP äº‹ä»¶
        events_by_satellite = self._organize_events_by_satellite(gpp_events)

        for sat_id, sat_data in signal_analysis.items():
            # åˆ¤æ–·æ˜Ÿåº§
            constellation = self._get_constellation(sat_id)

            # å‰µå»º Episode
            episode = Episode(sat_id, constellation)

            # æ·»åŠ æ™‚é–“åºåˆ—æ•¸æ“šï¼ˆæå–å®Œæ•´ 12 ç¶­ç‰¹å¾µï¼‰
            for time_point in sat_data['time_series']:
                features = self.extract_full_features(time_point)
                episode.add_time_point(features)

            # æ·»åŠ å°æ‡‰çš„ 3GPP äº‹ä»¶
            if sat_id in events_by_satellite:
                for event in events_by_satellite[sat_id]:
                    episode.add_gpp_event(event)

            episodes.append(episode)

        print(f"   å‰µå»º Episodes: {len(episodes)}")

        # çµ±è¨ˆ Episodes é•·åº¦
        episode_lengths = [ep.episode_length for ep in episodes]
        print(f"   å¹³å‡ Episode é•·åº¦: {np.mean(episode_lengths):.1f} æ™‚é–“é»")
        print(f"   æœ€çŸ­ Episode: {np.min(episode_lengths)} æ™‚é–“é»")
        print(f"   æœ€é•· Episode: {np.max(episode_lengths)} æ™‚é–“é»")

        return episodes

    def _organize_events_by_satellite(self, gpp_events: Dict) -> Dict[str, List]:
        """æŒ‰è¡›æ˜Ÿçµ„ç¹” 3GPP äº‹ä»¶"""
        events_by_sat = defaultdict(list)

        for event_type in ['a3_events', 'a4_events', 'a5_events', 'd2_events']:
            for event in gpp_events.get(event_type, []):
                # æœå‹™è¡›æ˜Ÿ
                serving_sat = event.get('serving_satellite')
                if serving_sat:
                    events_by_sat[serving_sat].append({
                        'type': event_type.replace('_events', '').upper(),
                        'role': 'serving',
                        **event
                    })

                # é„°å±…è¡›æ˜Ÿ
                neighbor_sat = event.get('neighbor_satellite') or event.get('target_satellite')
                if neighbor_sat:
                    events_by_sat[neighbor_sat].append({
                        'type': event_type.replace('_events', '').upper(),
                        'role': 'neighbor',
                        **event
                    })

        return dict(events_by_sat)

    def _get_constellation(self, satellite_id: str) -> str:
        """
        åˆ¤æ–·è¡›æ˜Ÿæ‰€å±¬æ˜Ÿåº§

        SOURCE: orbit-engine Stage 1 æ˜Ÿåº§é…ç½®
        - Starlink: NORAD ID 40000-60000 ç¯„åœ
        - OneWeb: NORAD ID 44000-49000 ç¯„åœ
        """
        try:
            sat_id_int = int(satellite_id)
            if 40000 <= sat_id_int < 60000:
                return 'starlink'
            elif 44000 <= sat_id_int < 50000:
                return 'oneweb'
            else:
                return 'unknown'
        except:
            return 'unknown'

    def split_episodes(self, episodes: List[Episode]) -> Tuple[List, List, List]:
        """
        åˆ†å‰²è¨“ç·´/é©—è­‰/æ¸¬è©¦é›†

        SOURCE: æ¨™æº– ML æ•¸æ“šåˆ†å‰²æ¯”ä¾‹
        - è¨“ç·´é›†: 75%
        - é©—è­‰é›†: 12.5%
        - æ¸¬è©¦é›†: 12.5%
        """
        split_config = self.config['data_split']
        train_ratio = split_config['train_ratio']
        val_ratio = split_config['val_ratio']
        seed = split_config['random_seed']

        np.random.seed(seed)

        indices = np.arange(len(episodes))
        np.random.shuffle(indices)

        n_episodes = len(episodes)
        n_train = int(n_episodes * train_ratio)
        n_val = int(n_episodes * val_ratio)

        train_idx = indices[:n_train]
        val_idx = indices[n_train:n_train + n_val]
        test_idx = indices[n_train + n_val:]

        train_episodes = [episodes[i] for i in train_idx]
        val_episodes = [episodes[i] for i in val_idx]
        test_episodes = [episodes[i] for i in test_idx]

        print(f"\nğŸ“Š æ•¸æ“šåˆ†å‰²:")
        print(f"   è¨“ç·´é›†: {len(train_episodes)} Episodes ({train_ratio*100:.1f}%)")
        print(f"   é©—è­‰é›†: {len(val_episodes)} Episodes ({val_ratio*100:.1f}%)")
        print(f"   æ¸¬è©¦é›†: {len(test_episodes)} Episodes ({(1-train_ratio-val_ratio)*100:.1f}%)")

        return train_episodes, val_episodes, test_episodes

    def build_timestamp_index(self, episodes: List[Episode]) -> Dict:
        """
        æ§‹å»ºæ™‚é–“æˆ³ç´¢å¼• - ç”¨æ–¼çœŸå¯¦é„°å±…è¡›æ˜ŸæŸ¥æ‰¾

        âœ… æ¶ˆé™¤ç°¡åŒ–å‡è¨­çš„é—œéµåŠŸèƒ½ï¼

        åŸç†ï¼š
        - åœ¨åŒä¸€æ™‚åˆ»ï¼Œå¯èƒ½æœ‰ 10-15 é¡†è¡›æ˜ŸåŒæ™‚å¯è¦‹
        - é€šéæ™‚é–“æˆ³ç´¢å¼•ï¼Œå¯ä»¥å¿«é€Ÿæ‰¾åˆ°çœŸå¯¦é„°å±…è¡›æ˜ŸåŠå…¶ RSRP
        - å®Œå…¨åŸºæ–¼ Stage 5 çœŸå¯¦è§€æ¸¬æ•¸æ“šï¼Œç„¡ä¼°ç®—æˆ–å‡è¨­

        SOURCE:
        - Stage 5 signal_analysis çœŸå¯¦æ™‚é–“åºåˆ—æ•¸æ“š
        - æ™‚é–“æˆ³é‡ç–Šåˆ†æé¡¯ç¤ºæ¯å€‹æ™‚åˆ»æœ‰ 10-15 é¡†è¡›æ˜Ÿ

        Returns:
            timestamp_index: {
                "2025-10-16T03:08:30+00:00": {
                    "55487": {12ç¶­ç‰¹å¾µ},
                    "55490": {12ç¶­ç‰¹å¾µ},
                    ...  # åŒä¸€æ™‚åˆ»æ‰€æœ‰å¯è¦‹è¡›æ˜Ÿ
                }
            }
        """
        print(f"\nğŸ” æ§‹å»ºæ™‚é–“æˆ³ç´¢å¼•ï¼ˆç”¨æ–¼çœŸå¯¦é„°å±…æŸ¥æ‰¾ï¼‰...")

        timestamp_index = defaultdict(dict)

        for episode in episodes:
            sat_id = episode.satellite_id
            for time_point in episode.time_series:
                timestamp = time_point['timestamp']
                # å°‡è©²è¡›æ˜Ÿåœ¨è©²æ™‚åˆ»çš„å®Œæ•´ç‰¹å¾µåŠ å…¥ç´¢å¼•
                timestamp_index[timestamp][sat_id] = time_point

        # çµ±è¨ˆç´¢å¼•è³ªé‡
        unique_timestamps = len(timestamp_index)
        satellites_per_timestamp = [len(sats) for sats in timestamp_index.values()]
        avg_neighbors = np.mean(satellites_per_timestamp)
        min_neighbors = np.min(satellites_per_timestamp)
        max_neighbors = np.max(satellites_per_timestamp)

        print(f"   å”¯ä¸€æ™‚é–“æˆ³æ•¸: {unique_timestamps}")
        print(f"   å¹³å‡åŒæ™‚å¯è¦‹è¡›æ˜Ÿæ•¸: {avg_neighbors:.1f}")
        print(f"   æœ€å°‘åŒæ™‚å¯è¦‹: {min_neighbors} é¡†")
        print(f"   æœ€å¤šåŒæ™‚å¯è¦‹: {max_neighbors} é¡†")
        print(f"   âœ… æ™‚é–“æˆ³ç´¢å¼•æ§‹å»ºå®Œæˆï¼ˆç”¨æ–¼çœŸå¯¦é„°å±… RSRP æ¯”è¼ƒï¼‰")

        return dict(timestamp_index)

    def save_episodes(self, train_episodes: List[Episode],
                     val_episodes: List[Episode],
                     test_episodes: List[Episode]):
        """ä¿å­˜ Episodesï¼ˆä½¿ç”¨ pickle ä¿ç•™å°è±¡çµæ§‹ï¼‰"""
        data_dir = Path("data")
        data_dir.mkdir(exist_ok=True)

        print(f"\nğŸ’¾ ä¿å­˜ Episodes...")

        # ä¿å­˜è¨“ç·´é›†
        with open(data_dir / "train_episodes.pkl", 'wb') as f:
            pickle.dump([ep.to_dict() for ep in train_episodes], f)
        print(f"   âœ… train_episodes.pkl ({len(train_episodes)} Episodes)")

        # ä¿å­˜é©—è­‰é›†
        with open(data_dir / "val_episodes.pkl", 'wb') as f:
            pickle.dump([ep.to_dict() for ep in val_episodes], f)
        print(f"   âœ… val_episodes.pkl ({len(val_episodes)} Episodes)")

        # ä¿å­˜æ¸¬è©¦é›†
        with open(data_dir / "test_episodes.pkl", 'wb') as f:
            pickle.dump([ep.to_dict() for ep in test_episodes], f)
        print(f"   âœ… test_episodes.pkl ({len(test_episodes)} Episodes)")

        # æ§‹å»ºä¸¦ä¿å­˜æ™‚é–“æˆ³ç´¢å¼•ï¼ˆç”¨æ–¼çœŸå¯¦é„°å±…æŸ¥æ‰¾ï¼‰
        all_episodes = train_episodes + val_episodes + test_episodes
        timestamp_index = self.build_timestamp_index(all_episodes)

        with open(data_dir / "timestamp_index.pkl", 'wb') as f:
            pickle.dump(timestamp_index, f)
        print(f"   âœ… timestamp_index.pkl (ç”¨æ–¼çœŸå¯¦é„°å±…æŸ¥æ‰¾)")

        # ä¿å­˜çµ±è¨ˆä¿¡æ¯
        statistics = self._compute_statistics(train_episodes, val_episodes, test_episodes)
        with open(data_dir / "data_statistics.json", 'w') as f:
            json.dump(statistics, f, indent=2)
        print(f"   âœ… data_statistics.json")

    def _compute_statistics(self, train_eps: List, val_eps: List, test_eps: List) -> Dict:
        """è¨ˆç®—æ•¸æ“šçµ±è¨ˆ"""
        all_episodes = train_eps + val_eps + test_eps

        # çµ±è¨ˆç‰¹å¾µå€¼ç¯„åœ
        feature_stats = defaultdict(lambda: {'values': []})

        for episode in all_episodes:
            for time_point in episode.time_series:
                for key, value in time_point.items():
                    if isinstance(value, (int, float)) and value != -999:
                        feature_stats[key]['values'].append(value)

        # è¨ˆç®—çµ±è¨ˆé‡
        stats = {}
        for feature, data in feature_stats.items():
            if data['values']:
                values = np.array(data['values'])
                stats[feature] = {
                    'mean': float(np.mean(values)),
                    'std': float(np.std(values)),
                    'min': float(np.min(values)),
                    'max': float(np.max(values)),
                    'median': float(np.median(values))
                }

        # æ˜Ÿåº§çµ±è¨ˆ
        constellation_counts = defaultdict(int)
        for episode in all_episodes:
            constellation_counts[episode.constellation] += 1

        return {
            'total_episodes': len(all_episodes),
            'train_episodes': len(train_eps),
            'val_episodes': len(val_eps),
            'test_episodes': len(test_eps),
            'constellation_distribution': dict(constellation_counts),
            'feature_statistics': stats,
            'generated_at': datetime.now().isoformat()
        }


def main():
    """ä¸»å‡½æ•¸"""
    print("=" * 70)
    print("Phase 1: æ•¸æ“šè¼‰å…¥èˆ‡è™•ç†ï¼ˆå­¸è¡“æ¨™æº–ç‰ˆ v2ï¼‰")
    print("=" * 70)

    loader = OrbitEngineDataLoader()

    # è¼‰å…¥æ•¸æ“š
    loader.load_stage5()
    loader.load_stage6()

    # å‰µå»º Episodes
    episodes = loader.create_episodes()

    # åˆ†å‰²æ•¸æ“š
    train, val, test = loader.split_episodes(episodes)

    # ä¿å­˜æ•¸æ“š
    loader.save_episodes(train, val, test)

    print("\n" + "=" * 70)
    print("âœ… Phase 1 å®Œæˆï¼")
    print("=" * 70)
    print("\nâœ¨ é—œéµæ”¹é€²:")
    print("   - âœ… æå–å®Œæ•´ 12 ç¶­ç‰¹å¾µï¼ˆRSRP/RSRQ/SINR/distance/elevation/doppler...ï¼‰")
    print("   - âœ… åŸºæ–¼è»Œé“é€±æœŸå‰µå»º Episodesï¼ˆä¿æŒæ™‚é–“é€£çºŒæ€§ï¼‰")
    print("   - âœ… å……åˆ†åˆ©ç”¨ Stage 5 çš„æ™‚é–“åºåˆ—çµæ§‹")
    print("\nä¸‹ä¸€æ­¥: é‹è¡Œ Phase 2 (Baseline æ–¹æ³•)")
    print("  python phase2_baseline_methods.py")


if __name__ == "__main__":
    main()
